{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCODE-ARMY/GAN/blob/main/CWGAN_refined%20with%20ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYeOozq5owHg",
        "outputId": "f082d3d5-e1ed-44a6-827c-c7108bb93c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jul  9 17:47:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_NXH3DLL4Xv"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#   tpu_addr='grpc://' + os.environ['COLAB_TPU_ADDR'] #google remote procedure call (GRPC)\n",
        "#   print(tpu_addr)\n",
        "#   tpu=tf.distribute.cluster_resolver.TPUClusterResolver(tpu_addr)\n",
        "#   tf.config.experimental_connect_to_cluster(tpu)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "#   strategy=tf.distribute.experimental.TPUStrategy(tpu)\n",
        "#   print('Running on Tpu',tpu.cluster_spec().as_dict()['worker'])\n",
        "#   print('Number of accelerators',strategy.num_replicas_in_sync)\n",
        "\n",
        "# except ValueError:\n",
        "#   print('fuck')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWQpEX7liD1b"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# a=tf.keras.applications.inception_v3.InceptionV3(include_top=True,\n",
        "#     weights='imagenet')\n",
        "# a.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2fAD5rMGjUe"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/GAN GENERATED/DiffAug.py' /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJW2pdicsFst",
        "outputId": "ed042ef6-fbcf-454f-c1e0-070aede13d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_uJNCUfsO8n"
      },
      "outputs": [],
      "source": [
        "#use centralStorageStrategy\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense,Conv2D,BatchNormalization,MaxPooling2D, Dropout,Conv2DTranspose,InputLayer,Concatenate,LeakyReLU,Embedding,Reshape,AveragePooling2D\n",
        "import cv2 \n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import tensorflow_addons as tfa #used for spectral normalaization\n",
        "from sklearn.utils import shuffle\n",
        "import PIL\n",
        "import PIL.Image\n",
        "# from DiffAug import DiffAugment as df\n",
        "\n",
        "# TF_GPU_ALLOCATOR=cuda_malloc_async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGVvcC_oV3Kr"
      },
      "outputs": [],
      "source": [
        "# a=Embedding(5,16)(1)\n",
        "# # a.numpy()\n",
        "# a=np.expand_dims(a.numpy(),axis=0)\n",
        "# print(a.shape)\n",
        "# a=tf.keras.layers.RepeatVector(4096)(a)\n",
        "# print(a.shape)\n",
        "# a=Reshape((256,256,1))(a)\n",
        "# print(a.shape)\n",
        "# print(a.numpy)\n",
        "# c=a.numpy()\n",
        "# print(c[0,0,255])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ettE0yrYsPNN"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1777254f5OC",
        "outputId": "f555957e-2ba5-4bfc-8bd2-1198a3394360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['headphone', 'mouse', 'laptop', 'keyboard', 'monitor']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('/content/drive/MyDrive/scrapped data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3P01LyefMcw"
      },
      "outputs": [],
      "source": [
        "#total image 1228/32= 38 || 1228/16=76 || 1228/26=46\n",
        "batch_size = 16\n",
        "num_channels = 3\n",
        "num_classes = 5\n",
        "image_size = 256\n",
        "latent_dim = 256\n",
        "channel_axis=3\n",
        "steps_per_epoc=38\n",
        "epochh=1\n",
        "# divide_array=np.array([6])\n",
        "\n",
        "# policy = 'color,translation,cutout'# color,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kByHhFqX_4vE"
      },
      "outputs": [],
      "source": [
        "# if np.any(74%divide_array==0) :\n",
        "#   print(True)\n",
        "\n",
        "# 74%divide_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVe8LFuVWiwT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # @tf.function \n",
        "\n",
        "# It does not support generator\n",
        "# It cannot be used with funcs returing model_variables\n",
        "# It excepts to return atleast one Tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPYR0Dt4sPQO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gene(data_dir='/content/drive/MyDrive/scrapped data',batch_size=batch_size,resize=(image_size,image_size)):\n",
        "  cat=['laptop', 'keyboard', 'mouse', 'headphone', 'monitor']\n",
        "\n",
        "  img_path_list=[]\n",
        "  labels=[]\n",
        "\n",
        "  #getting path to all images\n",
        "  for i in cat:\n",
        "    path=os.path.join(data_dir,i)\n",
        "    for j in os.listdir(path):\n",
        "      img_path_list.append(os.path.join(path,j))\n",
        "\n",
        "  img_path_list=shuffle(img_path_list)\n",
        "\n",
        "  for i in img_path_list:\n",
        "    # print(cat.index(i.split('/')[-2]))\n",
        "    labels.append(cat.index(i.split('/')[-2]))\n",
        "\n",
        "\n",
        "#converting labels to onehot encoded vectors  \n",
        "  # labels=tf.keras.utils.to_categorical(labels,5)\n",
        " \n",
        "\n",
        "  img_list=[]\n",
        "  labels_list=[]\n",
        " \n",
        "  for i,j in enumerate(img_path_list):\n",
        "    # img=cv2.resize(cv2.imread(j,cv2.IMREAD_UNCHANGED),resize,interpolation=cv2.INTER_AREA)\n",
        "    img=np.array(PIL.Image.open(j))\n",
        "    # tensor = tf.image.resize(tensor, (128,128))\n",
        "    # tensor = tf.subtract(tf.divide(tensor, 127.5), 1)\n",
        "\n",
        "    img=img.astype(np.float32)\n",
        "   \n",
        "    img=tf.image.resize(img,[image_size,image_size],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,antialias=False)\n",
        "    # img=img.astype(np.float32)\n",
        "    # img=(img-127.5)/127.5\n",
        "    img = tf.subtract(tf.divide(img, 127.5), 1)\n",
        "    assert not np.any(np.isnan(img))\n",
        "    img_list.append(img)\n",
        "    \n",
        "    labels_list.append(labels[i])\n",
        "\n",
        "    if len(img_list)==batch_size:\n",
        "      \n",
        "      data=np.array(img_list,dtype=np.float32),np.expand_dims(np.array(labels_list,dtype=np.int8),axis=1)#not necessarily convert to tensor\n",
        "      yield data\n",
        "      img_list.clear()\n",
        "      labels_list.clear()\n",
        "\n",
        "\n",
        "\n",
        "#Tensorspec can be used to declare numpy signature but with dtype specified in tf\n",
        "\n",
        "dataset=tf.data.Dataset.from_generator(gene,output_signature=(tf.TensorSpec(shape=(batch_size, image_size, image_size, channel_axis),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(batch_size,1),dtype=tf.dtypes.int8)))\n",
        "dataset=dataset.prefetch(buffer_size=tf.data.AUTOTUNE).repeat(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay27Cx9mNc2k"
      },
      "outputs": [],
      "source": [
        "#prepping  dataset for Tpu \n",
        "# strategy.experimental_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc8zP1VpH_ge"
      },
      "outputs": [],
      "source": [
        "# a=36\n",
        "# if np.any(35%np.array([36,37,38])==0):\n",
        "#   print(True)\n",
        "# else:\n",
        "#   print(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUK4CUlX4wyz"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x,filter,kernel_size,stride,padding='same',activation=tf.keras.layers.LeakyReLU(alpha=0.2),is_initializer=True,is_regularizer=False,initializer= tf.keras.initializers.RandomNormal()\n",
        ",regularizer=None,name=None):\n",
        "  if name is not None:\n",
        "    bn_name = name + '_bn'\n",
        "    conv_name = name + '_conv'\n",
        "  else:\n",
        "    bn_name = None\n",
        "    conv_name = None\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  if is_initializer and is_regularizer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,kernel_initializer=initializer,regularizer=regularizer,name=conv_name))(x)\n",
        "\n",
        "  elif is_regularizer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,regularizer=regularizer,name=conv_name))(x)\n",
        "\n",
        "  elif is_initializer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,kernel_initializer=initializer,name=conv_name))(x)\n",
        "\n",
        "  else:\n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,name=conv_name))(x)\n",
        "   \n",
        "  \n",
        "\n",
        "  \n",
        "  return x\n",
        "\n",
        "    \n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cncoxYkaDwDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# a=np.random.rand(0,256)\n",
        "# # a=np.expand_dims(np.random.rand(None,256),axis=1)\n",
        "# print(a.shape)\n",
        "# a=tf.keras.layers.RepeatVector(256)(a)\n",
        "# tf.print(a.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWFuBH0ziV0K"
      },
      "outputs": [],
      "source": [
        "# embedding=Embedding(num_classes,10)\n",
        "\n",
        "# for i in range(10):\n",
        "#   q=embedding()\n",
        "#   print(q.numpy(),q.numpy().shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYeAopgPsPTU",
        "outputId": "f7416bcc-4fce-4959-ae1a-1261f1f2af56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 16)        80          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spectral_normalization (Spectr  (None, 1, 16)       288         ['embedding[0][0]']              \n",
            " alNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 16)           0           ['spectral_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 4096, 16)     0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 256, 256, 1)  0           ['repeat_vector[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256, 256, 4)  0           ['input_1[0][0]',                \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " spectral_normalization_1 (Spec  (None, 128, 128, 64  2432       ['concatenate[0][0]']            \n",
            " tralNormalization)             )                                                                 \n",
            "                                                                                                  \n",
            " spectral_normalization_2 (Spec  (None, 128, 128, 32  2112       ['spectral_normalization_1[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_3 (Spec  (None, 126, 126, 19  55680      ['spectral_normalization_2[0][0]'\n",
            " tralNormalization)             2)                               ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 126, 126, 19  0           ['spectral_normalization_3[0][0]'\n",
            "                                2)                               ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_4 (Spec  (None, 126, 126, 80  15520      ['dropout[0][0]']                \n",
            " tralNormalization)             )                                                                 \n",
            "                                                                                                  \n",
            " spectral_normalization_5 (Spec  (None, 124, 124, 64  46208      ['spectral_normalization_4[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_6 (Spec  (None, 124, 124, 32  2112       ['spectral_normalization_5[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_7 (Spec  (None, 124, 124, 64  51328      ['spectral_normalization_6[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_8 (Spec  (None, 124, 124, 80  5280       ['spectral_normalization_7[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_9 (Spec  (None, 62, 62, 64)  46208       ['spectral_normalization_8[0][0]'\n",
            " tralNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_13 (Spe  (None, 62, 62, 64)  4224        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_11 (Spe  (None, 62, 62, 48)  3168        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_14 (Spe  (None, 62, 62, 43)  68886       ['spectral_normalization_13[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 62, 62, 64)   0           ['spectral_normalization_9[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_10 (Spe  (None, 62, 62, 64)  4224        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_12 (Spe  (None, 62, 62, 32)  38464       ['spectral_normalization_11[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_15 (Spe  (None, 62, 62, 64)  24896       ['spectral_normalization_14[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_16 (Spe  (None, 62, 62, 32)  2112        ['max_pooling2d[0][0]']          \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 62, 62, 192)  0           ['spectral_normalization_10[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_12[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_15[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_16[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_17 (Spe  (None, 62, 62, 128)  24832      ['mixed0[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_18 (Spe  (None, 31, 31, 196)  226184     ['spectral_normalization_17[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 31, 31, 196)  0           ['spectral_normalization_18[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_22 (Spe  (None, 31, 31, 64)  12672       ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_20 (Spe  (None, 31, 31, 48)  9504        ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_23 (Spe  (None, 31, 31, 64)  36992       ['spectral_normalization_22[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 31, 31, 196)  0          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " spectral_normalization_19 (Spe  (None, 31, 31, 64)  12672       ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_21 (Spe  (None, 31, 31, 64)  76928       ['spectral_normalization_20[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_24 (Spe  (None, 31, 31, 64)  102528      ['spectral_normalization_23[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_25 (Spe  (None, 31, 31, 32)  6336        ['max_pooling2d_1[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 31, 31, 224)  0           ['spectral_normalization_19[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_21[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_24[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_25[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 31, 31, 224)  0           ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_29 (Spe  (None, 31, 31, 64)  14464       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_27 (Spe  (None, 31, 31, 48)  10848       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_30 (Spe  (None, 31, 31, 96)  55488       ['spectral_normalization_29[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 31, 31, 224)  0          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " spectral_normalization_26 (Spe  (None, 31, 31, 64)  14464       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_28 (Spe  (None, 31, 31, 32)  38464       ['spectral_normalization_27[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_31 (Spe  (None, 31, 31, 64)  55424       ['spectral_normalization_30[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_32 (Spe  (None, 31, 31, 32)  7232        ['max_pooling2d_2[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 31, 31, 192)  0           ['spectral_normalization_26[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_28[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_31[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_32[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 31, 31, 192)  0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_34 (Spe  (None, 31, 31, 64)  12416       ['dropout_3[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_35 (Spe  (None, 31, 31, 96)  55488       ['spectral_normalization_34[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_33 (Spe  (None, 15, 15, 196)  339080     ['dropout_3[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_36 (Spe  (None, 15, 15, 96)  83136       ['spectral_normalization_35[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 192)  0          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 15, 15, 484)  0           ['spectral_normalization_33[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_36[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " spectral_normalization_41 (Spe  (None, 15, 15, 128)  62208      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_42 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_41[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_38 (Spe  (None, 15, 15, 128)  62208      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_43 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_42[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_39 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_38[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_44 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_43[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 484)  0          ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_37 (Spe  (None, 15, 15, 192)  93312      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_40 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_39[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_45 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_44[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_46 (Spe  (None, 15, 15, 192)  93312      ['max_pooling2d_4[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 15, 15, 640)  0           ['spectral_normalization_37[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_40[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_45[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_46[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 15, 15, 640)  0           ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_51 (Spe  (None, 15, 15, 140)  89880      ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_52 (Spe  (None, 15, 15, 128)  125696     ['spectral_normalization_51[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_48 (Spe  (None, 15, 15, 160)  102720     ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_53 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_52[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_49 (Spe  (None, 15, 15, 128)  143616     ['spectral_normalization_48[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_54 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_53[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 15, 15, 640)  0          ['dropout_4[0][0]']              \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " spectral_normalization_47 (Spe  (None, 15, 15, 192)  123264     ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_50 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_49[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_55 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_54[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_56 (Spe  (None, 15, 15, 128)  82176      ['average_pooling2d[0][0]']      \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 15, 15, 576)  0           ['spectral_normalization_47[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_50[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_55[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_56[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 15, 15, 576)  0           ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_61 (Spe  (None, 15, 15, 140)  80920      ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_62 (Spe  (None, 15, 15, 128)  125696     ['spectral_normalization_61[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_58 (Spe  (None, 15, 15, 160)  92480      ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_63 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_62[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_59 (Spe  (None, 15, 15, 128)  143616     ['spectral_normalization_58[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_64 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_63[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 15, 15, 576)  0          ['dropout_5[0][0]']              \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " spectral_normalization_57 (Spe  (None, 15, 15, 192)  110976     ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_60 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_59[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_65 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_64[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_66 (Spe  (None, 15, 15, 128)  73984      ['average_pooling2d_1[0][0]']    \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 15, 15, 576)  0           ['spectral_normalization_57[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_60[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_65[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_66[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_67 (Spe  (None, 15, 15, 192)  110976     ['mixed6[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_68 (Spe  (None, 13, 13, 64)  110720      ['spectral_normalization_67[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 13, 13, 64)   0           ['spectral_normalization_68[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_69 (Spe  (None, 7, 7, 64)    102528      ['dropout_6[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_70 (Spe  (None, 7, 7, 32)    2112        ['spectral_normalization_69[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_71 (Spe  (None, 4, 4, 64)    51328       ['spectral_normalization_70[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_72 (Spe  (None, 1, 1, 128)   73984       ['spectral_normalization_71[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 128)          0           ['spectral_normalization_72[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            129         ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,235,431\n",
            "Trainable params: 5,228,092\n",
            "Non-trainable params: 7,339\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# tf.config.run_functions_eagerly(True)\n",
        "# embedding=Embedding(num_classes,50)\n",
        "\n",
        "\n",
        "def discriminator():\n",
        "  # initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=.05)\n",
        "\n",
        "  # Create the discriminator.\n",
        "  inp =layers.Input(shape=[image_size, image_size,channel_axis])\n",
        "\n",
        "  label_inp_layer=layers.Input(shape=(1,))\n",
        "  label_inp=Embedding(num_classes,16)(label_inp_layer)\n",
        "\n",
        "  label_inp=tfa.layers.SpectralNormalization(layers.Dense(16,activation=tf.keras.layers.LeakyReLU(alpha=0.2) )) (label_inp)\n",
        "\n",
        "  label_inp=layers.Flatten()(label_inp)\n",
        " \n",
        "  label_inp=tf.keras.layers.RepeatVector(4096)(label_inp) #try using 16 embedding\n",
        "  \n",
        "  \n",
        "  # label_inp= tf.repeat(label_inp.numpy(), repeats=[image_size * image_size])\n",
        "\n",
        "  \n",
        "  label_inp=Reshape((image_size,image_size,1))(label_inp)\n",
        "\n",
        "  \n",
        "  x = Concatenate(axis=-1)([inp, label_inp])\n",
        "\n",
        "  #filter,kernel_size,stride,padding,activation,initializer,regularizer,dropout_val\n",
        "\n",
        "  # x=conv2d_bn(x,64,3,1,padding='same')\n",
        "\n",
        "  # batch_size,128,128,32\n",
        "  x=conv2d_bn(x,64,3,2,padding='same')\n",
        "\n",
        "\n",
        "  x=conv2d_bn(x,32,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,192,3,1,padding='valid')\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x,80,1,1,padding='valid')\n",
        "\n",
        "  # batch_size,128,128,64\n",
        "  x=conv2d_bn(x,64,3,1,padding='valid') #maxpool_2\n",
        "\n",
        "  x=conv2d_bn(x,32,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,64,5,1,padding='same')\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "  x=conv2d_bn(x,80,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,64,3,2,padding='same')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  #block 1\n",
        "  #batch_size,35 x 35 x 256\n",
        " \n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 32, 5, 1)\n",
        "  \n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 43, 5, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "  \n",
        "  branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed0')\n",
        "\n",
        "  x=conv2d_bn(x,128,1,1)\n",
        "  x=conv2d_bn(x,196,3,2)\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  #block 2\n",
        "  #batch_size,35 x 35 x 256\n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 1)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.2)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 5, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.2)(branch3x3dbl)\n",
        " \n",
        "  branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed1')\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x=conv2d_bn(x, 64, 5, 2)\n",
        "\n",
        "  #block 3\n",
        "  #batch_size,35 x 35 x 256\n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 32, 5, 1)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "\n",
        "  branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed2')\n",
        "\n",
        "\n",
        "  \n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  #block 3\n",
        "  #batch_size,17 x 17 x 768\n",
        "  branch3x3 = conv2d_bn(x, 196, 3, 2,padding='valid')\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 1,)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 2,padding='valid')\n",
        "  \n",
        "  branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  x = layers.concatenate([branch3x3, branch3x3dbl,branch_pool], axis=channel_axis, name='mixed3')\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "  # mixed 4: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, (1,7), 1)\n",
        "  # branch7x7=layers.Dropout(0.2)(branch7x7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, (7,1), 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "\n",
        "  branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],axis=channel_axis,name='mixed4')\n",
        "\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  # mixed 5,6  batch_size,17 x 17 x 768\n",
        "  for i in range(2):\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, (1,7), 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, (7,1), 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 140, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "\n",
        "    branch_pool =AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    branch_pool = conv2d_bn(branch_pool, 128, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed' + str(5 + i))\n",
        "    if i==0:\n",
        "      x=layers.Dropout(0.4)(x)\n",
        "\n",
        "\n",
        "  #  # mixed 7: 17 x 17 x 768\n",
        "  # branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  # branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "  # branch7x7 = conv2d_bn(branch7x7, 192, (1,7), 1)\n",
        "  # branch7x7 = conv2d_bn(branch7x7, 192, (7,1), 1)\n",
        "\n",
        "  # branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (1,7), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (7,1), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (1,7), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (7,1), 1)\n",
        "\n",
        "  # branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  # branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  # x = layers.concatenate(\n",
        "  #     [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "  #     axis=channel_axis,\n",
        "  #     name='mixed7')\n",
        "  \n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "  \n",
        "  x=conv2d_bn(x, 192, 1, 1,padding='same')\n",
        "\n",
        "  x=conv2d_bn(x, 64, 3, 1,padding='valid')\n",
        "  x=layers.Dropout(0.2)(x)\n",
        " \n",
        "  # x=conv2d_bn(x, 192, 3, 1,padding='same')\n",
        "  # # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x=conv2d_bn(x, 64, 1, 1,padding='valid')\n",
        "  # # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 64, 5, 2,padding='same')\n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 32, 1, 1,padding='valid')\n",
        "  x=conv2d_bn(x, 64, 5, 2,padding='same')\n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 128, 3, 2,padding='valid')\n",
        "  # x=conv2d_bn(x, 32, 1, 1,padding='valid')\n",
        "  # x=conv2d_bn(x, 64, 2, 1,padding='valid')\n",
        "  # x=layers.Dropout(0.3)(x)\n",
        "  \n",
        "  x=layers.Flatten()(x)\n",
        "\n",
        "  # x=tfa.layers.SpectralNormalization(layers.Dense(units=1024,use_bias=False,kernel_regularizer=tf.keras.regularizers.L2(0.1),kernel_initializer='random_normal'))(x)\n",
        "  # x=layers.Activation('LeakyReLU')(x)\n",
        "  x=layers.Dropout(0.5)(x)\n",
        "\n",
        "  x=layers.Dense(units=1)(x)\n",
        "\n",
        "  return keras.Model(inputs=[label_inp_layer,inp], outputs=x)\n",
        "\n",
        "discriminator=discriminator()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P2shJRsTRY4"
      },
      "outputs": [],
      "source": [
        "# discriminator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3b3TlPJsPYe"
      },
      "outputs": [],
      "source": [
        "def generator():\n",
        "\n",
        "  # kernel_regularizer=regularizers.L2(1e-4)\n",
        "  \n",
        "  initializer =tf.keras.initializers.RandomNormal()\n",
        "\n",
        "  label_inp_layer=layers.Input(shape=(1,))\n",
        "  x=Embedding(num_classes,16)(label_inp_layer)\n",
        "  # x=Dense(1*1*256)(x)\n",
        "  # x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "  x=Reshape((1,1,16))(x)\n",
        "\n",
        "  inp =layers.Input(shape=(latent_dim,))\n",
        "  # y=layers.Dense(1 * 1 * latent_dim)(inp)\n",
        "  # y=layers.LeakyReLU(alpha=0.2)(y)\n",
        "  y=layers.Reshape((1, 1, latent_dim))(inp)\n",
        "  \n",
        "  y=Concatenate(axis=-1)([y, x])\n",
        "\n",
        "  y=Dense(256)(y)\n",
        "  y=layers.LeakyReLU(alpha=0.2)(y)\n",
        " \n",
        "\n",
        "  #(batch_size, 2, 2,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.5)(y)\n",
        "\n",
        "  #(batch_size, 4, 4,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "  #(batch_size, 8, 8,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.5)(y)\n",
        "\n",
        "  #(batch_size, 16, 16,514) 50=128\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "\n",
        "  #(batch_size, 32, 32,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer=initializer )(y)#tf.random_normal_initializer(0., 0.05)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "\n",
        "  #(batch_size, 64, 64,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)#,kernel_regularizer=regularizers.L2(1e-4)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "  #(batch_size, 128, 128,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',kernel_initializer= initializer)(y)\n",
        "  y=layers.BatchNormalization()(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "  \n",
        "  #(batch_size, 256, 256,3)\n",
        "  y=layers.Conv2DTranspose(3,4,strides=2,padding='same',kernel_initializer= initializer,activation='tanh')(y)\n",
        "\n",
        "  return keras.Model(inputs=[label_inp_layer,inp], outputs=y)\n",
        "\n",
        "generator=generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tZ_OFaPsPbQ",
        "outputId": "182e4362-0c42-4d80-86c5-16f0c7ffb7c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 16)        80          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 1, 256)    0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 1, 16)     0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 1, 1, 272)    0           ['reshape_2[0][0]',              \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1, 1, 256)    69888       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 1, 1, 256)    0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 2, 2, 200)   819400      ['leaky_re_lu_2[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 2, 2, 200)   800         ['conv2d_transpose[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2, 2, 200)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 2, 2, 200)    0           ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 200)   640200      ['dropout_8[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4, 4, 200)   800         ['conv2d_transpose_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 200)    0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 4, 4, 200)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 200)   640200      ['dropout_9[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 8, 8, 200)   800         ['conv2d_transpose_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 8, 8, 200)    0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 8, 8, 200)    0           ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 200)  640200     ['dropout_10[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 200)  800        ['conv2d_transpose_3[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 16, 16, 200)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 16, 16, 200)  0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 200)  640200     ['dropout_11[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 200)  800        ['conv2d_transpose_4[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32, 32, 200)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 32, 32, 200)  0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 200)  640200     ['dropout_12[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 200)  800        ['conv2d_transpose_5[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 64, 64, 200)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 64, 64, 200)  0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 20  640200     ['dropout_13[0][0]']             \n",
            " spose)                         0)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 20  800        ['conv2d_transpose_6[0][0]']     \n",
            " rmalization)                   0)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 128, 128, 20  0           ['batch_normalization_6[0][0]']  \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 128, 128, 20  0           ['leaky_re_lu_9[0][0]']          \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 3)  9603       ['dropout_14[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,745,771\n",
            "Trainable params: 4,742,971\n",
            "Non-trainable params: 2,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ahWp00G0XLh"
      },
      "outputs": [],
      "source": [
        "# max_translation = 0.145 #125\n",
        "# max_rotation = 0.145 #125\n",
        "# max_zoom = 0.25 #0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PtUiOMtcfmS"
      },
      "outputs": [],
      "source": [
        "# class AdaptiveAugmenter(keras.Model):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "        \n",
        "\n",
        "#         # stores the current probability of an image being augmented\n",
        "#         # self.probability = tf.Variable(0.0)\n",
        "\n",
        "#         # the corresponding augmentation names from the paper are shown above each layer\n",
        "#         # the authors show (see figure 4), that the blitting and geometric augmentations\n",
        "#         # are the most helpful in the low-data regime\n",
        "#         self.augmenter = keras.Sequential(\n",
        "#             [\n",
        "#                 layers.InputLayer(input_shape=(image_size, image_size, 3)),\n",
        "#                 # blitting/x-flip:\n",
        "#                 layers.RandomFlip(\"horizontal\"),\n",
        "#                 # blitting/integer translation:\n",
        "#                 layers.RandomTranslation(\n",
        "#                     height_factor=max_translation,\n",
        "#                     width_factor=max_translation,\n",
        "#                     interpolation=\"nearest\",\n",
        "#                 ),\n",
        "#                 # geometric/rotation:\n",
        "#                 layers.RandomRotation(factor=max_rotation),\n",
        "#                 # geometric/isotropic and anisotropic scaling:\n",
        "#                 layers.RandomZoom(\n",
        "#                     height_factor=(-max_zoom, 0.0), width_factor=(-max_zoom, 0.0)\n",
        "#                 ),\n",
        "#             ],\n",
        "#             name=\"adaptive_augmenter\",\n",
        "#         )\n",
        "    \n",
        "\n",
        "#     def call(self, images, epoch,training=True):\n",
        "\n",
        "#       augmented_images = self.augmenter(images)\n",
        "      \n",
        "\n",
        "#       if np.any(epoch % divide_array==0):\n",
        "#         return augmented_images\n",
        "#       else:\n",
        "#         return images\n",
        "\n",
        "\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLPKl0TETdfS"
      },
      "outputs": [],
      "source": [
        "max_translation = 0.125\n",
        "max_rotation = 0.125\n",
        "max_zoom = 0.25\n",
        "target_accuracy = 0.85\n",
        "integration_steps = 1000\n",
        "#  \"hard sigmoid\", useful for binary accuracy calculation from logits\n",
        "def step(values):\n",
        "    # negative values -> 0.0, positive values -> 1.0\n",
        "    return 0.5 * (1.0 + tf.sign(values))\n",
        "\n",
        "\n",
        "# augments images with a probability that is dynamically updated during training\n",
        "class AdaptiveAugmenter(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # stores the current probability of an image being augmented\n",
        "        self.probability = tf.Variable(0.0)\n",
        "\n",
        "        # the corresponding augmentation names from the paper are shown above each layer\n",
        "        # the authors show (see figure 4), that the blitting and geometric augmentations\n",
        "        # are the most helpful in the low-data regime\n",
        "        self.augmenter = keras.Sequential(\n",
        "            [\n",
        "                layers.InputLayer(input_shape=(image_size, image_size, 3)),\n",
        "                # blitting/x-flip:\n",
        "                layers.RandomFlip(\"horizontal\"),\n",
        "                # blitting/integer translation:\n",
        "                layers.RandomTranslation(\n",
        "                    height_factor=max_translation,\n",
        "                    width_factor=max_translation,\n",
        "                    interpolation=\"nearest\",\n",
        "                ),\n",
        "                # geometric/rotation:\n",
        "                layers.RandomRotation(factor=max_rotation),\n",
        "                # geometric/isotropic and anisotropic scaling:\n",
        "                layers.RandomZoom(\n",
        "                    height_factor=(-max_zoom, 0.0), width_factor=(-max_zoom, 0.0)\n",
        "                ),\n",
        "            ],\n",
        "            name=\"adaptive_augmenter\",\n",
        "        )\n",
        "\n",
        "    def call(self, images, training):\n",
        "        if training:\n",
        "            augmented_images = self.augmenter(images, training)\n",
        "\n",
        "            # during training either the original or the augmented images are selected\n",
        "            # based on self.probability\n",
        "            augmentation_values = tf.random.uniform(\n",
        "                shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "            )\n",
        "            augmentation_bools = tf.math.less(augmentation_values, self.probability)\n",
        "\n",
        "            images = tf.where(augmentation_bools, augmented_images, images)\n",
        "        return images\n",
        "\n",
        "    def update(self, real_logits):\n",
        "        current_accuracy = tf.reduce_mean(step(real_logits))\n",
        "\n",
        "        # the augmentation probability is updated based on the dicriminator's\n",
        "        # accuracy on real images\n",
        "        accuracy_error = current_accuracy - target_accuracy\n",
        "        self.probability.assign(\n",
        "            tf.clip_by_value(\n",
        "                self.probability + accuracy_error / integration_steps, 0.0, 1.0\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anDWwTKLnxcS"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# a=np.array([1,2,3,4,5])\n",
        "# # a*=10\n",
        "# print((sum(a)/5)*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM4n-2nosPd3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tf.config.run_functions_eagerly(True)\n",
        "\n",
        "class ConditionalGAN(tf.keras.Model):\n",
        "  def __init__(self,discriminator, generator, latent_dim,critic_steps,gp_weight=10.0):\n",
        "    super(ConditionalGAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "    self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "    self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "    self.gp_weight=gp_weight\n",
        "    self.critic_steps=critic_steps\n",
        "    self.augmenter = AdaptiveAugmenter()\n",
        "    \n",
        "    \n",
        "    \n",
        "  def compile(self, d_optimizer, g_optimizer, generator_loss,critic_loss):\n",
        "    super(ConditionalGAN,self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.generator_loss = generator_loss\n",
        "    self.critic_loss=critic_loss\n",
        "    self.augmentation_probability_tracker = keras.metrics.Mean(name=\"aug_p\")\n",
        "   \n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.gen_loss_tracker, self.disc_loss_tracker,self.augmentation_probability_tracker]   \n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def gradient_penalty(self,batch_size, real_images, fake_images,labels):\n",
        "\n",
        "    epsilon = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "    diff = fake_images - real_images\n",
        "    interpolated = real_images + (epsilon * diff)\n",
        "\n",
        "    \n",
        "    with tf.GradientTape() as gp_tape:\n",
        "\n",
        "      #tf.GradientTape().watch() is used to record constant vals.we can perform some computation on the variables we are watching. \n",
        "      #The computation can be anything from cubing it, x**3, to passing it through a neural network\n",
        "\n",
        "      gp_tape.watch(interpolated)\n",
        "\n",
        "      # 1. Get the discriminator output for this interpolated image.\n",
        "\n",
        "      pred = self.discriminator([labels,interpolated], training=True)\n",
        "\n",
        "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "\n",
        "\n",
        "    # print('shape= ',grads.numpy().shape)\n",
        "    #what is gradient\n",
        "   #The gradient of any line or curve tells us the rate of change of one variable with respect to another.\n",
        "\n",
        "    #Gradient norm scaling involves changing the derivatives of the loss function to have a given vector norm when the L2 vector norm \n",
        "    #(sum of the squared values) of the gradient vector exceeds a threshold value.\n",
        "\n",
        "    norm = tf.sqrt(1e-8 + tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "\n",
        "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "    # print('norm= ',norm,' gp= ',gp)\n",
        "\n",
        "    return gp\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self,data):\n",
        "   \n",
        "    real_images,labels=data\n",
        "  \n",
        "    # real_images=self.diff(epoch=epochh,images=real_images)\n",
        "    \n",
        "    real_images=self.augmenter(images=real_images,training=True)\n",
        "    \n",
        "    for i in range(self.critic_steps):\n",
        "      random_vectors=tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "      \n",
        "      #training descriminator\n",
        "      with tf.GradientTape() as tape:\n",
        "\n",
        "        fake_images = self.generator([labels,random_vectors], training=True)\n",
        "\n",
        "        fake_images=self.augmenter(images=fake_images,training=True)\n",
        "     \n",
        "\n",
        "        fake_logits=self.discriminator([labels,fake_images],training=True)\n",
        "        # print(fake_logits)\n",
        "\n",
        "\n",
        "        real_logits=self.discriminator([labels,real_images], training=True)\n",
        "    \n",
        "        d_cost = self.critic_loss(real_logits=real_logits, fake_logits=fake_logits)\n",
        "\n",
        "        gp = self.gradient_penalty(batch_size, real_images, fake_images,labels=labels) #both real and fake image have the shape of (256,256,3)\n",
        "\n",
        "        #while interplating it will give the image with size(32, 256, 256, 3) so add the vector image labels\n",
        "        d_loss = d_cost + gp * self.gp_weight\n",
        "\n",
        "    \n",
        "      #wasserstein\n",
        "      grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "      self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
        "\n",
        "      self.augmenter.update(real_logits)\n",
        "\n",
        "#||||GENERATOR|||||||||||||||||||||||GENERATOR|||||||||||||||||||||||||||GENERATOR|||||||||||||||||||||||||||||||||||GENERATOR||||||||||||||||||||||||||||GENERATOR||||||||||\n",
        "#--------------------GENERATOR-----------------------------GENERATOR---------------------------------GENERATOR---------------------------GENERATOR---------------------------\n",
        "#||||||GENERATOR||||||||||||||||||GENERATOR|||||||||||||||||||||||||||GENERATOR|||||||||||||||||||||||||||||||||||GENERATOR|||||||||||||||||||||||||GENERATOR||||||||||||||||\n",
        "\n",
        "    # Sample random points in the latent space for training generator\n",
        "    random_vectors= tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "   \n",
        "    \n",
        "    #train generator\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      fake_images=self.generator([labels,random_vectors],training=True)\n",
        "      fake_images=self.augmenter(images=fake_images,training=True) #self.augmenter\n",
        "\n",
        "      fake_logits=self.discriminator([labels,fake_images],training=True)\n",
        "      g_loss = self.generator_loss(fake_logits) \n",
        "\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
        "\n",
        "    # Monitor loss.\n",
        "    self.gen_loss_tracker.update_state(g_loss)\n",
        "    self.disc_loss_tracker.update_state(d_loss)\n",
        "    self.augmentation_probability_tracker.update_state(self.augmenter.probability)\n",
        "\n",
        "  \n",
        "    return {\n",
        "        \"g_loss\": self.gen_loss_tracker.result(),\n",
        "        \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        \"aug_p\":self.augmentation_probability_tracker.result()\n",
        "    }\n",
        "\n",
        "# # @tf.function\n",
        "# def aug(epoch,images):\n",
        "#   # return df(images,policy=policy)\n",
        "\n",
        "#   if np.any(epoch % divide_array==0):\n",
        "#     images=df(images,policy=policy)\n",
        "#     return images\n",
        "#   else:\n",
        "#     return images\n",
        "\n",
        "@tf.function\n",
        "def critic_loss(real_logits, fake_logits):\n",
        "    real_loss = tf.reduce_mean(real_logits)\n",
        "    fake_loss = tf.reduce_mean(fake_logits)\n",
        "    return fake_loss - real_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_logits):\n",
        "    return -tf.reduce_mean(fake_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73v2j8xH2_bj"
      },
      "outputs": [],
      "source": [
        "LR = 0.0002 # WGAN-GP paper recommends lr of 0.0002\n",
        "d_optimizer = keras.optimizers.Adam(learning_rate=LR, beta_1=0.5, beta_2=0.9) # UPDATE for WGAN-GP: use Adam instead of RMSProp\n",
        "g_optimizer = keras.optimizers.Adam(learning_rate=LR, beta_1=0.5, beta_2=0.9) # UPDATE for WGAN-GP: use Adam instead of RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cEGQ7Qv0jb0"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/GAN GENERATED/chk'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,discriminator_optimizer=d_optimizer,\n",
        "                                 generator=generator,discriminator=discriminator)\n",
        "\n",
        "manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=checkpoint_dir, max_to_keep=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOxnHb2usPji"
      },
      "outputs": [],
      "source": [
        "#tf.config.run_functions_eagerly(True) #will make all invocations of tf.function run eagerly instead of running as a traced graph function.This can be useful for debugging. \n",
        "\n",
        "import time\n",
        "%matplotlib inline\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    global epochh\n",
        "    epochh=epoch+1\n",
        "    \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "  #   print('GAN MONITOR',logs.keys)\n",
        "    if (epoch+1) % 15 == 0:\n",
        "      manager.save()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      pth=['laptop', 'keyboard', 'mouse', 'headphone', 'monitor']\n",
        "      path=['/content/drive/MyDrive/GAN GENERATED/'+i for i in pth]\n",
        "      \n",
        "      random_latent_vectors = tf.random.normal(shape=(num_classes, latent_dim))#(5,256)\n",
        "      classes=[[0],[1],[2],[3],[4]]\n",
        "      classes=np.array(classes,dtype=np.int8)  #(5, 1)\n",
        "\n",
        "\n",
        "      \n",
        "      generated_images = self.model.generator([classes,random_latent_vectors])\n",
        "      generated_images = (generated_images*127.5)+127.5\n",
        "\n",
        "      for i in range(num_classes):\n",
        "        img = generated_images[i].numpy()\n",
        "        img = keras.preprocessing.image.array_to_img(img) \n",
        "      \n",
        "        img.save(path[i]+'/'+str(epoch+1)+'.png')\n",
        "      \n",
        "    \n",
        "    \n",
        "\n",
        "callback=GANMonitor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9qGNTmZsPsG"
      },
      "outputs": [],
      "source": [
        "# #restoring checkpoint. verify using assert below\n",
        "\n",
        "# checkpoint_dir=('/content/drive/MyDrive/GAN GENERATED/chk')\n",
        "\n",
        "# #checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir)).assert_consumed()\n",
        "\n",
        "# checkpoint.restore(manager.latest_checkpoint).assert_consumed()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfzIv7ca_uZ0",
        "outputId": "551c73c5-b030-433d-d8ad-bb3586524747"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "38.375"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1228/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmfuAX8mwDw-"
      },
      "outputs": [],
      "source": [
        "#https://github.com/keras-team/keras/blob/master/keras/engine/training.py/Model\n",
        "#It is extracted as tf.keras.Model\n",
        "#so ConditionalGan(tf.keras.Model) super(ConditioanlGan,self).__init__() means we are calling the init func in keras/engine/training.py/Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8X9HskQsPvB"
      },
      "outputs": [],
      "source": [
        "#total image 1228 \n",
        "\n",
        "csv_logger=tf.keras.callbacks.CSVLogger('/content/drive/MyDrive/GAN GENERATED/log.csv', separator=\",\", append=True)\n",
        "\n",
        "cond_gan = ConditionalGAN( discriminator=discriminator , generator=generator, latent_dim=latent_dim, critic_steps=5)\n",
        "\n",
        "cond_gan.compile( d_optimizer=d_optimizer, g_optimizer=g_optimizer, generator_loss=generator_loss, critic_loss=critic_loss)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejITXc5rsPxp",
        "outputId": "644c92b3-8852-480c-9180-7ccdd532bd41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 308s 4s/step - g_loss: 676.8735 - d_loss: -221.6521 - aug_p: 3.9474e-06\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 2580.7798 - d_loss: -421.7225 - aug_p: 2.1941e-04\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 3317.4585 - d_loss: -569.3931 - aug_p: 1.2632e-04\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -930.4764 - d_loss: -549.8812 - aug_p: 0.0036\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 140s 4s/step - g_loss: 3289.7350 - d_loss: -230.2306 - aug_p: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -2080.1420 - d_loss: 464.2151 - aug_p: 0.0081\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 143.4458 - d_loss: -134.9314 - aug_p: 0.0038\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 13718.0089 - d_loss: -56.2680 - aug_p: 7.5658e-06\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 25775.7035 - d_loss: 375.4791 - aug_p: 5.9539e-05\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 8529.8363 - d_loss: -531.7064 - aug_p: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 1918.8934 - d_loss: -118.0479 - aug_p: 7.4671e-05\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 204240.2026 - d_loss: -864.9713 - aug_p: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 12802382.7692 - d_loss: -19015.5693 - aug_p: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 14308648.3077 - d_loss: 89339.2373 - aug_p: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 138s 4s/step - g_loss: 10030583.6923 - d_loss: 436994.3493 - aug_p: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 28209016.2051 - d_loss: -108285.2851 - aug_p: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 32124199.0769 - d_loss: -730086.4547 - aug_p: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 17348840.7179 - d_loss: 29676.7619 - aug_p: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 9210806.2436 - d_loss: 1406219.0905 - aug_p: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -2143821.4615 - d_loss: 504660.4475 - aug_p: 2.3026e-06\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 10825.2437 - d_loss: 668697.7194 - aug_p: 1.9737e-06\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -166340.1875 - d_loss: 40733.8800 - aug_p: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 20.4390 - d_loss: 261.8507 - aug_p: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -0.0533 - d_loss: 9.9953 - aug_p: 2.3026e-06\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 0.0116 - d_loss: 9.9941 - aug_p: 6.5789e-07\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -0.0491 - d_loss: 9.9911 - aug_p: 3.1250e-05\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -0.0336 - d_loss: 9.9706 - aug_p: 6.5789e-07\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -64.4884 - d_loss: -14.1423 - aug_p: 0.0015\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1788.8718 - d_loss: -73.2289 - aug_p: 3.3092e-04\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 43048.6327 - d_loss: 225.4243 - aug_p: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 28520.9479 - d_loss: -72.0204 - aug_p: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 272127.3523 - d_loss: 514.8246 - aug_p: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1224000.0481 - d_loss: -37129.1531 - aug_p: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 731318.2340 - d_loss: 20875.0027 - aug_p: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 463999.2644 - d_loss: 18187.9629 - aug_p: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 58660.7934 - d_loss: 7226.6423 - aug_p: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 243665.8317 - d_loss: -7401.0407 - aug_p: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1048715.6779 - d_loss: -42008.4052 - aug_p: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 738705.5529 - d_loss: 11419.8859 - aug_p: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 370213.0096 - d_loss: -35913.0707 - aug_p: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 59363.8995 - d_loss: 8773.5337 - aug_p: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 36161.5564 - d_loss: 23392.2276 - aug_p: 1.3158e-06\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -102.8248 - d_loss: 209.2699 - aug_p: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 8.7977 - d_loss: 38.0435 - aug_p: 2.0066e-05\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 1223.7050 - d_loss: -79.5055 - aug_p: 2.5132e-04\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 454.2864 - d_loss: -102.4811 - aug_p: 5.8553e-04\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -1393.9032 - d_loss: -76.3398 - aug_p: 0.0110\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 428.3988 - d_loss: -127.0283 - aug_p: 0.0015\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 199.4719 - d_loss: 16.7879 - aug_p: 3.7829e-05\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -345.3888 - d_loss: -11.0160 - aug_p: 0.0020\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1961.0968 - d_loss: -76.8414 - aug_p: 0.0070\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 10329.0218 - d_loss: 1070.8119 - aug_p: 0.0074\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 634.0957 - d_loss: 104.1702 - aug_p: 0.0013\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -5013.1036 - d_loss: -628.5212 - aug_p: 0.0113\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 43163.6092 - d_loss: -227025.6237 - aug_p: 2.2171e-04\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 14223658.2436 - d_loss: -2550586.0167 - aug_p: 2.3026e-06\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -27070625.3846 - d_loss: -2627092.6418 - aug_p: 2.3355e-05\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -751183.3774 - d_loss: -66464.8579 - aug_p: 9.1118e-05\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -3276.1171 - d_loss: 393.1496 - aug_p: 0.0035\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -110.0064 - d_loss: 15.8351 - aug_p: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 400.0410 - d_loss: -64.2784 - aug_p: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 30.7609 - d_loss: 9.8556 - aug_p: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 254.7315 - d_loss: -29.7036 - aug_p: 0.0011\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -141.9574 - d_loss: -46.6039 - aug_p: 0.0113\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 333.8378 - d_loss: 68.1530 - aug_p: 6.7171e-04\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -190.0321 - d_loss: -34.8253 - aug_p: 0.0100\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 192.0910 - d_loss: 6.5872 - aug_p: 0.0057\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -9152.6584 - d_loss: 157.1303 - aug_p: 0.0212\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -13352.4333 - d_loss: 757.2710 - aug_p: 0.0495\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 626.5317 - d_loss: 17.7672 - aug_p: 0.0524\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2734.9786 - d_loss: 60.7316 - aug_p: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 1176.4628 - d_loss: -11.7181 - aug_p: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 161.2040 - d_loss: -9.9549 - aug_p: 0.0076\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -559.7352 - d_loss: -6.2110 - aug_p: 0.0079\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -607.2745 - d_loss: 38.9304 - aug_p: 0.0166\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 2564.3720 - d_loss: -44.9287 - aug_p: 3.8454e-04\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -146.1303 - d_loss: -29.6000 - aug_p: 9.8585e-04\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -197.1434 - d_loss: 113.0241 - aug_p: 0.0058\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1004.7590 - d_loss: 38.0592 - aug_p: 0.0028\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 356.8901 - d_loss: -2.5925 - aug_p: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1084.4500 - d_loss: -41.4093 - aug_p: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 15972.8004 - d_loss: -621.5651 - aug_p: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 382486.3047 - d_loss: -4303.4019 - aug_p: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 631873.8998 - d_loss: 47499.4226 - aug_p: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 254475.0901 - d_loss: 6346.8429 - aug_p: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1653.7294 - d_loss: 402.8688 - aug_p: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 510.9022 - d_loss: -11.9585 - aug_p: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 876.6948 - d_loss: -45.1631 - aug_p: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2718.8569 - d_loss: -71.0113 - aug_p: 7.3355e-05\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 671.8953 - d_loss: -10.4918 - aug_p: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 109.3893 - d_loss: 67.7038 - aug_p: 0.0053\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -452.2951 - d_loss: 21.0544 - aug_p: 0.0308\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -935.0585 - d_loss: -46.0964 - aug_p: 0.0591\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -587.3245 - d_loss: 38.7863 - aug_p: 0.0872\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 437.2183 - d_loss: 11.8595 - aug_p: 0.0403\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1327.1518 - d_loss: -139.5728 - aug_p: 2.9934e-05\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 76.2249 - d_loss: -3.4391 - aug_p: 0.0010\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 230.0624 - d_loss: -14.2264 - aug_p: 0.0013\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -75.2675 - d_loss: 173.7497 - aug_p: 5.4474e-04\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 1779.8280 - d_loss: 428.7998 - aug_p: 1.9408e-05\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 14188.4870 - d_loss: -709.0430 - aug_p: 6.5789e-07\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -2924.1467 - d_loss: -340.3364 - aug_p: 0.0044\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 165.0902 - d_loss: -102.8725 - aug_p: 0.0035\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -103.4075 - d_loss: -13.9546 - aug_p: 0.0043\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 7883.4989 - d_loss: 1334.2725 - aug_p: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 168509.1595 - d_loss: -7116.2543 - aug_p: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 24044.2799 - d_loss: 3135.1429 - aug_p: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 34.8559 - d_loss: 2.2812 - aug_p: 6.4243e-04\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1318.0407 - d_loss: 372.3692 - aug_p: 4.2632e-04\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -2169.0448 - d_loss: -99.2698 - aug_p: 0.0187\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -6338.5988 - d_loss: -2.6045 - aug_p: 0.0469\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2073.1061 - d_loss: 157.4591 - aug_p: 0.0585\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 25056.8622 - d_loss: -1423.6547 - aug_p: 0.0039\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 537597.3939 - d_loss: -12615.1442 - aug_p: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 4221.8667 - d_loss: 241.3673 - aug_p: 3.8487e-05\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -326.3635 - d_loss: -33.5005 - aug_p: 1.1513e-04\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 42764.1634 - d_loss: 1533.4431 - aug_p: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 40301.9200 - d_loss: 1088.9698 - aug_p: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -695.6966 - d_loss: -23.7025 - aug_p: 0.0055\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -544.6545 - d_loss: -87.0429 - aug_p: 2.3717e-04\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2292.1954 - d_loss: 56.2447 - aug_p: 7.8322e-04\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 19224.9483 - d_loss: 1780.4048 - aug_p: 0.0016\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -623.6417 - d_loss: -15.3405 - aug_p: 0.0032\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 100114.3691 - d_loss: -10663.0405 - aug_p: 1.1414e-04\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -652.1402 - d_loss: 67.3015 - aug_p: 8.2039e-04\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -2181.5927 - d_loss: -305.1467 - aug_p: 1.5724e-04\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 3167.3101 - d_loss: 56.2441 - aug_p: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 15556.8721 - d_loss: 97.8768 - aug_p: 3.4737e-04\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -83.9045 - d_loss: 2.2232 - aug_p: 0.0148\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1686.5625 - d_loss: -19.6584 - aug_p: 2.4671e-05\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -10278.7449 - d_loss: 332.6379 - aug_p: 0.0128\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1412.0073 - d_loss: 431.9090 - aug_p: 0.0025\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -149.3460 - d_loss: -40.5282 - aug_p: 6.4704e-04\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 39046.4584 - d_loss: 2058.6800 - aug_p: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 861.7151 - d_loss: 47.1041 - aug_p: 4.5625e-04\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -963.7573 - d_loss: -23.9790 - aug_p: 0.0086\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 320.9307 - d_loss: -16.7961 - aug_p: 8.7401e-04\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 475.4444 - d_loss: 27.2514 - aug_p: 0.0020\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1826.1723 - d_loss: 44.7599 - aug_p: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 2101.3661 - d_loss: 6.2756 - aug_p: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 62177.7438 - d_loss: -770.0208 - aug_p: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 15509.9771 - d_loss: 552.6988 - aug_p: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -7.8481 - d_loss: 2.0322 - aug_p: 0.0066\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -667.3630 - d_loss: -55.2478 - aug_p: 0.0229\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -1169.8543 - d_loss: -21.5443 - aug_p: 0.0442\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -519.9139 - d_loss: -70.6787 - aug_p: 0.0430\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -382.3211 - d_loss: -25.9652 - aug_p: 0.0325\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -34761.7393 - d_loss: 1073.6655 - aug_p: 0.0075\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -7903.4228 - d_loss: -2205.9655 - aug_p: 0.0026\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -111.7375 - d_loss: 19.0031 - aug_p: 5.1118e-04\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1565.7018 - d_loss: -65.3467 - aug_p: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 165.2105 - d_loss: -64.2884 - aug_p: 9.2862e-04\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -44.3909 - d_loss: -20.3872 - aug_p: 0.0079\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 55523.5654 - d_loss: 159.7871 - aug_p: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 221583.3039 - d_loss: 4367.9265 - aug_p: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 116795.6494 - d_loss: 7635.0359 - aug_p: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 3741105.0513 - d_loss: -271548.1749 - aug_p: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 419906.9022 - d_loss: -15568.1711 - aug_p: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1055871.0128 - d_loss: -59329.7771 - aug_p: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 11446.8013 - d_loss: -775.7198 - aug_p: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 192954.5715 - d_loss: 10832.7234 - aug_p: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 5616.9098 - d_loss: 444.2189 - aug_p: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 146.9317 - d_loss: 6.9174 - aug_p: 2.5658e-05\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -26.9474 - d_loss: 16.0562 - aug_p: 0.0027\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -913.1522 - d_loss: -9.1159 - aug_p: 0.0154\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -23933.5902 - d_loss: 7562.7457 - aug_p: 0.0017\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -244.8518 - d_loss: 5.3348 - aug_p: 0.0159\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -26.0832 - d_loss: 6.6783 - aug_p: 0.0114\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -12354.9435 - d_loss: -1157.8395 - aug_p: 3.2895e-05\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 16268.0346 - d_loss: -323.1971 - aug_p: 1.5789e-05\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -52.6044 - d_loss: -2.4372 - aug_p: 1.9638e-04\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 413.8535 - d_loss: 167.0374 - aug_p: 4.5921e-04\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -518.7678 - d_loss: -8.4595 - aug_p: 0.0156\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -22.2237 - d_loss: -19.7635 - aug_p: 0.0052\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -179.3565 - d_loss: -27.5027 - aug_p: 0.0049\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 755.9859 - d_loss: 83.4269 - aug_p: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 2590.4419 - d_loss: -81.4785 - aug_p: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 2405.1018 - d_loss: 1582.5987 - aug_p: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1194.8928 - d_loss: -330.7133 - aug_p: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 1097.2391 - d_loss: 230.5582 - aug_p: 5.6250e-05\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -189659.4394 - d_loss: -3881.1628 - aug_p: 0.0101\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -32953.1509 - d_loss: -477.7618 - aug_p: 8.3190e-04\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -73115.6108 - d_loss: -6929.9484 - aug_p: 0.0023\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -69333.8964 - d_loss: -3762.3499 - aug_p: 0.0032\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 153274.4825 - d_loss: -17187.9986 - aug_p: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 195061.1849 - d_loss: -25219.3861 - aug_p: 2.9605e-06\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 629.1643 - d_loss: 27.1712 - aug_p: 4.4211e-04\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 3.4555 - d_loss: 9.8460 - aug_p: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 19.7449 - d_loss: 6.9940 - aug_p: 2.5658e-05\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -116.5318 - d_loss: -36.4296 - aug_p: 0.0036\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -58.9571 - d_loss: -12.8435 - aug_p: 0.0027\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 17.6755 - d_loss: -4.8113 - aug_p: 0.0090\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -2563.0004 - d_loss: 1230.9512 - aug_p: 0.0050\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2176.4281 - d_loss: -1114.9945 - aug_p: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 30591.0105 - d_loss: 458.1576 - aug_p: 6.5789e-07\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 47323.9625 - d_loss: -2855.5705 - aug_p: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 6003.5071 - d_loss: 180.9172 - aug_p: 2.8947e-05\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 9464.4657 - d_loss: 1566.2916 - aug_p: 0.0034\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 97698.9862 - d_loss: -160.7449 - aug_p: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 42199.4145 - d_loss: -2084.7746 - aug_p: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 6091.2426 - d_loss: 84.8816 - aug_p: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 5695.1843 - d_loss: 685.2632 - aug_p: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1781.3815 - d_loss: 102.8991 - aug_p: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 9.5121 - d_loss: 9.8238 - aug_p: 6.8257e-04\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 5.3946 - d_loss: 6.7143 - aug_p: 0.0015\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -11.8169 - d_loss: 5.4494 - aug_p: 0.0015\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -420.4344 - d_loss: -26.4498 - aug_p: 0.0125\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -19834.6220 - d_loss: -481.6042 - aug_p: 0.0390\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -568.2433 - d_loss: 4.3547 - aug_p: 0.0529\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -176.5968 - d_loss: 13.8775 - aug_p: 0.0620\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 970.2400 - d_loss: 8.7787 - aug_p: 0.0078\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 4257.2311 - d_loss: 188.1175 - aug_p: 4.3388e-04\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -201.2224 - d_loss: -5.2593 - aug_p: 0.0026\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -607.1761 - d_loss: -0.9913 - aug_p: 0.0021\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -886.3941 - d_loss: -41.4804 - aug_p: 0.0233\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -639.8347 - d_loss: -12.4116 - aug_p: 0.0284\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -289.6681 - d_loss: 0.7732 - aug_p: 0.0037\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 214.8372 - d_loss: 7.8358 - aug_p: 0.0017\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 3239.1023 - d_loss: -22.6773 - aug_p: 4.7664e-04\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1679.0924 - d_loss: -33.7251 - aug_p: 0.0024\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 19453.2117 - d_loss: -268.9655 - aug_p: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 7310.9674 - d_loss: 439.1019 - aug_p: 0.0020\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 30.0174 - d_loss: 7.4877 - aug_p: 0.0172\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 285.4626 - d_loss: -6.7270 - aug_p: 0.0083\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 348.1280 - d_loss: 19.0145 - aug_p: 0.0015\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 3001.9143 - d_loss: -49.0969 - aug_p: 8.9474e-05\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 6504.0418 - d_loss: -162.0010 - aug_p: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 552.4808 - d_loss: -61.2708 - aug_p: 5.1316e-04\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 55552.9027 - d_loss: -7012.4158 - aug_p: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 279514.2825 - d_loss: -10986.5613 - aug_p: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 48511.3802 - d_loss: 402.7495 - aug_p: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 230619.1851 - d_loss: -8268.2589 - aug_p: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 59860.5383 - d_loss: 1300.6195 - aug_p: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 37056.3801 - d_loss: 2600.7262 - aug_p: 9.6711e-05\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -582.1103 - d_loss: -21.9377 - aug_p: 0.0157\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -44.1084 - d_loss: -3.2198 - aug_p: 0.0231\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1047.5276 - d_loss: 18.8650 - aug_p: 0.0013\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -3447.8374 - d_loss: -100.8478 - aug_p: 0.0137\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -1837.1684 - d_loss: -41.9590 - aug_p: 0.0293\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -5233.2129 - d_loss: -109.8605 - aug_p: 0.0383\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -416.8808 - d_loss: -30.2386 - aug_p: 0.0287\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -2491.1089 - d_loss: -57.6475 - aug_p: 0.0122\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -840.5105 - d_loss: -16.3778 - aug_p: 0.0247\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -9805.3980 - d_loss: 188.2878 - aug_p: 0.0306\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -468.3452 - d_loss: -77.3911 - aug_p: 0.0328\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -10203.8493 - d_loss: -187.9616 - aug_p: 0.0207\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1445.7968 - d_loss: -114.9149 - aug_p: 6.4605e-04\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1140.9096 - d_loss: -121.0943 - aug_p: 2.0428e-04\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -1584.9477 - d_loss: -201.2244 - aug_p: 0.0022\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 5954.1798 - d_loss: -490.4706 - aug_p: 3.9539e-04\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 33145.0205 - d_loss: 324.5450 - aug_p: 6.8750e-05\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 15727.5799 - d_loss: 708.5675 - aug_p: 8.9737e-04\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -200.7911 - d_loss: -10.3021 - aug_p: 0.0017\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -762.9531 - d_loss: -146.9348 - aug_p: 0.0013\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 45311.3672 - d_loss: 3392.5808 - aug_p: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -138998.5941 - d_loss: 65025.1240 - aug_p: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -171697.3465 - d_loss: 13659.4178 - aug_p: 0.0014\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1400.3178 - d_loss: 1175.7977 - aug_p: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2117.7412 - d_loss: 74.9478 - aug_p: 6.5789e-07\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 77.6515 - d_loss: 33.1510 - aug_p: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 905.8959 - d_loss: -11.7516 - aug_p: 6.5789e-07\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 330664.4605 - d_loss: 5932.3299 - aug_p: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 900811.0707 - d_loss: 91544.8136 - aug_p: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 2375065.5080 - d_loss: 1075382.9832 - aug_p: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 13043810.5897 - d_loss: 3838886.3205 - aug_p: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -8422693.7917 - d_loss: -1082248.6333 - aug_p: 3.1316e-04\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -45946312.1538 - d_loss: -1390022.1150 - aug_p: 0.0035\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -10799497.5769 - d_loss: 3275490.5497 - aug_p: 2.2270e-04\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -27097525.0769 - d_loss: 5293861.3045 - aug_p: 9.8684e-06\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 138s 4s/step - g_loss: 10198008.3590 - d_loss: 467769.3785 - aug_p: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1549202.4567 - d_loss: -102070.1856 - aug_p: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1320508.8746 - d_loss: 50045.7163 - aug_p: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -1187196.0699 - d_loss: -500753.3966 - aug_p: 1.3158e-06\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 681002.0361 - d_loss: 405210.3482 - aug_p: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 735.8477 - d_loss: 958.5299 - aug_p: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 0.3651 - d_loss: 9.9947 - aug_p: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -9.2537 - d_loss: 19.4737 - aug_p: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 38.9211 - d_loss: 23.9369 - aug_p: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 173.4295 - d_loss: -6.3279 - aug_p: 0.0015\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -68.0268 - d_loss: 21.3949 - aug_p: 0.0220\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -151.4668 - d_loss: -17.9235 - aug_p: 0.0306\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 9398.0442 - d_loss: 6199.8512 - aug_p: 6.5526e-04\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 527.5487 - d_loss: -264.0428 - aug_p: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 6.8341 - d_loss: -1.2716 - aug_p: 0.0050\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 9743.9471 - d_loss: 251.3669 - aug_p: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 6399.0267 - d_loss: 264.0746 - aug_p: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -948.8223 - d_loss: -58.4731 - aug_p: 0.0075\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -24930.3050 - d_loss: 410.6860 - aug_p: 0.0296\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -744.4887 - d_loss: 212.2014 - aug_p: 0.0365\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 242.0727 - d_loss: 0.5805 - aug_p: 0.0016\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 19487.6258 - d_loss: -1288.0326 - aug_p: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 11007.6460 - d_loss: 1420.8562 - aug_p: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1442.8522 - d_loss: -13.6465 - aug_p: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 496.3884 - d_loss: -0.2162 - aug_p: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 390.8536 - d_loss: 18.7308 - aug_p: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 5259.8965 - d_loss: -266.5470 - aug_p: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 37.7827 - d_loss: 9.9421 - aug_p: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 794.5688 - d_loss: 1.6764 - aug_p: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 769.8861 - d_loss: -9.3635 - aug_p: 8.1710e-04\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -1359.9004 - d_loss: -75.2348 - aug_p: 0.0095\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -507.4005 - d_loss: -31.7664 - aug_p: 0.0062\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -1412.0164 - d_loss: 117.5855 - aug_p: 0.0065\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -6987.4729 - d_loss: 125.2917 - aug_p: 0.0117\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -880.7863 - d_loss: 68.4628 - aug_p: 0.0110\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -18339.2615 - d_loss: -36.4820 - aug_p: 0.0246\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 10437.3604 - d_loss: 432.2191 - aug_p: 3.5526e-05\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 15562.1158 - d_loss: 450.9596 - aug_p: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -31.3844 - d_loss: 9.0192 - aug_p: 0.0025\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -1687.3012 - d_loss: 162.9985 - aug_p: 0.0257\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 54.8883 - d_loss: -19.2010 - aug_p: 0.0086\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1442.8330 - d_loss: -228.4331 - aug_p: 0.0062\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 57003.6020 - d_loss: 963.9658 - aug_p: 2.8322e-04\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -4171.1343 - d_loss: -130.7168 - aug_p: 0.0147\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -687.0734 - d_loss: 0.8959 - aug_p: 0.0344\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -202.9348 - d_loss: -5.5690 - aug_p: 0.0596\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -3335.0361 - d_loss: 327.7447 - aug_p: 0.0228\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -36229.4374 - d_loss: -1383.9339 - aug_p: 0.0249\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -102386.5467 - d_loss: 1835.5137 - aug_p: 0.0422\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -7574.5735 - d_loss: -442.1095 - aug_p: 0.0574\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -62.7539 - d_loss: 7.7066 - aug_p: 0.0057\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -129.6938 - d_loss: 17.0375 - aug_p: 8.5526e-06\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 764.6203 - d_loss: -1.9070 - aug_p: 1.9079e-05\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2263.7070 - d_loss: 1931.6928 - aug_p: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 3390.2396 - d_loss: -127.3480 - aug_p: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 1676.1454 - d_loss: 241.9661 - aug_p: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 11.8574 - d_loss: -15.8541 - aug_p: 0.0021\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -126.6682 - d_loss: -0.1212 - aug_p: 0.0183\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 162.1972 - d_loss: -32.9899 - aug_p: 3.5329e-04\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 140.9549 - d_loss: 118.4413 - aug_p: 0.0011\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 138s 4s/step - g_loss: -8638.2952 - d_loss: -1543.9063 - aug_p: 8.4211e-05\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -66050.0493 - d_loss: 5094.0130 - aug_p: 0.0028\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -209.8800 - d_loss: 14.0223 - aug_p: 0.0058\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2782.8628 - d_loss: 86.9900 - aug_p: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 13436.7250 - d_loss: -214.9490 - aug_p: 1.2829e-05\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 101.6214 - d_loss: -3.1242 - aug_p: 9.1447e-05\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 2066.6667 - d_loss: -33.1138 - aug_p: 3.7270e-04\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 1482.6776 - d_loss: -110.4822 - aug_p: 2.6645e-04\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 23650.5122 - d_loss: 504.8714 - aug_p: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1264.4872 - d_loss: -122.7935 - aug_p: 6.4474e-05\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -2047.1504 - d_loss: 49.9838 - aug_p: 0.0044\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -2925.8736 - d_loss: 210.0331 - aug_p: 0.0144\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 967.9704 - d_loss: -0.6444 - aug_p: 0.0021\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 26288.0275 - d_loss: 128.2174 - aug_p: 0.0017\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1086.6349 - d_loss: -33.0291 - aug_p: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 2579.2836 - d_loss: -80.1772 - aug_p: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 6841.8341 - d_loss: -19.5655 - aug_p: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 277.9940 - d_loss: -18.7598 - aug_p: 6.1579e-04\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -831.0410 - d_loss: -22.9955 - aug_p: 0.0107\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -12878.4309 - d_loss: 53.0377 - aug_p: 0.0367\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 1019.4575 - d_loss: -51.4195 - aug_p: 0.0091\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -44.5603 - d_loss: 73.7131 - aug_p: 7.8651e-04\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -259.6283 - d_loss: 50.1928 - aug_p: 0.0013\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 460.4549 - d_loss: -3.6633 - aug_p: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 460.9124 - d_loss: -15.0173 - aug_p: 0.0012\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -56.8297 - d_loss: 1.8017 - aug_p: 7.9210e-04\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 12110.5673 - d_loss: -919.9626 - aug_p: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 948.8099 - d_loss: -12.1086 - aug_p: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2340.4935 - d_loss: 136.1202 - aug_p: 1.0066e-04\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 479.6936 - d_loss: 80.6940 - aug_p: 2.6776e-04\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 5313.4672 - d_loss: 32.7386 - aug_p: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 137561.3102 - d_loss: -2857.5578 - aug_p: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 27134.8359 - d_loss: -537.3744 - aug_p: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 40195.9478 - d_loss: -765.4686 - aug_p: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 8539497.2057 - d_loss: -17289.0245 - aug_p: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 3777805.4519 - d_loss: -6967.2648 - aug_p: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2336.1344 - d_loss: 161.8303 - aug_p: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 6.4666 - d_loss: 9.9313 - aug_p: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 166.8270 - d_loss: -0.1876 - aug_p: 4.6151e-04\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -327.1877 - d_loss: -7.7082 - aug_p: 0.0118\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 386.3539 - d_loss: -7.0632 - aug_p: 3.1579e-05\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 413.4955 - d_loss: -3.0432 - aug_p: 5.5263e-04\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -546.9827 - d_loss: -6.2024 - aug_p: 0.0175\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -26.4038 - d_loss: 11.3134 - aug_p: 0.0076\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -306.1105 - d_loss: -5.8908 - aug_p: 0.0134\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -995.2656 - d_loss: -31.6616 - aug_p: 0.0100\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -1685.7469 - d_loss: -23.8134 - aug_p: 0.0128\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1516.6148 - d_loss: -50.0901 - aug_p: 9.3224e-04\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -12435.4608 - d_loss: 371.6949 - aug_p: 0.0123\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -135.7716 - d_loss: -7.2281 - aug_p: 0.0173\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 102.8409 - d_loss: 10.5548 - aug_p: 1.6546e-04\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 275.4077 - d_loss: -47.0323 - aug_p: 0.0020\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 911.5943 - d_loss: 30.2632 - aug_p: 4.4901e-04\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -416.3962 - d_loss: 1.1069 - aug_p: 0.0096\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -7002.8622 - d_loss: -123.1536 - aug_p: 0.0375\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -690.1588 - d_loss: 4.9936 - aug_p: 0.0660\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -863.5354 - d_loss: -10.6996 - aug_p: 0.0829\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -981.0355 - d_loss: 3.2691 - aug_p: 0.1088\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 4070.4933 - d_loss: -65.4865 - aug_p: 0.0534\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 278022.6006 - d_loss: -4746.8800 - aug_p: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 165761.5212 - d_loss: -1669.8853 - aug_p: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 530.5506 - d_loss: 1.2806 - aug_p: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -9.0216 - d_loss: 6.1169 - aug_p: 0.0024\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -354.2549 - d_loss: 16.4855 - aug_p: 7.0460e-04\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 948.7660 - d_loss: -59.0218 - aug_p: 4.5757e-04\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -668.8217 - d_loss: -26.8441 - aug_p: 0.0060\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 7082.8100 - d_loss: 56.9143 - aug_p: 6.7763e-04\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 126967.9875 - d_loss: 2710.3973 - aug_p: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 39299.2551 - d_loss: -1115.1928 - aug_p: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 69396.1416 - d_loss: 1275.7278 - aug_p: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 6352211.2853 - d_loss: -124011.8413 - aug_p: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 3376103.4103 - d_loss: -334102.1486 - aug_p: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 4598303.6154 - d_loss: -80394.9915 - aug_p: 5.2632e-05\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -2.3652 - d_loss: 9.9641 - aug_p: 0.0076\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 139.7161 - d_loss: 12.1721 - aug_p: 0.0012\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -4.3819 - d_loss: 9.9262 - aug_p: 1.2829e-05\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -6.0941 - d_loss: 12.3076 - aug_p: 0.0014\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -123.3111 - d_loss: -40.1637 - aug_p: 0.0111\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -301.3165 - d_loss: 24.5245 - aug_p: 0.0039\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -380.4964 - d_loss: 7.7556 - aug_p: 0.0070\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -631.9584 - d_loss: -41.9733 - aug_p: 0.0013\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 904.7688 - d_loss: -211.2469 - aug_p: 1.8750e-05\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 673017.2965 - d_loss: 5860.1180 - aug_p: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 279265.4042 - d_loss: 11850.5905 - aug_p: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2754.3930 - d_loss: -22.4293 - aug_p: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 38.6117 - d_loss: 0.2775 - aug_p: 0.0043\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -203.8656 - d_loss: 16.3032 - aug_p: 0.0210\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 880.1443 - d_loss: -25.9043 - aug_p: 2.4342e-05\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -460.5228 - d_loss: 16.4664 - aug_p: 0.0084\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -25291.6246 - d_loss: 492.6066 - aug_p: 0.0185\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 12476.2706 - d_loss: -326.3006 - aug_p: 1.1842e-05\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 744.3751 - d_loss: 50.9634 - aug_p: 7.4013e-05\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 23458.4975 - d_loss: -185.7651 - aug_p: 2.0230e-04\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 3309.8280 - d_loss: -70.4576 - aug_p: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 194.0262 - d_loss: -33.0015 - aug_p: 0.0027\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -5497.0342 - d_loss: 117.3051 - aug_p: 0.0109\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1600.0361 - d_loss: -1.7955 - aug_p: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 934.4271 - d_loss: 9.0590 - aug_p: 0.0037\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 14749.7988 - d_loss: 194.9483 - aug_p: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 4.5915 - d_loss: 36.5403 - aug_p: 0.0066\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 713.9461 - d_loss: 62.3529 - aug_p: 6.6151e-04\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 1716.2715 - d_loss: 58.9195 - aug_p: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -98.1763 - d_loss: 17.1369 - aug_p: 0.0034\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -251.6977 - d_loss: -29.1220 - aug_p: 0.0148\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 272.6326 - d_loss: -16.3151 - aug_p: 0.0051\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 1059.1709 - d_loss: -38.5934 - aug_p: 2.8586e-04\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 107.0991 - d_loss: -8.0380 - aug_p: 0.0011\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -7268.9835 - d_loss: -1284.9061 - aug_p: 7.1086e-04\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -255077.0561 - d_loss: -40821.3276 - aug_p: 2.9605e-06\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1715.4857 - d_loss: 3149.3363 - aug_p: 1.9737e-06\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 130.1730 - d_loss: -49.9752 - aug_p: 1.3158e-06\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -153.7089 - d_loss: 23.5372 - aug_p: 8.2895e-05\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 763.3699 - d_loss: -60.5629 - aug_p: 0.0020\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 181.0292 - d_loss: -29.1163 - aug_p: 1.7533e-04\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 88226.9012 - d_loss: -21048.4690 - aug_p: 1.1678e-04\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -198970.8434 - d_loss: -146948.2633 - aug_p: 4.7039e-05\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -469.2351 - d_loss: -66.5364 - aug_p: 9.3421e-05\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 4379.2201 - d_loss: 382.7015 - aug_p: 2.9605e-06\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2284.1573 - d_loss: -29.3434 - aug_p: 1.4539e-04\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 3691.8358 - d_loss: -37.5817 - aug_p: 3.6447e-04\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -178.6699 - d_loss: -37.1389 - aug_p: 8.3750e-04\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -22086.8786 - d_loss: 154.0541 - aug_p: 0.0181\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -66267.7626 - d_loss: 263.7326 - aug_p: 0.0466\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -661933.5329 - d_loss: -9625.5418 - aug_p: 0.0751\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -16692.6633 - d_loss: 127.0271 - aug_p: 0.1036\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -30856.4110 - d_loss: -129.4069 - aug_p: 0.1320\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -35980.7836 - d_loss: -575.8416 - aug_p: 0.1605\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -12536.3182 - d_loss: 1487.7121 - aug_p: 0.1890\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -29892.7543 - d_loss: -22.8684 - aug_p: 0.2175\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -30779.7907 - d_loss: 225.7046 - aug_p: 0.2460\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -26959.3612 - d_loss: 815.6218 - aug_p: 0.2745\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -42416.1396 - d_loss: 1879.0656 - aug_p: 0.3020\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -2327929.1667 - d_loss: 2404.4841 - aug_p: 0.3303\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -164423.1751 - d_loss: -2111.6831 - aug_p: 0.3565\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -20771.1413 - d_loss: 131.1049 - aug_p: 0.3808\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 138s 4s/step - g_loss: -9517.9220 - d_loss: 1041.4973 - aug_p: 0.3960\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -11652.0652 - d_loss: -692.0841 - aug_p: 0.3939\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -95.8371 - d_loss: -8.6061 - aug_p: 0.3717\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -13.6828 - d_loss: 10.2605 - aug_p: 0.3339\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -43875.1880 - d_loss: -880.2975 - aug_p: 0.3098\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: -114920.3337 - d_loss: 5061.2644 - aug_p: 0.2993\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -16715.5673 - d_loss: 9204.7546 - aug_p: 0.2569\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -87267.8159 - d_loss: -23005.0654 - aug_p: 0.2019\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -2763.9972 - d_loss: 622.4006 - aug_p: 0.1515\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1.4861 - d_loss: 12.6997 - aug_p: 0.0965\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -151.4874 - d_loss: 11.1914 - aug_p: 0.1039\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1249.0012 - d_loss: -21.3755 - aug_p: 0.1235\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -801.1085 - d_loss: -8.4379 - aug_p: 0.1341\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1763.9326 - d_loss: -13.4587 - aug_p: 0.1569\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1855.3151 - d_loss: 54.8819 - aug_p: 0.1854\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -2387.0416 - d_loss: -65.6985 - aug_p: 0.2139\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -3213.3499 - d_loss: -7.8139 - aug_p: 0.2424\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -1125.9028 - d_loss: -10.7697 - aug_p: 0.2709\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1761.5801 - d_loss: -84.3076 - aug_p: 0.2988\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -557.5023 - d_loss: -40.2714 - aug_p: 0.3164\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 543.8736 - d_loss: -14.9210 - aug_p: 0.2393\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 6766.5512 - d_loss: -39.4520 - aug_p: 0.1685\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -1325.6644 - d_loss: -34.3946 - aug_p: 0.1143\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -15146.4519 - d_loss: -129.7022 - aug_p: 0.1119\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -10789.1846 - d_loss: -453.9889 - aug_p: 0.1392\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -12936.3009 - d_loss: -137.6285 - aug_p: 0.1582\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -6550.5451 - d_loss: 140.3223 - aug_p: 0.1769\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 56029.1247 - d_loss: 87.8653 - aug_p: 0.1090\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1567.9794 - d_loss: -86.3871 - aug_p: 0.0028\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 7822.9445 - d_loss: 202.6028 - aug_p: 7.6941e-04\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 19100.0107 - d_loss: -673.5784 - aug_p: 8.0230e-04\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 11085729.5192 - d_loss: -96252.4296 - aug_p: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2193902.5641 - d_loss: -7233.4442 - aug_p: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 540222.6623 - d_loss: 5106.9286 - aug_p: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 2315.5887 - d_loss: -18.4955 - aug_p: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 122120.8165 - d_loss: -1022.5437 - aug_p: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 709356.8986 - d_loss: 3666.9808 - aug_p: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 20393217.1795 - d_loss: 269170.4887 - aug_p: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 7773706.0641 - d_loss: -236398.5992 - aug_p: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 5668633.8654 - d_loss: -55992.3078 - aug_p: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 399837.2650 - d_loss: 8378.8446 - aug_p: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2122012.4920 - d_loss: -32713.5393 - aug_p: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 2563181.8558 - d_loss: 26415.1159 - aug_p: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 10227921.3077 - d_loss: 147659.8563 - aug_p: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 36508888.3333 - d_loss: 171020.6791 - aug_p: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 74119367.7949 - d_loss: 653962.3397 - aug_p: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 36472667.6022 - d_loss: 635379.4796 - aug_p: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 74188313.7436 - d_loss: 1342908.0573 - aug_p: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 43064.9110 - d_loss: 9964.6723 - aug_p: 2.6447e-04\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -5.9087 - d_loss: 33.2850 - aug_p: 0.0020\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -2.0657 - d_loss: -4.2444 - aug_p: 0.0035\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -9260.3546 - d_loss: -226.5697 - aug_p: 0.0125\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -33444.1227 - d_loss: -1722.0611 - aug_p: 0.0396\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -12684.7552 - d_loss: -88.4912 - aug_p: 0.0644\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -66.2285 - d_loss: 24.2401 - aug_p: 0.0747\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -40.0252 - d_loss: 15.6288 - aug_p: 0.0557\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -0.7228 - d_loss: 16.7184 - aug_p: 0.0061\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -10.5919 - d_loss: -0.3496 - aug_p: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 210.6966 - d_loss: 48.7859 - aug_p: 0.0016\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -534.9021 - d_loss: -26.1965 - aug_p: 0.0216\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: -11998.0129 - d_loss: -183.0274 - aug_p: 0.0340\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2213.4600 - d_loss: -374.1883 - aug_p: 0.0215\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 2182.1089 - d_loss: 50.0496 - aug_p: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 734.0032 - d_loss: -6.0868 - aug_p: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 36029.5823 - d_loss: 1210.6947 - aug_p: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 34326.1626 - d_loss: 1252.7656 - aug_p: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 32414.2553 - d_loss: -2824.2250 - aug_p: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 11350.7935 - d_loss: 2216.8647 - aug_p: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 245.4804 - d_loss: 12.1436 - aug_p: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 438.0772 - d_loss: 15.1696 - aug_p: 2.7303e-05\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 499.7651 - d_loss: -15.5211 - aug_p: 2.5822e-04\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -897.3178 - d_loss: 306.9147 - aug_p: 0.0041\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2986.7309 - d_loss: -37.0237 - aug_p: 1.5329e-04\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 63431.8812 - d_loss: 2834.5617 - aug_p: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 40522.3243 - d_loss: -1957.7807 - aug_p: 5.6349e-04\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: -389.0096 - d_loss: 61.9059 - aug_p: 5.5131e-04\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -6566.1517 - d_loss: -809.2036 - aug_p: 0.0021\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -76.9126 - d_loss: -23.8598 - aug_p: 3.7138e-04\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 70.7278 - d_loss: 0.8988 - aug_p: 0.0052\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1034.1295 - d_loss: -81.9644 - aug_p: 4.1480e-04\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 126.8683 - d_loss: -6.7525 - aug_p: 0.0039\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 225.5132 - d_loss: -15.6979 - aug_p: 2.3487e-04\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -5059.3762 - d_loss: 33.5765 - aug_p: 0.0098\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -3107.5248 - d_loss: 208.4270 - aug_p: 0.0028\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2085.1488 - d_loss: 1780.9421 - aug_p: 7.9605e-05\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 5137.0153 - d_loss: 241.7226 - aug_p: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 17814.9880 - d_loss: -1344.9380 - aug_p: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 851.1928 - d_loss: 115.7599 - aug_p: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 2015.3248 - d_loss: 74.4535 - aug_p: 4.7697e-05\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 416.9745 - d_loss: 22.4518 - aug_p: 1.0888e-04\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 319.0998 - d_loss: 14.8227 - aug_p: 6.5789e-07\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 937.8126 - d_loss: -40.4804 - aug_p: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 44644.5556 - d_loss: 371.3202 - aug_p: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 685674.7829 - d_loss: 36965.8707 - aug_p: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 246010.9395 - d_loss: 6631.7210 - aug_p: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 15117.9817 - d_loss: 671.4646 - aug_p: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 4151.3474 - d_loss: 338.3723 - aug_p: 1.9868e-04\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 104.0386 - d_loss: 8.9589 - aug_p: 0.0021\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 64.1947 - d_loss: 5.0395 - aug_p: 3.5526e-05\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 123.8321 - d_loss: 1.5196 - aug_p: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 2065.0950 - d_loss: 4.9272 - aug_p: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1898.3982 - d_loss: 337.4773 - aug_p: 4.5625e-04\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -219.1741 - d_loss: -0.6384 - aug_p: 0.0130\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 485.2733 - d_loss: -26.9947 - aug_p: 3.2237e-04\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: -404.2230 - d_loss: -40.6509 - aug_p: 0.0042\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -2399.9645 - d_loss: 3.3702 - aug_p: 0.0188\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -2362.4628 - d_loss: -53.7569 - aug_p: 0.0471\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -48485.7804 - d_loss: -1145.0666 - aug_p: 0.0744\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1542.0471 - d_loss: -10.8321 - aug_p: 0.0827\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 405.9257 - d_loss: -12.1122 - aug_p: 0.0027\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 1447.2230 - d_loss: -3.8937 - aug_p: 3.9474e-06\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 2930.6003 - d_loss: 1431.1143 - aug_p: 6.6776e-05\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 22934.8810 - d_loss: -70.9553 - aug_p: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 4036.4461 - d_loss: -149.2138 - aug_p: 1.8421e-04\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 429.6099 - d_loss: 17.5801 - aug_p: 2.6645e-04\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 3068.1689 - d_loss: -2.0550 - aug_p: 3.3224e-05\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 8963.1129 - d_loss: 2611.6093 - aug_p: 7.2138e-04\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 476.1114 - d_loss: 286.7432 - aug_p: 4.6053e-06\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 4.0859 - d_loss: 2.2571 - aug_p: 5.8224e-05\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 131s 3s/step - g_loss: 4568.3012 - d_loss: 303.8715 - aug_p: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 137s 4s/step - g_loss: 99443.0600 - d_loss: -1566.8878 - aug_p: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 525451.9159 - d_loss: -32115.1898 - aug_p: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1018.9518 - d_loss: 181.8490 - aug_p: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 38.2504 - d_loss: 21.0128 - aug_p: 0.0027\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 444.1813 - d_loss: 14.6487 - aug_p: 1.5592e-04\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 403.6278 - d_loss: 83.5522 - aug_p: 0.0019\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: -461.9916 - d_loss: -16.2787 - aug_p: 2.9276e-05\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 299.0614 - d_loss: 31.6833 - aug_p: 6.4474e-05\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -1230.1662 - d_loss: -44.7182 - aug_p: 0.0119\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -1224.5543 - d_loss: -26.5707 - aug_p: 0.0154\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 563.5503 - d_loss: 43.4256 - aug_p: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 269.0841 - d_loss: 12.8769 - aug_p: 9.5724e-05\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 244.6695 - d_loss: 17.4389 - aug_p: 4.6711e-05\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 1830.4235 - d_loss: 52.8669 - aug_p: 4.7961e-04\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 2156.4316 - d_loss: 96.2644 - aug_p: 0.0011\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 33020.7639 - d_loss: 620.6748 - aug_p: 0.0013\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 52486.6353 - d_loss: 17.3539 - aug_p: 0.0032\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 607.4659 - d_loss: -85.2530 - aug_p: 5.9803e-04\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 2518.7843 - d_loss: -90.5152 - aug_p: 2.0757e-04\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: -176.1629 - d_loss: 6.4868 - aug_p: 0.0024\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 1549.2087 - d_loss: 131.7623 - aug_p: 0.0036\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 23163.5600 - d_loss: 20.3053 - aug_p: 3.9474e-06\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 3034.1492 - d_loss: 346.5999 - aug_p: 7.2368e-06\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 1688.6086 - d_loss: -171.0777 - aug_p: 1.0789e-04\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 5916.9457 - d_loss: -188.1125 - aug_p: 5.5592e-05\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 1489679.1186 - d_loss: -782.0710 - aug_p: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 3127859.6635 - d_loss: -99299.8171 - aug_p: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 401269.3858 - d_loss: 23549.7581 - aug_p: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 5598.8136 - d_loss: 121.5405 - aug_p: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 24085.0717 - d_loss: 123.9675 - aug_p: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 136s 4s/step - g_loss: 22572.4367 - d_loss: 509.7140 - aug_p: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 5972.7005 - d_loss: -8.6371 - aug_p: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 4494.4271 - d_loss: -171.2507 - aug_p: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 19611.3908 - d_loss: 345.5602 - aug_p: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 96247.3095 - d_loss: -4039.9423 - aug_p: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 135s 4s/step - g_loss: 354841.4715 - d_loss: 10386.8170 - aug_p: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 483504.2930 - d_loss: -11077.6434 - aug_p: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 73895611.0769 - d_loss: -251973.4187 - aug_p: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 109023458.2564 - d_loss: -3610756.8055 - aug_p: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 202709624.8205 - d_loss: 1430811.1388 - aug_p: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 270296004.1026 - d_loss: 14104428.0449 - aug_p: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: 116151844.5128 - d_loss: -4680850.1026 - aug_p: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: 13047792.2692 - d_loss: 5794245.3205 - aug_p: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 132s 3s/step - g_loss: -3425.5328 - d_loss: 976.2929 - aug_p: 6.5789e-07\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 222.7841 - d_loss: 42.6961 - aug_p: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 138s 4s/step - g_loss: 1613.1556 - d_loss: -79.2941 - aug_p: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 133s 3s/step - g_loss: 42.3052 - d_loss: 43.7487 - aug_p: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 133s 4s/step - g_loss: 8.2609 - d_loss: 3.6138 - aug_p: 6.5197e-04\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 134s 4s/step - g_loss: -108.2897 - d_loss: -1.8406 - aug_p: 0.0071\n",
            "Epoch 634/1000\n",
            " 7/38 [====>.........................] - ETA: 1:51 - g_loss: -1154.3923 - d_loss: -13.3255 - aug_p: 0.0225"
          ]
        }
      ],
      "source": [
        "cond_gan.fit(dataset, epochs=1000,steps_per_epoch=38,callbacks=[callback,csv_logger]) #aprox 1000 epochs trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyPdKjz0wcX3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(False)\n",
        "a=np.random.randint(0,10000,32)\n",
        "a=np.array(a,dtype=np.float32)\n",
        "print(a)\n",
        "\n",
        "reduce_mean=tf.reduce_mean(0.5 * (1.0+tf.sign([a]))) \n",
        "print(reduce_mean,'reduce mean' )\n",
        "accuracy_error=reduce_mean-0.85\n",
        "print(accuracy_error,'accuracy_error' )\n",
        "# b=tf.metrics.Mean(name='mean')\n",
        "# b.update_state(a)\n",
        "# b.result()\n",
        "c=tf.clip_by_value(0.3016499998+ accuracy_error / 1000, 0.0, 1.0)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xvIE8YI1nNk"
      },
      "outputs": [],
      "source": [
        "augmentation_values = tf.random.uniform(\n",
        "                shape=(32, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "            )\n",
        "print(augmentation_values)\n",
        "augmentation_bools = tf.math.less(augmentation_values,c)\n",
        "print(augmentation_bools)\n",
        "\n",
        "tf.where(augmentation_bools, 100, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUEsuRlhPTzk"
      },
      "outputs": [],
      "source": [
        "# count=0\n",
        "# for i in range(1,301):\n",
        "#   print(i*divide_array)\n",
        "#   if np.any(i%divide_array==0):\n",
        "#     count+=1\n",
        "# print(count,(count/300)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocvWObYiPeZ1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTYAUD2pftqL"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/GAN GENERATED/log.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwtjnwtnlmdJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.drop('epoch',inplace=True,axis=1)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtgsWalZmGMH"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(df['gen'])\n",
        "\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['gen'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(df['dis'])\n",
        "\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['dis'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufFEVQGfgApJ"
      },
      "outputs": [],
      "source": [
        "a=df['epoch']\n",
        "for i,j in enumerate(a[546:]):\n",
        "  df['epoch'][544+i]=544.0+i\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDpNgYnOiDEZ"
      },
      "outputs": [],
      "source": [
        "df['epoch'][543:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e9u0r7UjQ9s"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/GAN GENERATED/log.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "CWGAN_refined.ipynb",
      "provenance": [],
      "mount_file_id": "1TKeUP2zQLC37_Qm-mOmJjNU1RvT_Xrg8",
      "authorship_tag": "ABX9TyMiWR06LT6aBy11vtuxA4+o",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}