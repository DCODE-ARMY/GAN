{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " darshan_mainFrame.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCODE-ARMY/GAN/blob/3DCNN/darshan_mainFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3thPIvOhTAZj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFgBae2ZBZ1Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeHkJrRo-YGl"
      },
      "source": [
        "# Abuse028_x264.mp4  Abuse  165  240  -1  -1  \n",
        "# Abuse030_x264.mp4  Abuse  1275  1360  -1  -1  \n",
        "# Arrest001_x264.mp4  Arrest  1185  1485  -1  -1  \n",
        "# Arrest007_x264.mp4  Arrest  1530  2160  -1  -1  \n",
        "# Arrest024_x264.mp4  Arrest  1005  3105  -1  -1  \n",
        "# Arrest030_x264.mp4  Arrest  5535  7200  -1  -1  \n",
        "# Arrest039_x264.mp4  Arrest  7215  10335  -1  -1  \n",
        "\n",
        "# Arson009_x264.mp4  Arson  220  315  -1  -1  \n",
        "# Arson010_x264.mp4  Arson  885  1230  -1  -1  \n",
        "# Arson011_x264.mp4  Arson  150  420  680  1267  \n",
        "# Arson016_x264.mp4  Arson  1000  1796  -1  -1  \n",
        "# Arson018_x264.mp4  Arson  270  600  -1  -1  \n",
        "\n",
        "# Arson035_x264.mp4  Arson  600  900  -1  -1  \n",
        "\n",
        "# Assault006_x264.mp4  Assault  1185  8096  -1  -1  \n",
        "# Assault010_x264.mp4  Assault  11330  11680  12260  12930"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxCjc42eu8sI"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdHwN-o5fA6B"
      },
      "source": [
        "# ['Arson009_x264.mp4',\n",
        "#  'Arson018_x264.mp4',\n",
        "#  'Arson016_x264.mp4',\n",
        "#  'Abuse028_x264.mp4',\n",
        "#  'Abuse030_x264.mp4',\n",
        "#  'Arson011_x264.mp4',\n",
        "#  'Normal_Videos_360_x264.mp4',\n",
        "#  'Normal_Videos_914_x264.mp4',\n",
        "#  'arrest007-x264_ldZ38wMI_vvBC.mp4',\n",
        "#  'Arrest001_x264.mp4',\n",
        "#  'Arrest024_x264.mp4',\n",
        "#  'Arrest030_x264.mp4',\n",
        "#  'Arrest039_x264.mp4',\n",
        "#  'Assault006_x264.mp4',\n",
        "#  'Assault010_x264.mp4',\n",
        "#  'arson010-x264_KMoffemL_vahT.mp4',\n",
        "#  'arson035-x264_OXD2FVDS_6e8U.mp4']\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeBhMljQeDqi"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWQP2x4OT6au"
      },
      "source": [
        "# # the integer values for the get() function\n",
        "#   cv::CAP_PROP_POS_MSEC =0,\n",
        "#   cv::CAP_PROP_POS_FRAMES =1,\n",
        "#   cv::CAP_PROP_POS_AVI_RATIO =2,\n",
        "#   cv::CAP_PROP_FRAME_WIDTH =3,\n",
        "#   cv::CAP_PROP_FRAME_HEIGHT =4,\n",
        "#   cv::CAP_PROP_FPS =5,\n",
        "#   cv::CAP_PROP_FOURCC =6,\n",
        "#   cv::CAP_PROP_FRAME_COUNT =7,\n",
        "#   cv::CAP_PROP_FORMAT =8,\n",
        "#   cv::CAP_PROP_MODE =9,"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcf_wmtdO3e4"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM7Fa9-QcPD"
      },
      "source": [
        "# !wget -O /bin/data/Anomaly-Videos-Part-1.zip \"https://uce6b85d399116cca469b88611cd.dl.dropboxusercontent.com/cd/0/get/BK8zNXUi_AG54RgTMjiE45MQxtVltgTFo0tBxoz0N_ramFgpYRnn4dEQx6NJwLSBE1m8qRDySClFziDgpT_UEJXXF27pqvQ8X2deu_0XWahO4aZbkzZgof1sI1ljMeNueO2dYkg6LTIHLXJU0wLTqjnE/file?_download_id=4557435652575734982252352094408618977674127408532000794491165885&_notify_domain=www.dropbox.com&dl=1\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewk90wnG88WU"
      },
      "source": [
        "# !wget -O /bin/data/Normal_vids.zip \"https://uc4c3ade6d9cad2e8a98fa2c1221.dl.dropboxusercontent.com/cd/0/get/BK8XoVncGfI4vBlvISquSh7qS5tA5W-aLnJp-Ckt-Ilg47hOk_MfyuA35P1S_zYgqZZUEzma6SErj5EixLCGAFdeMUIjwv-k9sGlDxfPEuXko4N_9KXnjvUPIGwiOeTX5Dh7WPYiWhYK_-2urRrLHuF0/file?_download_id=5365242495127689218169027975862853839888765030923789802636200086&_notify_domain=www.dropbox.com&dl=1\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g39GyAnY9WE5"
      },
      "source": [
        "# !unzip - /bin/data/Anomaly-Videos-Part-1.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r033yzl08_ls"
      },
      "source": [
        "# !unzip /bin/data/Normal_vids.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZau0EDFW7Dd"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "# def s(files_list=files_list[0][1]):\n",
        "#     yield files_list\n",
        "# s_gen=s()\n",
        "# dataset=tf.data.Dataset.from_generator(s,tf.string).repeat(count=2)\n",
        "\n",
        "\n",
        "# for i in dataset:\n",
        "#   print(i)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQAnjKMeARcI"
      },
      "source": [
        "# print(files_list[1][1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzS930JBvrQR"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO6Vve8KsGpT"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "# from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=256\n",
        "train_data_dir='/content/drive/MyDrive/crime detection/train'\n",
        "categories=['arrest', 'arson', 'abuse', 'Normal', 'assault']\n",
        "test_data_dir='/content/drive/MyDrive/crime detection/test'\n",
        "batch_size=32\n",
        "temporal_length=30\n",
        "stride=15\n",
        "channel_axis=temporal_length\n",
        "repeat=1500"
      ],
      "metadata": {
        "id": "iv_ncKw5BYuW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF8pgRw__4lO",
        "outputId": "98814b97-2c7e-4789-c1f8-d2e8ef36fe75"
      },
      "source": [
        "#getting list of videos\n",
        "import os \n",
        "global files_list\n",
        "temp_files_list=[]\n",
        "\n",
        "print(os.listdir(train_data_dir))\n",
        "\n",
        "for i in categories:\n",
        "  temp_files_list.append(os.listdir(train_data_dir+'/{}'.format(i)))\n",
        "\n",
        "print([len(temp_files_list[i]) for i in range(5)])\n",
        "\n",
        "#changing files names to directory name\n",
        "\n",
        "\n",
        "for i in range(len(categories)):\n",
        "\n",
        "  for k in range(len(temp_files_list[i])):\n",
        "    temp_files_list[i][k] =train_data_dir+\"/{}/{}\".format(categories[i],temp_files_list[i][k])\n",
        "\n",
        "#len of all videos \n",
        "print([len(temp_files_list[i]) for i in range(5)])\n",
        "\n",
        "#changing categories to single list\n",
        "files_list=[]\n",
        "\n",
        "for i in range(len(temp_files_list)):\n",
        "  for j in range(len(temp_files_list[i])):\n",
        "    files_list.append(temp_files_list[i][j])    \n",
        "len(files_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arrest', 'arson', 'abuse', 'Normal', 'assault']\n",
            "[42, 36, 27, 41, 31]\n",
            "[42, 36, 27, 41, 31]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SevE_Wo6c5Vk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSG0dLmxdcGD"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# getting test videos name\n",
        "test_files=[]\n",
        "for i in os.listdir(test_data_dir):\n",
        "  test_files.append(i)\n",
        "\n",
        "\n",
        "\n",
        "# getting test video path \n",
        "for i in range(len(test_files)):\n",
        "  test_files[i]=test_data_dir+\"/{}\".format(test_files[i])\n",
        "\n",
        "# print(len(test_files))\n",
        "# test_files\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r3aMyLmU5H0X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Qo8l5BSthl"
      },
      "source": [
        "import collections\n",
        "import copy\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\"\"\"manualy shuffling data for epoch since using custom generator and also the bulit in gen wont shuffle first.\n",
        "it splits the data first and then at the end of every epoch it shuffles\"\"\"\n",
        "files_list=shuffle(files_list)\n",
        "\n",
        "def gen(data=files_list,temporal_lenght=temporal_length,temporal_stride=stride,batch_size=batch_size):  \n",
        "  chunk_frames=[]\n",
        "  batch_count=0\n",
        "  queue=collections.deque()\n",
        "  label=collections.deque()\n",
        "  ch=0 #check var\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    frame_count=0 #to check enough frames are available to append in queue\n",
        "    chunk_frames.clear() # batch list \n",
        "    queue.clear() # frame queue\n",
        "    label.clear() # lable queue\n",
        "    batch_count=0 #when new video starts the batch begins form Zero\n",
        "    lable_list=[0,0,0,0,0]#for labeling \n",
        "    \n",
        "    cap=cv2.VideoCapture(data[i])\n",
        "    total_frames=int(cap.get(7))\n",
        "\n",
        "    for k in range(total_frames):\n",
        "      \n",
        "      if total_frames-frame_count >=temporal_lenght:\n",
        "\n",
        "        if len(queue) != temporal_lenght:\n",
        "          img=cap.read()[1]\n",
        "          img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "          img=img.astype(np.float32)\n",
        "\n",
        "          img=tf.keras.layers.Resizing(image_size,image_size,interpolation='gaussian',crop_to_aspect_ratio=False)(img)\n",
        "          img = tf.keras.layers.Rescaling(scale=1./255)(img)\n",
        "\n",
        "          if np.ndarray.all((np.array(img) == 0)):\n",
        "            pass\n",
        "            # print(\"zero\",data[i])\n",
        "\n",
        "          elif np.isnan(np.sum(img)):\n",
        "            print('nan',data[i])\n",
        "\n",
        "          elif np.any(np.isnan(img)):\n",
        "            print('nan 2')\n",
        "\n",
        "          elif np.any(np.isinf(img)):\n",
        "            print('inf')\n",
        "        \n",
        "          else:\n",
        "            queue.append(img)\n",
        "            frame_count+=1\n",
        "\n",
        "        if len(queue) == temporal_length:  \n",
        "# ['arrest','abuse','Normal','arson','assault']\n",
        "          chunk_frames.append(np.array(queue,ndmin=4))\n",
        "          #txt=['arrest', 'arson', 'abuse', 'Normal', 'assault']\n",
        "          #use split to get catrgory and use index to replace 0 with 1\n",
        "          if 'arrest' in data[i]:\n",
        "            lable_list.pop(0)\n",
        "            lable_list.insert(0,1)\n",
        "            label.append(lable_list) \n",
        "      \n",
        "        \n",
        "          if 'arson' in data[i]:\n",
        "            lable_list.pop(1)\n",
        "            lable_list.insert(1,1)\n",
        "            label.append(lable_list)\n",
        "            \n",
        "          if 'abuse' in data[i]:\n",
        "            lable_list.pop(2)\n",
        "            lable_list.insert(2,1)\n",
        "            label.append(lable_list) \n",
        "                        \n",
        "          if 'Normal' in data[i]:\n",
        "            lable_list.pop(3)\n",
        "            lable_list.insert(3,1)\n",
        "            label.append(lable_list)\n",
        "\n",
        "          if 'assault' in data[i]:\n",
        "            lable_list.pop(4)\n",
        "            lable_list.insert(4,1)\n",
        "            label.append(lable_list)\n",
        "\n",
        "        \n",
        "\n",
        "          batch_count+=1\n",
        "          for stride in range(temporal_stride):\n",
        "            queue.popleft()          \n",
        "            \n",
        "        if batch_count == batch_size:\n",
        "          chunk_frames=shuffle(chunk_frames)  \n",
        "          batch_return=np.array(chunk_frames)\n",
        "          label_return=np.reshape(np.array(label,ndmin=2),(32,5))         \n",
        "                  \n",
        "          yield  batch_return, label_return\n",
        "          \n",
        "          batch_count=0\n",
        "          label.clear()\n",
        "          chunk_frames.clear()\n",
        "          batch_return=0\n",
        "          label_return=0\n",
        "\n",
        "\n",
        "      else:\n",
        "        batch_count=0\n",
        "        continue\n",
        "    cap.release()\n",
        "\n",
        "\n",
        "gen_data=tf.data.Dataset.from_generator(gen, output_signature=(tf.TensorSpec(shape=(batch_size, temporal_length,image_size, image_size, 3),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(batch_size,5),dtype=tf.dtypes.int8) ))\n",
        "gen_data=gen_data.prefetch(buffer_size=tf.data.AUTOTUNE).repeat(repeat)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGCW9AJExkI"
      },
      "source": [
        "val_tuple=[(220,315),(270,600),(1000,1796),(165,240),(1275,1360),(680,1267),(1,984),(1,880),(1185,1485),(1005,3105),(5535,7200),(7215,10335),(1185,8096),(11330,11680)]\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFqdcqauMl0z"
      },
      "source": [
        "# #  np.isinf([np.inf, -np.inf, 1.0, np.nan])\n",
        "# import numpy as np\n",
        "# print(np.any(np.sum(np.array([7, 5, 1.0, np.nan]))))\n",
        "# np.isnan(np.sum(np.array([7, 5, 1.0, np.nan])))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkHTF00Qiwk5"
      },
      "source": [
        "def val_gen(val_data=test_files,temporal_lenght=temporal_length,temporal_stride=stride,batch_size=batch_size):  \n",
        "  chunk_frames=[]\n",
        "  batch_count=0\n",
        "  queue=collections.deque()\n",
        "  label=collections.deque()\n",
        "  val_ch=0\n",
        "\n",
        "  # val_data=shuffle(val_data)\n",
        "\n",
        "  for i in range(len(val_data)):\n",
        "\n",
        "\n",
        "    frame_count=0 #to check enough frames are available to append in queue\n",
        "    chunk_frames.clear() # batch list \n",
        "    queue.clear() # frame queue\n",
        "    label.clear() # lable queue\n",
        "    batch_count=0 #when new video starts the batch begins form Zero\n",
        "    temp_frames=[]\n",
        "    main_frames=[]\n",
        "    lable_list=[0,0,0,0,0]\n",
        "    \n",
        "\n",
        "    total_frames=int(cv2.VideoCapture(val_data[i]).get(7))\n",
        "    cap=cv2.VideoCapture(val_data[i])\n",
        "\n",
        "    for k in range(total_frames):\n",
        "      \n",
        "      \n",
        "      if total_frames-frame_count >=temporal_lenght:\n",
        "\n",
        "        if len(queue) != temporal_lenght:\n",
        "          img=cap.read()[1]\n",
        "          img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "          img=img.astype(np.float32)\n",
        "\n",
        "          img=tf.keras.layers.Resizing(image_size,image_size,interpolation='gaussian',crop_to_aspect_ratio=False)(img)\n",
        "          img = tf.keras.layers.Rescaling(scale=1./255)(img)\n",
        "\n",
        "          if np.ndarray.all((np.array(img) == 0)):\n",
        "            pass\n",
        "            print(\"zero\",val_data[i])\n",
        "          \n",
        "          elif np.isnan(np.sum(img)):\n",
        "            print('nan',val_data[i])\n",
        "\n",
        "          elif np.any(np.isnan(img)):\n",
        "            print('nan 2',val_data[i])\n",
        "\n",
        "          elif np.any(np.isinf(img)):\n",
        "            print('inf',val_data[i])\n",
        " \n",
        "          else:\n",
        "            queue.append(img)\n",
        "            frame_count+=1\n",
        "\n",
        "        if len(queue) == temporal_lenght:\n",
        "\n",
        "          chunk_frames.append(np.array(queue,ndmin=4))\n",
        "          #txt=['arrest', 'abuse', 'Normal_Videos', 'Arson ', 'assault']\n",
        "\n",
        "          if 'arrest' in val_data[i]:\n",
        "            lable_list.pop(0)\n",
        "            lable_list.insert(0,1)\n",
        "            label.append(lable_list)\n",
        "          \n",
        "          \n",
        "          if 'abuse' in val_data[i]:\n",
        "            lable_list.pop(1)\n",
        "            lable_list.insert(1,1)\n",
        "            label.append(lable_list)\n",
        "            \n",
        "          if 'normal' in val_data[i]:\n",
        "            lable_list.pop(2)\n",
        "            lable_list.insert(2,1)\n",
        "            label.append(lable_list)     \n",
        "\n",
        "          if 'arson' in val_data[i]:\n",
        "            lable_list.pop(3)\n",
        "            lable_list.insert(3,1)\n",
        "            label.append(lable_list)\n",
        "\n",
        "          if 'assault' in val_data[i]:\n",
        "            lable_list.pop(4)\n",
        "            lable_list.insert(4,1)\n",
        "            label.append(lable_list)\n",
        "\n",
        "          batch_count+=1\n",
        "            \n",
        "          \n",
        "          for stride in range(temporal_stride):\n",
        "            queue.popleft()\n",
        "\n",
        "        if batch_count == batch_size:\n",
        "          chunk_frames=shuffle(chunk_frames)  \n",
        "          batch_return=np.array(chunk_frames)\n",
        "          label_return=np.reshape(np.array(label,ndmin=2),(32,5))\n",
        "         \n",
        "          \n",
        "\n",
        "          yield  batch_return , label_return\n",
        "          # yield 1\n",
        "          batch_count=0\n",
        "          label.clear()\n",
        "          chunk_frames.clear()\n",
        "          batch_return=0\n",
        "          label_return=0\n",
        "\n",
        "\n",
        "\n",
        "      else:\n",
        "        continue\n",
        "    cap.release()\n",
        "\n",
        "val_data=tf.data.Dataset.from_generator(val_gen, output_signature=(tf.TensorSpec(shape=(batch_size, temporal_length,image_size, image_size, 3),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(batch_size,5),dtype=tf.dtypes.int8) ))\n",
        "val_data=val_data.prefetch(buffer_size=tf.data.AUTOTUNE).repeat(repeat)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7WfhbE-_scJ"
      },
      "source": [
        "# fun=val_gen()\n",
        "# for i in range(31):\n",
        "#   ws,b=next(fun)\n",
        "#   print('ws',ws.shape,'b',b.shape)\n",
        "# print(b.shape)\n",
        "# # individual chucks =37243.933333333334  batches =1163.8729166666667\n",
        "# for i in b:\n",
        "#   print(i)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYPCQLkNUmUM"
      },
      "source": [
        "#678  train\n",
        "#49 test"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr1GzHgJq4x7"
      },
      "source": [
        "# x_=[]\n",
        "# for j in  test_files:\n",
        "#   x_.append(cv2.VideoCapture(j).get(7))\n",
        "#   # print(j)\n",
        "# print(x_)\n",
        "# print(sum(x_))\n",
        "# print((int(sum(x_))-30)/15,((int(sum(x_))-30)/15)/32)\n",
        "\n",
        "# 23848.0 #total frames\n",
        "# 1587.8666666666666 #after made into chunks\n",
        "# 49.62083333333333 #after put into batches. So totally 49 batches available"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4gUlZCpbKZ"
      },
      "source": [
        "# x_=[]\n",
        "# for i in range(5):\n",
        "#   for j in range(len(files_list[i])):\n",
        "#     x_.append(cv2.VideoCapture(files_list[i][j]).get(7))\n",
        "# print(x_)\n",
        "# print(sum(x_))\n",
        "# print((int(sum(x_))-30)/15,((int(sum(x_))-30)/15)/32)\n",
        "\n",
        "# (11275-30)/15\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xok69s-UsP8m"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W92I3vsjSWfg"
      },
      "source": [
        "# 256%9"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jLcS4MXuzBcO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbbTWLpSTKLs"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9L9-ynZGM-m"
      },
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvKlPCQkaUH7"
      },
      "source": [
        "# for i in range(5):\n",
        "#   print(files_list[i][0])\n",
        "#   files_list[i]=shuffle(files_list[i])\n",
        "#   print(files_list[i][0])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3%3 ==0\n"
      ],
      "metadata": {
        "id": "rSrRzke_pG6T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zToojgzOFLpt",
        "outputId": "5f737335-e293-417c-a158-56841dfafa4c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# for running on gpu\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    global files_list\n",
        "    files_list=shuffle(files_list)\n",
        "\n",
        "csv_logger=tf.keras.callbacks.CSVLogger('/content/drive/MyDrive/crime detection/log.csv', separator=\",\", append=True)      \n",
        "    \n",
        "\n",
        "# initial_learning_rate = 0.01\n",
        "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate, decay_steps=1000, decay_rate=0.96, staircase=False\n",
        "# )\n",
        "\n",
        "# lr_scheduler=tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "# Define callbacks.\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"/content/drive/MyDrive/crime detection/model.{epoch:02d}-{val_accuracy:.2f}.h5\", save_best_only=True,monitor='val_accuracy'\n",
        ")\n",
        "\n",
        "adam=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "  model = get_model()\n",
        "\n",
        "  model.compile(\n",
        "      \n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      \n",
        "      optimizer=adam,\n",
        "\n",
        "      metrics=[\"accuracy\",\"AUC\",\"Precision\",\"Recall\"]  )\n",
        "  \n",
        "model.fit(gen_data,epochs=1000,steps_per_epoch=100,validation_data=val_data,validation_steps=48,callbacks=[csv_logger,checkpoint_cb,CustomCallback()],batch_size=batch_size)\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 30, 256, 25  0           []                               \n",
            "                                6, 3)]                                                            \n",
            "                                                                                                  \n",
            " first_layer_1 (Conv3D)         (None, 30, 128, 128  5248        ['input_2[0][0]']                \n",
            "                                , 64)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 30, 128, 128  256        ['first_layer_1[0][0]']          \n",
            " rmalization)                   , 64)                                                             \n",
            "                                                                                                  \n",
            " block_2_lealyer_6 (Conv3D)     (None, 15, 64, 64,   110656      ['batch_normalization_7[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_4 (Conv3D)       (None, 15, 64, 64,   2080        ['block_2_lealyer_6[0][0]']      \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_2 (Conv3D)       (None, 15, 64, 64,   6240        ['block_2_lealyer_6[0][0]']      \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_5 (Conv3D)       (None, 15, 64, 64,   50208       ['block_3_layer_4[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block_3_maxpool_1 (MaxPooling3  (None, 15, 64, 64,   0          ['block_2_lealyer_6[0][0]']      \n",
            " D)                             64)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_1 (Conv3D)       (None, 15, 64, 64,   4160        ['block_2_lealyer_6[0][0]']      \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_3 (Conv3D)       (None, 15, 64, 64,   165952      ['block_3_layer_2[0][0]']        \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_3c_layer_5 (Conv3D)      (None, 15, 64, 64,   50208       ['block_3_layer_5[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block_3_layer_6 (Conv3D)       (None, 15, 64, 64,   4160        ['block_3_maxpool_1[0][0]']      \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_3 (Concatenate)          (None, 15, 64, 64,   0           ['block_3_layer_1[0][0]',        \n",
            "                                224)                              'block_3_layer_3[0][0]',        \n",
            "                                                                  'block_3c_layer_5[0][0]',       \n",
            "                                                                  'block_3_layer_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 15, 64, 64,   896        ['block_3[0][0]']                \n",
            " rmalization)                   224)                                                              \n",
            "                                                                                                  \n",
            " block_4_layer_4 (Conv3D)       (None, 15, 64, 64,   14400       ['batch_normalization_8[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_4_layer_2 (Conv3D)       (None, 15, 64, 64,   21600       ['batch_normalization_8[0][0]']  \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " block_4_layer_5 (Conv3D)       (None, 15, 64, 64,   51232       ['block_4_layer_4[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block_4_maxpool_1 (MaxPooling3  (None, 15, 64, 64,   0          ['batch_normalization_8[0][0]']  \n",
            " D)                             224)                                                              \n",
            "                                                                                                  \n",
            " block_4_layer_1 (Conv3D)       (None, 15, 64, 64,   28800       ['batch_normalization_8[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " block_4_layer_3 (Conv3D)       (None, 15, 64, 64,   248928      ['block_4_layer_2[0][0]']        \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " bvlock_4_layer_5 (Conv3D)      (None, 15, 64, 64,   25632       ['block_4_layer_5[0][0]']        \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block_4_layer_6 (Conv3D)       (None, 15, 64, 64,   14400       ['block_4_maxpool_1[0][0]']      \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block_4 (Concatenate)          (None, 15, 64, 64,   0           ['block_4_layer_1[0][0]',        \n",
            "                                320)                              'block_4_layer_3[0][0]',        \n",
            "                                                                  'bvlock_4_layer_5[0][0]',       \n",
            "                                                                  'block_4_layer_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 15, 64, 64,   1280       ['block_4[0][0]']                \n",
            " rmalization)                   320)                                                              \n",
            "                                                                                                  \n",
            " block_2_leyer_6 (Conv3D)       (None, 15, 64, 64,   41088       ['batch_normalization_9[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " block_2_lealer_6 (Conv3D)      (None, 8, 32, 32, 6  221248      ['block_2_leyer_6[0][0]']        \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5_layer_4 (Conv3D)       (None, 8, 32, 32, 2  1560        ['block_2_lealer_6[0][0]']       \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5_layer_2 (Conv3D)       (None, 8, 32, 32, 9  6240        ['block_2_lealer_6[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block_5_laayer_5 (Conv3D)      (None, 8, 32, 32, 6  38464       ['block_5_layer_4[0][0]']        \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5_maxpool_1 (MaxPooling3  (None, 8, 32, 32, 6  0          ['block_2_lealer_6[0][0]']       \n",
            " D)                             4)                                                                \n",
            "                                                                                                  \n",
            " block_5_layer_1 (Conv3D)       (None, 8, 32, 32, 1  10400       ['block_2_lealer_6[0][0]']       \n",
            "                                60)                                                               \n",
            "                                                                                                  \n",
            " block_5_layer_3 (Conv3D)       (None, 8, 32, 32, 6  165952      ['block_5_layer_2[0][0]']        \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5_layaer_5 (Conv3D)      (None, 8, 32, 32, 6  102464      ['block_5_laayer_5[0][0]']       \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5_layer_6 (Conv3D)       (None, 8, 32, 32, 6  4160        ['block_5_maxpool_1[0][0]']      \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_5 (Concatenate)          (None, 8, 32, 32, 3  0           ['block_5_layer_1[0][0]',        \n",
            "                                52)                               'block_5_layer_3[0][0]',        \n",
            "                                                                  'block_5_layaer_5[0][0]',       \n",
            "                                                                  'block_5_layer_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 32, 32, 3  1408       ['block_5[0][0]']                \n",
            " ormalization)                  52)                                                               \n",
            "                                                                                                  \n",
            " block_6_layer_2 (Conv3D)       (None, 8, 32, 32, 9  33888       ['batch_normalization_10[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block_6_layer_4 (Conv3D)       (None, 8, 32, 32, 3  11296       ['batch_normalization_10[0][0]'] \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block_6_maxpool_1 (MaxPooling3  (None, 8, 32, 32, 3  0          ['batch_normalization_10[0][0]'] \n",
            " D)                             52)                                                               \n",
            "                                                                                                  \n",
            " block_6_layer_1 (Conv3D)       (None, 8, 32, 32, 1  45184       ['batch_normalization_10[0][0]'] \n",
            "                                28)                                                               \n",
            "                                                                                                  \n",
            " block_6_layer_3 (Conv3D)       (None, 8, 32, 32, 6  165952      ['block_6_layer_2[0][0]']        \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_6_layer_5 (Conv3D)       (None, 8, 32, 32, 3  27680       ['block_6_layer_4[0][0]']        \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block_6_layer_6 (Conv3D)       (None, 8, 32, 32, 6  22592       ['block_6_maxpool_1[0][0]']      \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_6 (Concatenate)          (None, 8, 32, 32, 2  0           ['block_6_layer_1[0][0]',        \n",
            "                                88)                               'block_6_layer_3[0][0]',        \n",
            "                                                                  'block_6_layer_5[0][0]',        \n",
            "                                                                  'block_6_layer_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 8, 32, 32, 2  1152       ['block_6[0][0]']                \n",
            " ormalization)                  88)                                                               \n",
            "                                                                                                  \n",
            " block2_lepayer_6 (Conv3D)      (None, 8, 32, 32, 1  36992       ['batch_normalization_12[0][0]'] \n",
            "                                28)                                                               \n",
            "                                                                                                  \n",
            " blok_2_lealyer_6 (Conv3D)      (None, 4, 16, 16, 6  221248      ['block2_lepayer_6[0][0]']       \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_7_layer_2 (Conv3D)       (None, 4, 16, 16, 1  8060        ['blok_2_lealyer_6[0][0]']       \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block_7_layer_4 (Conv3D)       (None, 4, 16, 16, 3  2080        ['blok_2_lealyer_6[0][0]']       \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " block_7_maxpool_1 (MaxPooling3  (None, 4, 16, 16, 6  0          ['blok_2_lealyer_6[0][0]']       \n",
            " D)                             4)                                                                \n",
            "                                                                                                  \n",
            " block_7_layer_1 (Conv3D)       (None, 4, 16, 16, 6  4160        ['blok_2_lealyer_6[0][0]']       \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_7_layer_3 (Conv3D)       (None, 4, 16, 16, 9  321504      ['block_7_layer_2[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " block_7_layler_5 (Conv3D)      (None, 4, 16, 16, 4  34600       ['block_7_layer_4[0][0]']        \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " block_7_layer_6 (Conv3D)       (None, 4, 16, 16, 6  4160        ['block_7_maxpool_1[0][0]']      \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " block_7 (Concatenate)          (None, 4, 16, 16, 2  0           ['block_7_layer_1[0][0]',        \n",
            "                                64)                               'block_7_layer_3[0][0]',        \n",
            "                                                                  'block_7_layler_5[0][0]',       \n",
            "                                                                  'block_7_layer_6[0][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling3d_1 (Gl  (None, 264)         0           ['block_7[0][0]']                \n",
            " obalAveragePooling3D)                                                                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 264)          0           ['global_average_pooling3d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 264)          0           ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2048)         540672      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 2048)        8192        ['dense_2[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 2048)         0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 2048)         0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 5)            10245       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 5)            0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,898,977\n",
            "Trainable params: 2,892,385\n",
            "Non-trainable params: 6,592\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-76c04a47c4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       metrics=[\"accuracy\",\"AUC\",\"Precision\",\"Recall\"]  )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/block_3/concat' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 661, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-29-76c04a47c4b6>\", line 46, in <module>\n      model.fit(gen_data,epochs=1000,steps_per_epoch=100,validation_data=val_data,validation_steps=48,callbacks=[csv_logger,checkpoint_cb,CustomCallback()],batch_size=batch_size)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\", line 183, in call\n      return self._merge_function(inputs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\", line 531, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 3313, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model_1/block_3/concat'\nDetected at node 'model_1/block_3/concat' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 661, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-29-76c04a47c4b6>\", line 46, in <module>\n      model.fit(gen_data,epochs=1000,steps_per_epoch=100,validation_data=val_data,validation_steps=48,callbacks=[csv_logger,checkpoint_cb,CustomCallback()],batch_size=batch_size)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\", line 183, in call\n      return self._merge_function(inputs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\", line 531, in _merge_function\n      return backend.concatenate(inputs, axis=self.axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 3313, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model_1/block_3/concat'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,224,15,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/block_3/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[assert_less_equal_1/Assert/AssertGuard/pivot_f/_33/_63]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,224,15,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/block_3/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_7488]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YWtVUm3c3I3"
      },
      "source": [
        "4279/32  #valid 133\n",
        "\n",
        "1163 # train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiDgP_cwcRb9"
      },
      "source": [
        "# loss:2.0897 acc:0.2936 val_loss: 4.4075 - val_accuracy: 0.4333 epoch 3\n",
        "# loss: 1.9303 - accuracy: 0.2906 - val_loss: 8.7073 - val_accuracy: 0.4333 epoch 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avVPP_yh3IHy"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "total_frames=int(cv2.VideoCapture('/content/drive/MyDrive/train/abuse/abuse_8.mp4').get(7))\n",
        "print(total_frames)\n",
        "tol=0\n",
        "\n",
        "# img is 2D image data\n",
        "# tol  is tolerance\n",
        "cap=cv2.VideoCapture('/content/drive/MyDrive/train/abuse/abuse_8.mp4')\n",
        "img=cap.read()[1]\n",
        "# img=cv2.resize(img,(180,180))\n",
        "cv2_imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3TR9xfR5W4Z"
      },
      "source": [
        "y_nonzero, x_nonzero, _ = np.nonzero(im)\n",
        "im=im[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUss70t5cVK_"
      },
      "source": [
        "# to try \n",
        "\"\"\"\n",
        "Clip the gradients to prevent their explosion. For instance in Keras you could use clipnorm=1. or clipvalue=1. as parameters for your optimizer.\n",
        "\n",
        "Try to increase the batch size (e.g. 32 to 64 or 128) to increase the stability of your optimization.\n",
        "\n",
        "Check the size of your last batch which may be different from the batch size.\n",
        "\n",
        "Try to increase the batch size (e.g. 32 to 64 or 128) to increase the stability of your optimization.\n",
        "\n",
        "Check validity of inputs (no NaNs or sometimes 0s). i.e df.isnull().any()\n",
        "array_sum = np.sum(array)\n",
        "array_has_nan = np.isnan(array_sum)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BG662yFa4tt"
      },
      "source": [
        "\"\"\"Add regularization to add l1 or l2 penalties to the weights. Otherwise, try a smaller l2 reg. i.e l2(0.001), \n",
        "      or remove it if already exists.\n",
        "\n",
        "Try a smaller Dropout rate.\n",
        "\n",
        "Clip the gradients to prevent their explosion. For instance in Keras you could use clipnorm=1. or clipvalue=1. as parameters for your optimizer.\n",
        "\n",
        "Check validity of inputs (no NaNs or sometimes 0s). i.e df.isnull().any()\n",
        "\n",
        "Replace optimizer with Adam which is easier to handle. Sometimes also replacing sgd with rmsprop would help.\n",
        "\n",
        "Use RMSProp with heavy regularization to prevent gradient explosion.\n",
        "\n",
        "Try normalizing your data, or inspect your normalization process for any bad values introduced.\n",
        "\n",
        "Verify that you are using the right activation function (e.g. using a softmax instead of sigmoid for multiple class classification).\n",
        "\n",
        "Try to increase the batch size (e.g. 32 to 64 or 128) to increase the stability of your optimization.\n",
        "\n",
        "Check the size of your last batch which may be different from the batch size.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq4FAg6WJKSR"
      },
      "source": [
        "# # model.history.history\n",
        "# import pickle\n",
        "# # with open('/content/drive/MyDrive/history/trainHistoryDict_2', 'wb') as file_pi:\n",
        "# #   pickle.dump(model.history.history, file_pi)\n",
        "# history = pickle.load(open('/content/drive/MyDrive/history/trainHistoryDict_main', \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDPTD9oZqRPR"
      },
      "source": [
        "# aaaa=history\n",
        "# bb=history\n",
        "\n",
        "# for d in aaaa.keys():\n",
        "#   bb[d].append(aaaa[d][-1])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOMd67_r7QX7"
      },
      "source": [
        "# model=tf.keras.models.load_model('/content/drive/MyDrive/re_train/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rElP3RHGi9G"
      },
      "source": [
        "# model.save('/content/drive/MyDrive/re_train/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wlJCwS9LBrg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL9GnCBII16L"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmvT2ktN2KCI"
      },
      "source": [
        "#for predicting output\n",
        "\n",
        "import collections\n",
        "import copy\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict(data,temporal_lenght=30,temporal_stride=20,batch_size=32):  \n",
        "  \n",
        "  chunk_frames=[]\n",
        "  batch_count=0\n",
        "  queue=collections.deque()\n",
        "  label=collections.deque()\n",
        "  # model=tf.keras.models.load_model('/content/drive/MyDrive/saved_model/my_model')\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    frame_count=0 #to check enough frames are available to append in queue\n",
        "    chunk_frames.clear() # batch list \n",
        "    queue.clear() # frame queue\n",
        "    label.clear() # lable queue\n",
        "    batch_count=0 #when new video starts the batch begins form Zero\n",
        "    lable_list=[0,0,0,0,0]#for labeling \n",
        "    \n",
        "    total_frames=int(cv2.VideoCapture(data[i]).get(7))\n",
        "    print(total_frames)\n",
        "    cap=cv2.VideoCapture(data[i])\n",
        "    for k in range(total_frames):\n",
        "      \n",
        "      if total_frames-frame_count >=temporal_lenght:\n",
        "        if len(queue) != temporal_lenght:\n",
        "          queue.append(cv2.resize(cap.read()[1],(180,180)))\n",
        "          #queue.append(cap.read()[1])\n",
        "          frame_count+=1\n",
        "\n",
        "        if len(queue) == temporal_lenght:\n",
        "          \n",
        "          chunk_frames.append(np.array(queue,ndmin=4))\n",
        "          for stride in range(temporal_stride):\n",
        "            queue.popleft()          \n",
        "          batch_return=np.array(chunk_frames)\n",
        "\n",
        "          #print(model.predict(batch_return))\n",
        "                          \n",
        "          yield  batch_return \n",
        "        \n",
        "        chunk_frames.clear()\n",
        "        batch_return=0\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "      batch_count=0\n",
        "      continue\n",
        "    cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEhlASJY9p4c"
      },
      "source": [
        "# 'arrest'-0, 'abuse'-1, 'Normal_Videos'-2, 'Arson '-3, 'assault'-4\n",
        "'Normal_Videos', 'assault', 'arson', ' arrest', 'abuse'\n",
        "'Normal_Videos', 'assault', 'arson', ' arrest', 'abuse'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHTSN-l3aSIi"
      },
      "source": [
        "model=tf.keras.models.load_model('/content/drive/MyDrive/high acc/model.11-0.71.h5')\n",
        "model.compile()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7zo8Nuoaf3j"
      },
      "source": [
        "model.save('/content/drive/MyDrive/new_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IomjqVPIqnFt"
      },
      "source": [
        "# to predict output\n",
        "\n",
        "\n",
        "dataa=['/content/drive/MyDrive/train/Normal_Videos/Normal_Videos_015_x264.mp4']\n",
        "pr=predict(data=dataa)\n",
        "ff=[]\n",
        "for i in range(1000):\n",
        "  x=next(pr)\n",
        "  ff.append(model.predict(x))\n",
        "  print(model.predict(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-lUpml2Bcr0"
      },
      "source": [
        "# print(np.count(np.array(ff),3))\n",
        "\n",
        "unique, counts = np.unique(np.array(ff), return_counts=True)\n",
        "dict(zip(unique, counts))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUS_SRrdSFKK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_train = model.history.history['loss']\n",
        "loss_val = model.history.history['val_loss']\n",
        "epochs = range(1,3,1)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgF1rO0cwR7D"
      },
      "source": [
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "face=cv2.imread(\"/content/im_1.jfif\")\n",
        "cv2_imshow(face)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Z8AkaFTP01"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "# import tensorflow as tf\n",
        "\n",
        "# model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n",
        "# # To add an extra dimension for batch, use tf.expand_dims()\n",
        "# low_resolution_image = tf.expand_dims(face, 0) # Low Resolution Image of shape [batch_size, height, width, 3]\n",
        "# low_resolution_image = tf.cast(low_resolution_image, tf.float32)\n",
        "# super_resolution = model(low_resolution_image) # Perform Super Resolution here\n",
        "# print(super_resolution[0].shape)\n",
        "\n",
        "# cv2_imshow(super_resolution[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ7Q2OLqv8OA"
      },
      "source": [
        "! pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "\n",
        "!pip show keras-vggface\n",
        "\n",
        "!pip install keras_applications\n",
        "# check version of keras_vggface\n",
        "import keras_vggface\n",
        "# print version\n",
        "print(keras_vggface.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188nCWA2wD3I"
      },
      "source": [
        "!pip install mtcnn\n",
        "# confirm mtcnn was installed correctly\n",
        "import mtcnn\n",
        "# print version\n",
        "print(mtcnn.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w78nxSHRwHpV"
      },
      "source": [
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions\n",
        "\n",
        "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W27tY7bvRje7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVVFyotxwKoi"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        " \n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename,size=(224,224)):\n",
        "  print(filename)\n",
        "  pixels= pyplot.imread(filename)\n",
        "  cv2_imshow(pixels)\n",
        "  detector = MTCNN()\n",
        "  results = detector.detect_faces(pixels) \n",
        "  x1, y1, width, height = results[0]['box']\n",
        "  x2, y2 = x1 + width, y1 + height\n",
        "  face = pixels[y1:y2, x1:x2]\n",
        "  cv2_imshow(cv2.resize(face,dsize=size))\n",
        "  image = Image.fromarray(face)\n",
        "  image = image.resize(size)\n",
        " \n",
        "  face_array = asarray(image)\n",
        "  return face_array\n",
        "\n",
        "# extract faces and calculate face embeddings for a list of photo files\n",
        "def get_embeddings(filenames):\n",
        "\t# extract faces\n",
        "\tfaces = [extract_face(f) for f in filenames]\n",
        "\t# convert into an array of samples\n",
        "\tsamples = asarray(faces, 'float32')\n",
        "\t# prepare the face for the model, e.g. center pixels\n",
        "\tsamples = preprocess_input(samples, version=2)\n",
        "\t# create a vggface model\n",
        "\tmodel = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\t# perform prediction\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat\n",
        " \n",
        "# determine if a candidate face is a match for a known face\n",
        "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
        "\t# calculate distance between embeddings\n",
        "\tscore = cosine(known_embedding, candidate_embedding)\n",
        "\tif score <= thresh:\n",
        "\t\tprint('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n",
        "\telse:\n",
        "\t\tprint('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))\n",
        " \n",
        "# define filenames\n",
        "filenames = ['/content/im_1.jfif', '/content/im_2.jpg',\n",
        "\t'/content/im-4.jfif', '/content/im_5.jfif']\n",
        "# get embeddings file filenames\n",
        "embeddings = get_embeddings(filenames)\n",
        "# define sharon stone\n",
        "sharon_id = embeddings[0]\n",
        "# verify known photos of sharon\n",
        "print('Positive Tests')\n",
        "is_match(embeddings[0], embeddings[1])\n",
        "is_match(embeddings[0], embeddings[2])\n",
        "# verify known photos of other people\n",
        "print('Negative Tests')\n",
        "is_match(embeddings[0], embeddings[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQ0NyAeG5ky"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1K0upOgrERM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfmXtN8D08VV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}