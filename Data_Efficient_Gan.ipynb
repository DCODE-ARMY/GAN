{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCODE-ARMY/GAN/blob/main/Data_Efficient_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhHhzUDwrdhI",
        "outputId": "8eb6166b-2f0e-49e3-ddec-bb91f70a8ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jul 13 09:22:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BRUi5CD0io1",
        "outputId": "a0fb7aec-841c-4492-c25b-2f75521efe8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnvOPlqbqbk4"
      },
      "outputs": [],
      "source": [
        "#use centralStorageStrategy\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import tensorflow_addons as tfa #used for spectral normalaization\n",
        "from sklearn.utils import shuffle\n",
        "import PIL\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "# TF_GPU_ALLOCATOR=cuda_malloc_async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBY_dKKIqdDd"
      },
      "outputs": [],
      "source": [
        "#total image 1228/32= 38 || 1228/16=76 || 1228/26=46\n",
        "batch_size = 32\n",
        "num_channels = 3\n",
        "num_classes = 5\n",
        "kid_image_size = 75\n",
        "image_size = 256\n",
        "noise_size = 256\n",
        "channel_axis=3\n",
        "steps_per_epoc=38\n",
        "epochh=1\n",
        "divide_array=np.array([6])\n",
        "\n",
        "policy = 'color,translation,cutout'# color,\n",
        "\n",
        "# adaptive discriminator augmentation\n",
        "max_translation = 0.125\n",
        "max_rotation = 0.125\n",
        "max_zoom = 0.25\n",
        "# target_accuracy = 0.85\n",
        "# integration_steps = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggp7yf19qdMi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gene(data_dir='/content/drive/MyDrive/scrapped data',batch_size=batch_size,resize=(image_size,image_size)):\n",
        "  cat=['laptop', 'keyboard', 'mouse', 'headphone', 'monitor']\n",
        "\n",
        "  img_path_list=[]\n",
        "  labels=[]\n",
        "\n",
        "  #getting path to all images\n",
        "  for i in cat:\n",
        "    path=os.path.join(data_dir,i)\n",
        "    for j in os.listdir(path):\n",
        "      img_path_list.append(os.path.join(path,j))\n",
        "\n",
        "  img_path_list=shuffle(img_path_list)\n",
        "\n",
        "  for i in img_path_list:\n",
        "    # print(cat.index(i.split('/')[-2]))\n",
        "    labels.append(cat.index(i.split('/')[-2]))\n",
        "\n",
        "\n",
        "#converting labels to onehot encoded vectors  \n",
        "  # labels=tf.keras.utils.to_categorical(labels,5)\n",
        " \n",
        "\n",
        "  img_list=[]\n",
        "  labels_list=[]\n",
        " \n",
        "  for i,j in enumerate(img_path_list):\n",
        "    # img=cv2.resize(cv2.imread(j,cv2.IMREAD_UNCHANGED),resize,interpolation=cv2.INTER_AREA)\n",
        "    img=np.array(PIL.Image.open(j))\n",
        "    # tensor = tf.image.resize(tensor, (128,128))\n",
        "    # tensor = tf.subtract(tf.divide(tensor, 127.5), 1)\n",
        "\n",
        "    # img=img.astype(np.float32)\n",
        "   \n",
        "    img=tf.keras.layers.Resizing(image_size,image_size,interpolation='gaussian',crop_to_aspect_ratio=False)(img)\n",
        "    # img=img.astype(np.float32)\n",
        "    # img=(img-127.5)/127.5\n",
        "    img = tf.subtract(tf.divide(img, 127.5), 1)\n",
        "    # assert not np.any(np.isnan(img))\n",
        "    img_list.append(img)\n",
        "    \n",
        "    labels_list.append(labels[i])\n",
        "\n",
        "    if len(img_list)==batch_size:\n",
        "      \n",
        "      data=np.array(img_list,dtype=np.float32),np.expand_dims(np.array(labels_list,dtype=np.int8),axis=1)#not necessarily convert to tensor\n",
        "      yield data\n",
        "      img_list.clear()\n",
        "      labels_list.clear()\n",
        "\n",
        "\n",
        "\n",
        "#Tensorspec can be used to declare numpy signature but with dtype specified in tf\n",
        "\n",
        "dataset=tf.data.Dataset.from_generator(gene,output_signature=(tf.TensorSpec(shape=(batch_size, image_size, image_size, channel_axis),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(batch_size,1),dtype=tf.dtypes.int8)))\n",
        "dataset=dataset.prefetch(buffer_size=tf.data.AUTOTUNE).repeat(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiQVx78fjMjN"
      },
      "outputs": [],
      "source": [
        "def val_gene(data_dir='/content/drive/MyDrive/scrapped data/val',batch_size=batch_size,resize=(image_size,image_size)):\n",
        "  cat=['laptop', 'keyboard', 'mouse', 'headphone', 'monitor']\n",
        "\n",
        "  img_path_list=[]\n",
        "  labels=[]\n",
        "\n",
        "  #getting path to all images\n",
        "  for i in cat:\n",
        "    path=os.path.join(data_dir,i)\n",
        "    for j in os.listdir(path):\n",
        "      img_path_list.append(os.path.join(path,j))\n",
        "\n",
        "  img_path_list=shuffle(img_path_list)\n",
        "\n",
        "  for i in img_path_list:\n",
        "    # print(cat.index(i.split('/')[-2]))\n",
        "    labels.append(cat.index(i.split('/')[-2]))\n",
        "\n",
        "\n",
        "#converting labels to onehot encoded vectors  \n",
        "  # labels=tf.keras.utils.to_categorical(labels,5)\n",
        " \n",
        "\n",
        "  img_list=[]\n",
        "  labels_list=[]\n",
        " \n",
        "  for i,j in enumerate(img_path_list):\n",
        "    # img=cv2.resize(cv2.imread(j,cv2.IMREAD_UNCHANGED),resize,interpolation=cv2.INTER_AREA)\n",
        "    img=np.array(PIL.Image.open(j))\n",
        "    # tensor = tf.image.resize(tensor, (128,128))\n",
        "    # tensor = tf.subtract(tf.divide(tensor, 127.5), 1)\n",
        "\n",
        "    # img=img.astype(np.float32)\n",
        "   \n",
        "    img=tf.keras.layers.Resizing(image_size,image_size,interpolation='gaussian',crop_to_aspect_ratio=False)(img)\n",
        "    # img=img.astype(np.float32)\n",
        "    # img=(img-127.5)/127.5\n",
        "    img = tf.subtract(tf.divide(img, 127.5), 1)\n",
        "    # assert not np.any(np.isnan(img))\n",
        "    img_list.append(img)\n",
        "    \n",
        "    labels_list.append(labels[i])\n",
        "\n",
        "    if len(img_list)==batch_size:\n",
        "      \n",
        "      data=np.array(img_list,dtype=np.float32),np.expand_dims(np.array(labels_list,dtype=np.int8),axis=1)#not necessarily convert to tensor\n",
        "      yield data\n",
        "      img_list.clear()\n",
        "      labels_list.clear()\n",
        "\n",
        "\n",
        "\n",
        "#Tensorspec can be used to declare numpy signature but with dtype specified in tf\n",
        "\n",
        "val_dataset=tf.data.Dataset.from_generator(gene,output_signature=(tf.TensorSpec(shape=(batch_size, image_size, image_size, channel_axis),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(batch_size,1),dtype=tf.dtypes.int8)))\n",
        "val_dataset=val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE).repeat(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdCPfndPqdPy"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x,filter,kernel_size,stride,padding='same',activation=tf.keras.layers.LeakyReLU(alpha=0.2),is_initializer=True,is_regularizer=False,initializer= tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05,)\n",
        ",regularizer=None,name=None):\n",
        "  if name is not None:\n",
        "    bn_name = name + '_bn'\n",
        "    conv_name = name + '_conv'\n",
        "  else:\n",
        "    bn_name = None\n",
        "    conv_name = None\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  if is_initializer and is_regularizer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,kernel_initializer=initializer,regularizer=regularizer,name=conv_name))(x)\n",
        "\n",
        "  elif is_regularizer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,regularizer=regularizer,name=conv_name))(x)\n",
        "\n",
        "  elif is_initializer:\n",
        "    \n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,kernel_initializer=initializer,name=conv_name))(x)\n",
        "\n",
        "  else:\n",
        "    x=tfa.layers.SpectralNormalization(layers.Conv2D(filters=filter,kernel_size=kernel_size,strides=stride,padding=padding,activation=activation,name=conv_name))(x)\n",
        "   \n",
        "  \n",
        "\n",
        "  \n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoGoM75VqdS3",
        "outputId": "c278f7b3-dacb-4124-ba3a-36e3b89eab5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 16)        80          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " spectral_normalization (Spectr  (None, 1, 16)       288         ['embedding[0][0]']              \n",
            " alNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 16)           0           ['spectral_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 4096, 16)     0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 256, 256, 1)  0           ['repeat_vector[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256, 256, 4)  0           ['input_1[0][0]',                \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " spectral_normalization_1 (Spec  (None, 128, 128, 64  2432       ['concatenate[0][0]']            \n",
            " tralNormalization)             )                                                                 \n",
            "                                                                                                  \n",
            " spectral_normalization_2 (Spec  (None, 128, 128, 32  2112       ['spectral_normalization_1[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_3 (Spec  (None, 126, 126, 19  55680      ['spectral_normalization_2[0][0]'\n",
            " tralNormalization)             2)                               ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 126, 126, 19  0           ['spectral_normalization_3[0][0]'\n",
            "                                2)                               ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_4 (Spec  (None, 126, 126, 80  15520      ['dropout[0][0]']                \n",
            " tralNormalization)             )                                                                 \n",
            "                                                                                                  \n",
            " spectral_normalization_5 (Spec  (None, 124, 124, 64  46208      ['spectral_normalization_4[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_6 (Spec  (None, 124, 124, 32  2112       ['spectral_normalization_5[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_7 (Spec  (None, 124, 124, 64  51328      ['spectral_normalization_6[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_8 (Spec  (None, 124, 124, 80  5280       ['spectral_normalization_7[0][0]'\n",
            " tralNormalization)             )                                ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_9 (Spec  (None, 62, 62, 64)  46208       ['spectral_normalization_8[0][0]'\n",
            " tralNormalization)                                              ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_13 (Spe  (None, 62, 62, 64)  4224        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_11 (Spe  (None, 62, 62, 48)  3168        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_14 (Spe  (None, 62, 62, 43)  68886       ['spectral_normalization_13[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 62, 62, 64)   0           ['spectral_normalization_9[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_10 (Spe  (None, 62, 62, 64)  4224        ['spectral_normalization_9[0][0]'\n",
            " ctralNormalization)                                             ]                                \n",
            "                                                                                                  \n",
            " spectral_normalization_12 (Spe  (None, 62, 62, 32)  38464       ['spectral_normalization_11[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_15 (Spe  (None, 62, 62, 64)  24896       ['spectral_normalization_14[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_16 (Spe  (None, 62, 62, 32)  2112        ['max_pooling2d[0][0]']          \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 62, 62, 192)  0           ['spectral_normalization_10[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_12[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_15[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_16[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_17 (Spe  (None, 62, 62, 128)  24832      ['mixed0[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_18 (Spe  (None, 31, 31, 196)  226184     ['spectral_normalization_17[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 31, 31, 196)  0           ['spectral_normalization_18[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_22 (Spe  (None, 31, 31, 64)  12672       ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_20 (Spe  (None, 31, 31, 48)  9504        ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_23 (Spe  (None, 31, 31, 64)  36992       ['spectral_normalization_22[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 31, 31, 196)  0          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " spectral_normalization_19 (Spe  (None, 31, 31, 64)  12672       ['dropout_1[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_21 (Spe  (None, 31, 31, 64)  76928       ['spectral_normalization_20[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_24 (Spe  (None, 31, 31, 64)  102528      ['spectral_normalization_23[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_25 (Spe  (None, 31, 31, 32)  6336        ['max_pooling2d_1[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 31, 31, 224)  0           ['spectral_normalization_19[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_21[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_24[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_25[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 31, 31, 224)  0           ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_29 (Spe  (None, 31, 31, 64)  14464       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_27 (Spe  (None, 31, 31, 48)  10848       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_30 (Spe  (None, 31, 31, 96)  55488       ['spectral_normalization_29[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 31, 31, 224)  0          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " spectral_normalization_26 (Spe  (None, 31, 31, 64)  14464       ['dropout_2[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_28 (Spe  (None, 31, 31, 32)  38464       ['spectral_normalization_27[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_31 (Spe  (None, 31, 31, 64)  55424       ['spectral_normalization_30[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_32 (Spe  (None, 31, 31, 32)  7232        ['max_pooling2d_2[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 31, 31, 192)  0           ['spectral_normalization_26[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_28[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_31[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_32[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 31, 31, 192)  0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_34 (Spe  (None, 31, 31, 64)  12416       ['dropout_3[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_35 (Spe  (None, 31, 31, 96)  55488       ['spectral_normalization_34[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_33 (Spe  (None, 15, 15, 196)  339080     ['dropout_3[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_36 (Spe  (None, 15, 15, 96)  83136       ['spectral_normalization_35[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 192)  0          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 15, 15, 484)  0           ['spectral_normalization_33[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_36[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " spectral_normalization_41 (Spe  (None, 15, 15, 128)  62208      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_42 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_41[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_38 (Spe  (None, 15, 15, 128)  62208      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_43 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_42[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_39 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_38[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_44 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_43[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 484)  0          ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_37 (Spe  (None, 15, 15, 192)  93312      ['mixed3[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_40 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_39[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_45 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_44[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_46 (Spe  (None, 15, 15, 192)  93312      ['max_pooling2d_4[0][0]']        \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 15, 15, 640)  0           ['spectral_normalization_37[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_40[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_45[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_46[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 15, 15, 640)  0           ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_51 (Spe  (None, 15, 15, 140)  89880      ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_52 (Spe  (None, 15, 15, 128)  125696     ['spectral_normalization_51[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_48 (Spe  (None, 15, 15, 160)  102720     ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_53 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_52[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_49 (Spe  (None, 15, 15, 128)  143616     ['spectral_normalization_48[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_54 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_53[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 15, 15, 640)  0          ['dropout_4[0][0]']              \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " spectral_normalization_47 (Spe  (None, 15, 15, 192)  123264     ['dropout_4[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_50 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_49[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_55 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_54[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_56 (Spe  (None, 15, 15, 128)  82176      ['average_pooling2d[0][0]']      \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 15, 15, 576)  0           ['spectral_normalization_47[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_50[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_55[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_56[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 15, 15, 576)  0           ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " spectral_normalization_61 (Spe  (None, 15, 15, 140)  80920      ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_62 (Spe  (None, 15, 15, 128)  125696     ['spectral_normalization_61[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_58 (Spe  (None, 15, 15, 160)  92480      ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_63 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_62[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_59 (Spe  (None, 15, 15, 128)  143616     ['spectral_normalization_58[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_64 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_63[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 15, 15, 576)  0          ['dropout_5[0][0]']              \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " spectral_normalization_57 (Spe  (None, 15, 15, 192)  110976     ['dropout_5[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_60 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_59[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_65 (Spe  (None, 15, 15, 128)  114944     ['spectral_normalization_64[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_66 (Spe  (None, 15, 15, 128)  73984      ['average_pooling2d_1[0][0]']    \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 15, 15, 576)  0           ['spectral_normalization_57[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_60[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_65[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'spectral_normalization_66[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_67 (Spe  (None, 15, 15, 192)  110976     ['mixed6[0][0]']                 \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_68 (Spe  (None, 13, 13, 64)  110720      ['spectral_normalization_67[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 13, 13, 64)   0           ['spectral_normalization_68[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_69 (Spe  (None, 7, 7, 64)    102528      ['dropout_6[0][0]']              \n",
            " ctralNormalization)                                                                              \n",
            "                                                                                                  \n",
            " spectral_normalization_70 (Spe  (None, 7, 7, 32)    2112        ['spectral_normalization_69[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_71 (Spe  (None, 4, 4, 64)    51328       ['spectral_normalization_70[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " spectral_normalization_72 (Spe  (None, 1, 1, 128)   73984       ['spectral_normalization_71[0][0]\n",
            " ctralNormalization)                                             ']                               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 128)          0           ['spectral_normalization_72[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            129         ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,235,431\n",
            "Trainable params: 5,228,092\n",
            "Non-trainable params: 7,339\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def discriminator():\n",
        "  # initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=.05)\n",
        "\n",
        "  # Create the discriminator.\n",
        "  inp =layers.Input(shape=[image_size, image_size,channel_axis])\n",
        "\n",
        "  label_inp_layer=layers.Input(shape=(1,))\n",
        "  label_inp=layers.Embedding(num_classes,16)(label_inp_layer)\n",
        "\n",
        "  label_inp=tfa.layers.SpectralNormalization(layers.Dense(16,activation=tf.keras.layers.LeakyReLU(alpha=0.2) )) (label_inp)\n",
        "\n",
        "  label_inp=layers.Flatten()(label_inp)\n",
        " \n",
        "  label_inp=layers.RepeatVector(4096)(label_inp) #try using 16 embedding\n",
        "  \n",
        "  \n",
        "  # label_inp= tf.repeat(label_inp.numpy(), repeats=[image_size * image_size])\n",
        "\n",
        "  \n",
        "  label_inp=layers.Reshape((image_size,image_size,1))(label_inp)\n",
        "\n",
        "  \n",
        "  x = layers.concatenate([inp, label_inp],axis=-1)\n",
        "\n",
        "  #filter,kernel_size,stride,padding,activation,initializer,regularizer,dropout_val\n",
        "\n",
        "  # x=conv2d_bn(x,64,3,1,padding='same')\n",
        "\n",
        "  # batch_size,128,128,32\n",
        "  x=conv2d_bn(x,64,3,2,padding='same')\n",
        "\n",
        "\n",
        "  x=conv2d_bn(x,32,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,192,3,1,padding='valid')\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x,80,1,1,padding='valid')\n",
        "\n",
        "  # batch_size,128,128,64\n",
        "  x=conv2d_bn(x,64,3,1,padding='valid') #maxpool_2\n",
        "\n",
        "  x=conv2d_bn(x,32,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,64,5,1,padding='same')\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "  x=conv2d_bn(x,80,1,1,padding='valid')\n",
        "\n",
        "  x=conv2d_bn(x,64,3,2,padding='same')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  #block 1\n",
        "  #batch_size,35 x 35 x 256\n",
        " \n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 32, 5, 1)\n",
        "  \n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 43, 5, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "  \n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed0')\n",
        "\n",
        "  x=conv2d_bn(x,128,1,1)\n",
        "  x=conv2d_bn(x,196,3,2)\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  #block 2\n",
        "  #batch_size,35 x 35 x 256\n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 1)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.2)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 5, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.2)(branch3x3dbl)\n",
        " \n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed1')\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x=conv2d_bn(x, 64, 5, 2)\n",
        "\n",
        "  #block 3\n",
        "  #batch_size,35 x 35 x 256\n",
        "  branch1x1=conv2d_bn(x,64,1,1)\n",
        "\n",
        "  branch5x5=conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 32, 5, 1)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 1)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 1)\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed2')\n",
        "\n",
        "\n",
        "  \n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  #block 3\n",
        "  #batch_size,17 x 17 x 768\n",
        "  branch3x3 = conv2d_bn(x, 196, 3, 2,padding='valid')\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 1,)\n",
        "  # branch3x3dbl=layers.Dropout(0.4)(branch3x3dbl)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 2,padding='valid')\n",
        "  \n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  x = layers.concatenate([branch3x3, branch3x3dbl,branch_pool], axis=channel_axis, name='mixed3')\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "  # mixed 4: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, (1,7), 1)\n",
        "  # branch7x7=layers.Dropout(0.2)(branch7x7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, (7,1), 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "  # branch7x7dbl=layers.Dropout(0.2)(branch7x7dbl)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],axis=channel_axis,name='mixed4')\n",
        "\n",
        "  # x=layers.Dropout(0.4)(x)\n",
        "\n",
        "\n",
        "  x=layers.Dropout(0.2)(x)\n",
        "  # mixed 5,6  batch_size,17 x 17 x 768\n",
        "  for i in range(2):\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, (1,7), 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, (7,1), 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 140, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (7,1), 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, (1,7), 1)\n",
        "\n",
        "    branch_pool =layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    branch_pool = conv2d_bn(branch_pool, 128, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed' + str(5 + i))\n",
        "    if i==0:\n",
        "      x=layers.Dropout(0.4)(x)\n",
        "\n",
        "\n",
        "  #  # mixed 7: 17 x 17 x 768\n",
        "  # branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  # branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "  # branch7x7 = conv2d_bn(branch7x7, 192, (1,7), 1)\n",
        "  # branch7x7 = conv2d_bn(branch7x7, 192, (7,1), 1)\n",
        "\n",
        "  # branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (1,7), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (7,1), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (1,7), 1)\n",
        "  # branch7x7dbl = conv2d_bn(branch7x7dbl, 192, (7,1), 1)\n",
        "\n",
        "  # branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  # branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  # x = layers.concatenate(\n",
        "  #     [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "  #     axis=channel_axis,\n",
        "  #     name='mixed7')\n",
        "  \n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "  \n",
        "  x=conv2d_bn(x, 192, 1, 1,padding='same')\n",
        "\n",
        "  x=conv2d_bn(x, 64, 3, 1,padding='valid')\n",
        "  x=layers.Dropout(0.2)(x)\n",
        " \n",
        "  # x=conv2d_bn(x, 192, 3, 1,padding='same')\n",
        "  # # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  # x=conv2d_bn(x, 64, 1, 1,padding='valid')\n",
        "  # # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 64, 5, 2,padding='same')\n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 32, 1, 1,padding='valid')\n",
        "  x=conv2d_bn(x, 64, 5, 2,padding='same')\n",
        "  # x=layers.Dropout(0.2)(x)\n",
        "\n",
        "  x=conv2d_bn(x, 128, 3, 2,padding='valid')\n",
        "  # x=conv2d_bn(x, 32, 1, 1,padding='valid')\n",
        "  # x=conv2d_bn(x, 64, 2, 1,padding='valid')\n",
        "  # x=layers.Dropout(0.3)(x)\n",
        "  \n",
        "  x=layers.Flatten()(x)\n",
        "\n",
        "  # x=tfa.layers.SpectralNormalization(layers.Dense(units=1024,use_bias=False,kernel_regularizer=tf.keras.regularizers.L2(0.1),kernel_initializer='random_normal'))(x)\n",
        "  # x=layers.Activation('LeakyReLU')(x)\n",
        "  x=layers.Dropout(0.5)(x)\n",
        "\n",
        "  x=layers.Dense(units=1)(x)\n",
        "\n",
        "  return keras.Model(inputs=[label_inp_layer,inp], outputs=x)\n",
        "\n",
        "discriminator=discriminator()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUO3yy6hqdWC",
        "outputId": "5d4aff4f-5ef8-456f-f51a-cbd47cd12b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 16)        80          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 1, 256)    0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 1, 16)     0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 1, 1, 272)    0           ['reshape_2[0][0]',              \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1, 1, 256)    69888       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 1, 1, 256)    0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 2, 2, 200)   819200      ['leaky_re_lu_2[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 2, 2, 200)   600         ['conv2d_transpose[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2, 2, 200)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 2, 2, 200)    0           ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 200)   640000      ['dropout_8[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4, 4, 200)   600         ['conv2d_transpose_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 200)    0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 4, 4, 200)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 200)   640000      ['dropout_9[0][0]']              \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 8, 8, 200)   600         ['conv2d_transpose_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 8, 8, 200)    0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 8, 8, 200)    0           ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 200)  640000     ['dropout_10[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 200)  600        ['conv2d_transpose_3[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 16, 16, 200)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 16, 16, 200)  0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 200)  640000     ['dropout_11[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 200)  600        ['conv2d_transpose_4[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 32, 32, 200)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 32, 32, 200)  0           ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 200)  640000     ['dropout_12[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 200)  600        ['conv2d_transpose_5[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 64, 64, 200)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 64, 64, 200)  0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 20  640000     ['dropout_13[0][0]']             \n",
            " spose)                         0)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 20  600        ['conv2d_transpose_6[0][0]']     \n",
            " rmalization)                   0)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 128, 128, 20  0           ['batch_normalization_6[0][0]']  \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 128, 128, 20  0           ['leaky_re_lu_9[0][0]']          \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 3)  9603       ['dropout_14[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,742,971\n",
            "Trainable params: 4,740,171\n",
            "Non-trainable params: 2,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def generator():\n",
        "\n",
        "  # kernel_regularizer=regularizers.L2(1e-4)\n",
        "  \n",
        "  initializer =tf.keras.initializers.RandomNormal()\n",
        "\n",
        "  label_inp_layer=layers.Input(shape=(1,))\n",
        "  x=layers.Embedding(num_classes,16)(label_inp_layer)\n",
        "  # x=Dense(1*1*256)(x)\n",
        "  # x=layers.LeakyReLU(alpha=0.2)(x)\n",
        "  x=layers.Reshape((1,1,16))(x)\n",
        "\n",
        "  inp =layers.Input(shape=(noise_size,))\n",
        "  # y=layers.Dense(1 * 1 * latent_dim)(inp)\n",
        "  # y=layers.LeakyReLU(alpha=0.2)(y)\n",
        "  y=layers.Reshape((1, 1, noise_size))(inp)\n",
        "  \n",
        "  y=layers.concatenate([y, x],axis=-1)\n",
        "\n",
        "  y=layers.Dense(256)(y)\n",
        "  y=layers.LeakyReLU(alpha=0.2)(y)\n",
        " \n",
        "\n",
        "  #(batch_size, 2, 2,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.5)(y)\n",
        "\n",
        "  #(batch_size, 4, 4,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "  #(batch_size, 8, 8,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.5)(y)\n",
        "\n",
        "  #(batch_size, 16, 16,514) 50=128\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "\n",
        "  #(batch_size, 32, 32,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False )(y)#tf.random_normal_initializer(0., 0.05)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "\n",
        "  #(batch_size, 64, 64,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)#,kernel_regularizer=regularizers.L2(1e-4)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "\n",
        "  #(batch_size, 128, 128,514)\n",
        "  y= layers.Conv2DTranspose(200,4,strides=2,padding='same',use_bias=False)(y)\n",
        "  y=layers.BatchNormalization(scale=False)(y)\n",
        "  y=layers.LeakyReLU()(y)\n",
        "  y=layers.Dropout(.3)(y)\n",
        "  \n",
        "  #(batch_size, 256, 256,3)\n",
        "  y=layers.Conv2DTranspose(3,4,strides=2,padding='same',activation='tanh')(y)\n",
        "\n",
        "  return keras.Model(inputs=[label_inp_layer,inp], outputs=y)\n",
        "\n",
        "generator=generator()\n",
        "\n",
        "# tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flP2GzlMqdZa"
      },
      "outputs": [],
      "source": [
        "kid_image_size=75\n",
        "ema = 0.99\n",
        "\n",
        "class KID(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"kid\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "\n",
        "        # KID is estimated per batch and is averaged across batches\n",
        "        self.kid_tracker = keras.metrics.Mean()\n",
        "\n",
        "        # a pretrained InceptionV3 is used without its classification layer\n",
        "        # transform the pixel values to the 0-255 range, then use the same\n",
        "        # preprocessing as during pretraining\n",
        "        self.encoder = keras.Sequential(\n",
        "            [\n",
        "                layers.InputLayer(input_shape=(image_size, image_size, 3)),\n",
        "                layers.Rescaling(255.0),\n",
        "                layers.Resizing(height=kid_image_size, width=kid_image_size),\n",
        "                layers.Lambda(keras.applications.inception_v3.preprocess_input),\n",
        "                keras.applications.InceptionV3(\n",
        "                    include_top=False,\n",
        "                    input_shape=(kid_image_size, kid_image_size, 3),\n",
        "                    weights=\"imagenet\",\n",
        "                ),\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "            ],\n",
        "            name=\"inception_encoder\",\n",
        "        )\n",
        "\n",
        "    def polynomial_kernel(self, features_1, features_2):\n",
        "        feature_dimensions = tf.cast(tf.shape(features_1)[1], dtype=tf.float32)\n",
        "        return (features_1 @ tf.transpose(features_2) / feature_dimensions + 1.0) ** 3.0\n",
        "\n",
        "    def update_state(self, real_images, generated_images, sample_weight=None):\n",
        "        real_features = self.encoder(real_images, training=False)\n",
        "        generated_features = self.encoder(generated_images, training=False)\n",
        "\n",
        "        # compute polynomial kernels using the two sets of features\n",
        "        kernel_real = self.polynomial_kernel(real_features, real_features)\n",
        "        kernel_generated = self.polynomial_kernel(\n",
        "            generated_features, generated_features\n",
        "        )\n",
        "        kernel_cross = self.polynomial_kernel(real_features, generated_features)\n",
        "\n",
        "        # estimate the squared maximum mean discrepancy using the average kernel values\n",
        "        batch_size = tf.shape(real_features)[0]\n",
        "        batch_size_f = tf.cast(batch_size, dtype=tf.float32)\n",
        "        mean_kernel_real = tf.reduce_sum(kernel_real * (1.0 - tf.eye(batch_size))) / (\n",
        "            batch_size_f * (batch_size_f - 1.0)\n",
        "        )\n",
        "        mean_kernel_generated = tf.reduce_sum(\n",
        "            kernel_generated * (1.0 - tf.eye(batch_size))\n",
        "        ) / (batch_size_f * (batch_size_f - 1.0))\n",
        "        mean_kernel_cross = tf.reduce_mean(kernel_cross)\n",
        "        kid = mean_kernel_real + mean_kernel_generated - 2.0 * mean_kernel_cross\n",
        "\n",
        "        # update the average KID estimate\n",
        "        self.kid_tracker.update_state(kid)\n",
        "\n",
        "    def result(self):\n",
        "        return self.kid_tracker.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.kid_tracker.reset_state()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYU1Se0oqdb2"
      },
      "outputs": [],
      "source": [
        "max_translation = 0.125\n",
        "max_rotation = 0.125\n",
        "max_zoom = 0.15\n",
        "target_accuracy = 0.85\n",
        "integration_steps = 1000\n",
        "#  \"hard sigmoid\", useful for binary accuracy calculation from logits\n",
        "\n",
        "def step(values):\n",
        "    # negative values -> 0.0, positive values -> 1.0\n",
        "    return 0.5 * (1.0 + tf.sign(values))\n",
        "\n",
        "\n",
        "# augments images with a probability that is dynamically updated during training\n",
        "\n",
        "class AdaptiveAugmenter(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # stores the current probability of an image being augmented\n",
        "        self.probability = tf.Variable(0.0)\n",
        "\n",
        "        # the corresponding augmentation names from the paper are shown above each layer\n",
        "        # the authors show (see figure 4), that the blitting and geometric augmentations\n",
        "        # are the most helpful in the low-data regime\n",
        "        self.augmenter = keras.Sequential(\n",
        "            [\n",
        "                layers.InputLayer(input_shape=(image_size, image_size, 3)),\n",
        "                # blitting/x-flip:\n",
        "                layers.RandomFlip(\"horizontal\"),\n",
        "                # blitting/integer translation:\n",
        "                layers.RandomTranslation(\n",
        "                    height_factor=max_translation,\n",
        "                    width_factor=max_translation,\n",
        "                    interpolation=\"nearest\",\n",
        "                ),\n",
        "                # geometric/rotation:\n",
        "                layers.RandomRotation(factor=max_rotation),\n",
        "                # geometric/isotropic and anisotropic scaling:\n",
        "                layers.RandomZoom(\n",
        "                    height_factor=(-max_zoom, 0.0), width_factor=(-max_zoom, 0.0)\n",
        "                ),\n",
        "            ],\n",
        "            name=\"adaptive_augmenter\",\n",
        "        )\n",
        "\n",
        "    def call(self, images, training):\n",
        "        if training:\n",
        "            augmented_images = self.augmenter(images, training)\n",
        "\n",
        "            # during training either the original or the augmented images are selected\n",
        "            # based on self.probability\n",
        "            augmentation_values = tf.random.uniform(\n",
        "                shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "            )\n",
        "            augmentation_bools = tf.math.less(augmentation_values, self.probability)\n",
        "\n",
        "            images = tf.where(augmentation_bools, augmented_images, images)\n",
        "        return images\n",
        "\n",
        "    def update(self, real_logits):\n",
        "        current_accuracy = tf.reduce_mean(step(real_logits))\n",
        "\n",
        "        # the augmentation probability is updated based on the dicriminator's\n",
        "        # accuracy on real images\n",
        "        accuracy_error = current_accuracy - target_accuracy\n",
        "        self.probability.assign(\n",
        "            tf.clip_by_value(\n",
        "                self.probability + accuracy_error / integration_steps, 0.0, 1.0\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moJg3Ui2qde6"
      },
      "outputs": [],
      "source": [
        "class ConditionalGAN(tf.keras.Model):\n",
        "  def __init__(self,discriminator, generator):\n",
        "    super(ConditionalGAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.ema_generator = keras.models.clone_model(self.generator)\n",
        "    self.augmenter = AdaptiveAugmenter()\n",
        "    \n",
        "    \n",
        "    \n",
        "  def compile(self, d_optimizer, g_optimizer):\n",
        "    super(ConditionalGAN,self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "\n",
        "    # self.generator_loss = generator_loss\n",
        "    # self.critic_loss=critic_loss\n",
        "    self.generator_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n",
        "    self.discriminator_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n",
        "    self.real_accuracy = keras.metrics.BinaryAccuracy(name=\"real_acc\")\n",
        "    self.generated_accuracy = keras.metrics.BinaryAccuracy(name=\"gen_acc\")\n",
        "    self.augmentation_probability_tracker = keras.metrics.Mean(name=\"aug_p\")\n",
        "\n",
        "    self.kid = KID()\n",
        "   \n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.generator_loss_tracker,\n",
        "            self.discriminator_loss_tracker,\n",
        "            self.real_accuracy,\n",
        "            self.generated_accuracy,\n",
        "            self.augmentation_probability_tracker,\n",
        "            self.kid,]   \n",
        "\n",
        "  @tf.function\n",
        "  def adversarial_loss(self, real_logits, generated_logits):\n",
        "    # this is usually called the non-saturating GAN loss\n",
        "\n",
        "    real_labels = tf.ones(shape=(batch_size, 1))\n",
        "    generated_labels = tf.zeros(shape=(batch_size, 1))\n",
        "\n",
        "    # the generator tries to produce images that the discriminator considers as real\n",
        "    generator_loss = keras.losses.binary_crossentropy(\n",
        "        real_labels, generated_logits, from_logits=True\n",
        "    )\n",
        "    # the discriminator tries to determine if images are real or generated\n",
        "    discriminator_loss = keras.losses.binary_crossentropy(\n",
        "        tf.concat([real_labels, generated_labels], axis=0),\n",
        "        tf.concat([real_logits, generated_logits], axis=0),\n",
        "        from_logits=True,\n",
        "    )\n",
        "\n",
        "    return tf.reduce_mean(generator_loss), tf.reduce_mean(discriminator_loss)\n",
        "    \n",
        "  @tf.function\n",
        "  def generate(self,labels, training, batch_size=batch_size):\n",
        "    latent_samples = tf.random.normal(shape=(batch_size, noise_size))\n",
        "    # use ema_generator during inference\n",
        "    if training:\n",
        "        generated_images = self.generator([labels,latent_samples], training)\n",
        "    else:\n",
        "        generated_images = self.ema_generator([labels,latent_samples], training)\n",
        "    return generated_images\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, data):\n",
        "    real_images,labels=data\n",
        "    real_images = self.augmenter(real_images, training=True)\n",
        "\n",
        "    # use persistent gradient tape because gradients will be calculated twice\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      generated_images = self.generate(labels,batch_size=batch_size,training=True)\n",
        "      # gradient is calculated through the image augmentation\n",
        "      generated_images = self.augmenter(generated_images, training=True)\n",
        "\n",
        "      # separate forward passes for the real and generated images, meaning\n",
        "      # that batch normalization is applied separately\n",
        "      real_logits = self.discriminator([labels,real_images], training=True)\n",
        "      generated_logits = self.discriminator([labels,generated_images], training=True)\n",
        "\n",
        "      generator_loss, discriminator_loss = self.adversarial_loss(\n",
        "          real_logits, generated_logits\n",
        "      )\n",
        "\n",
        "    # calculate gradients and update weights\n",
        "    generator_gradients = tape.gradient(\n",
        "        generator_loss, self.generator.trainable_weights\n",
        "    )\n",
        "    discriminator_gradients = tape.gradient(\n",
        "        discriminator_loss, self.discriminator.trainable_weights\n",
        "    )\n",
        "    self.g_optimizer.apply_gradients(\n",
        "        zip(generator_gradients, self.generator.trainable_weights)\n",
        "    )\n",
        "    self.d_optimizer.apply_gradients(\n",
        "        zip(discriminator_gradients, self.discriminator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    # update the augmentation probability based on the discriminator's performance\n",
        "    self.augmenter.update(real_logits)\n",
        "\n",
        "    self.generator_loss_tracker.update_state(generator_loss)\n",
        "    self.discriminator_loss_tracker.update_state(discriminator_loss)\n",
        "    self.real_accuracy.update_state(1.0, step(real_logits))\n",
        "    self.generated_accuracy.update_state(0.0, step(generated_logits))\n",
        "    self.augmentation_probability_tracker.update_state(self.augmenter.probability)\n",
        "\n",
        "    # track the exponential moving average of the generator's weights to decrease\n",
        "    # variance in the generation quality\n",
        "    for weight, ema_weight in zip(self.generator.weights, self.ema_generator.weights):\n",
        "      ema_weight.assign(ema * ema_weight + (1 - ema) * weight)\n",
        "\n",
        "    # KID is not measured during the training phase for computational efficiency\n",
        "    return {m.name: m.result() for m in self.metrics[:-1]}\n",
        "\n",
        "    \n",
        "  def test_step(self, data):\n",
        "    real_images,labels=data\n",
        "    generated_images = self.generate(labels,batch_size=batch_size, training=False)\n",
        "\n",
        "    self.kid.update_state(real_images, generated_images)\n",
        "\n",
        "    # only KID is measured during the evaluation phase for computational efficiency\n",
        "    return {self.kid.name: self.kid.result()}\n",
        "\n",
        "  def plot_images(self, epoch=None, logs=None, num_rows=1, num_cols=5, interval=5):\n",
        "    # plot random generated images for visual evaluation of generation quality\n",
        "    if epoch is None or (epoch + 1) % interval == 0:\n",
        "      num_images = num_rows * num_cols\n",
        "      generated_images = self.generate(np.array([0,1,2,3,4]),batch_size=5, training=False)\n",
        "\n",
        "      plt.figure(figsize=(num_cols * 2.0, num_rows * 2.0))\n",
        "      for row in range(num_rows):\n",
        "        for col in range(num_cols):\n",
        "          index = row * num_cols + col\n",
        "          plt.subplot(num_rows, num_cols, index + 1)\n",
        "          plt.imshow(generated_images[index])\n",
        "          plt.axis(\"off\")\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO2UFfsf0one"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/GAN GENERATED/chk'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator=generator,discriminator=discriminator)\n",
        "\n",
        "manager = tf.train.CheckpointManager(\n",
        "    checkpoint, directory=checkpoint_dir, max_to_keep=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ7yqtT90_oA"
      },
      "outputs": [],
      "source": [
        "# #restoring checkpoint. verify using assert below\n",
        "\n",
        "# checkpoint_dir=('/content/drive/MyDrive/GAN GENERATED/chk')\n",
        "\n",
        "# #checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir)).assert_consumed()\n",
        "\n",
        "# checkpoint.restore(manager.latest_checkpoint).assert_consumed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9EyWVI88ow8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "%matplotlib inline\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "\n",
        "  # def on_epoch_begin(self, epoch, logs=None):\n",
        "  #   global epochh\n",
        "  #   epochh=epoch+1\n",
        "    \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "  #   print('GAN MONITOR',logs.keys)\n",
        "    if (epoch+1) % 15 == 0:\n",
        "      manager.save()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      pth=['laptop', 'keyboard', 'mouse', 'headphone', 'monitor']\n",
        "      path=['/content/drive/MyDrive/GAN GENERATED/'+i for i in pth]\n",
        "            \n",
        "      classes=[[0],[1],[2],[3],[4]]\n",
        "      classes=np.array(classes,dtype=np.int8)  #(5, 1)\n",
        "\n",
        "      generated_images = self.model.generate(classes,batch_size=5, training=False)\n",
        "      generated_images = (generated_images*127.5)+127.5\n",
        "\n",
        "      for i in range(num_classes):\n",
        "        img = generated_images[i].numpy()\n",
        "        img = keras.preprocessing.image.array_to_img(img) \n",
        "      \n",
        "        img.save(path[i]+'/'+str(epoch+1)+'.png')\n",
        "      \n",
        "    \n",
        "    \n",
        "\n",
        "monitor=GANMonitor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxZ-Kkfxqdh1",
        "outputId": "6c640e8e-eacc-4de2-d770-7a1d2629a777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 468s 11s/step - g_loss: 0.6706 - d_loss: 1.1307 - real_acc: 0.5164 - gen_acc: 0.4762 - aug_p: 3.3865e-04 - val_kid: 6.6368\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7014 - d_loss: 0.6931 - real_acc: 0.0000e+00 - gen_acc: 1.0000 - aug_p: 0.0000e+00 - val_kid: 3.7126\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6647 - d_loss: 0.6811 - real_acc: 0.5395 - gen_acc: 0.5831 - aug_p: 2.2023e-04 - val_kid: 5.2697\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7579 - d_loss: 0.5519 - real_acc: 0.5189 - gen_acc: 0.7944 - aug_p: 1.7253e-04 - val_kid: 3.4059\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 56s 1s/step - g_loss: 0.9584 - d_loss: 0.7870 - real_acc: 0.2549 - gen_acc: 0.8734 - aug_p: 3.4868e-05 - val_kid: 3.9116\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7840 - d_loss: 0.6640 - real_acc: 0.2673 - gen_acc: 0.8627 - aug_p: 2.4013e-04 - val_kid: 3.5063\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7110 - d_loss: 0.6935 - real_acc: 0.2475 - gen_acc: 0.7434 - aug_p: 1.7270e-05 - val_kid: 3.9911\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7966 - d_loss: 0.7558 - real_acc: 0.3429 - gen_acc: 0.7311 - aug_p: 1.0280e-04 - val_kid: 5.3203\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7981 - d_loss: 0.6011 - real_acc: 0.7286 - gen_acc: 0.6217 - aug_p: 3.1250e-04 - val_kid: 4.1001\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 52s 1s/step - g_loss: 0.7692 - d_loss: 0.9096 - real_acc: 0.2081 - gen_acc: 0.7928 - aug_p: 5.1645e-05 - val_kid: 2.3162\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6947 - d_loss: 0.6839 - real_acc: 0.4260 - gen_acc: 0.5535 - aug_p: 8.1414e-05 - val_kid: 3.0377\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7116 - d_loss: 0.6812 - real_acc: 0.2377 - gen_acc: 0.8495 - aug_p: 0.0000e+00 - val_kid: 1.9001\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7119 - d_loss: 0.6453 - real_acc: 0.4745 - gen_acc: 0.6998 - aug_p: 4.6053e-06 - val_kid: 2.1202\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.8155 - d_loss: 0.6039 - real_acc: 0.5066 - gen_acc: 0.8322 - aug_p: 9.0460e-06 - val_kid: 1.6813\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 1.0404 - d_loss: 0.5878 - real_acc: 0.7410 - gen_acc: 0.7714 - aug_p: 2.1661e-04 - val_kid: 1.7202\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 1.1816 - d_loss: 0.5017 - real_acc: 0.6990 - gen_acc: 0.8363 - aug_p: 1.2928e-04 - val_kid: 2.0145\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.9094 - d_loss: 0.6158 - real_acc: 0.4975 - gen_acc: 0.8495 - aug_p: 1.1842e-05 - val_kid: 1.2028\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8408 - d_loss: 0.7561 - real_acc: 0.2039 - gen_acc: 0.9046 - aug_p: 1.1842e-05 - val_kid: 1.6012\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.4192 - d_loss: 0.6799 - real_acc: 0.5493 - gen_acc: 0.8512 - aug_p: 6.0362e-05 - val_kid: 1.2787\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 52s 1s/step - g_loss: 1.3049 - d_loss: 0.6274 - real_acc: 0.5773 - gen_acc: 0.7459 - aug_p: 1.3289e-04 - val_kid: 1.1008\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7409 - d_loss: 0.7655 - real_acc: 0.4918 - gen_acc: 0.6727 - aug_p: 1.8092e-05 - val_kid: 1.3519\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8480 - d_loss: 0.6877 - real_acc: 0.3076 - gen_acc: 0.7738 - aug_p: 6.9079e-06 - val_kid: 1.8078\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7509 - d_loss: 0.7209 - real_acc: 0.1012 - gen_acc: 0.9416 - aug_p: 3.9474e-06 - val_kid: 2.4919\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7096 - d_loss: 0.6848 - real_acc: 0.5502 - gen_acc: 0.5633 - aug_p: 1.2072e-04 - val_kid: 2.1850\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7285 - d_loss: 0.8034 - real_acc: 0.2599 - gen_acc: 0.7952 - aug_p: 5.5428e-05 - val_kid: 1.5769\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7207 - d_loss: 0.6888 - real_acc: 0.2673 - gen_acc: 0.8174 - aug_p: 2.3520e-05 - val_kid: 1.8156\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7852 - d_loss: 0.6963 - real_acc: 0.2837 - gen_acc: 0.7829 - aug_p: 3.0099e-05 - val_kid: 1.3148\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7318 - d_loss: 0.6853 - real_acc: 0.5288 - gen_acc: 0.5872 - aug_p: 3.4375e-05 - val_kid: 0.6604\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8047 - d_loss: 0.6798 - real_acc: 0.4474 - gen_acc: 0.7278 - aug_p: 3.2730e-05 - val_kid: 1.5591\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7285 - d_loss: 0.7050 - real_acc: 0.5617 - gen_acc: 0.6653 - aug_p: 2.4836e-05 - val_kid: 2.0088\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6962 - d_loss: 0.6815 - real_acc: 0.5469 - gen_acc: 0.5929 - aug_p: 5.9046e-05 - val_kid: 2.7775\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7580 - d_loss: 1.1330 - real_acc: 0.3750 - gen_acc: 0.7566 - aug_p: 3.8816e-05 - val_kid: 0.9579\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7008 - d_loss: 0.6934 - real_acc: 0.3232 - gen_acc: 0.6826 - aug_p: 0.0000e+00 - val_kid: 0.9646\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6951 - d_loss: 0.6930 - real_acc: 0.5025 - gen_acc: 0.5082 - aug_p: 2.7961e-06 - val_kid: 1.1760\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6983 - d_loss: 0.6697 - real_acc: 0.5600 - gen_acc: 0.5658 - aug_p: 1.5789e-05 - val_kid: 1.1294\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7972 - d_loss: 0.7085 - real_acc: 0.0452 - gen_acc: 0.9679 - aug_p: 0.0000e+00 - val_kid: 1.8978\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6946 - d_loss: 0.6934 - real_acc: 0.4474 - gen_acc: 0.5543 - aug_p: 0.0000e+00 - val_kid: 0.7653\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6917 - d_loss: 0.6928 - real_acc: 0.5880 - gen_acc: 0.4416 - aug_p: 4.0132e-05 - val_kid: 0.6837\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8230 - d_loss: 0.6480 - real_acc: 0.5699 - gen_acc: 0.6867 - aug_p: 3.5526e-05 - val_kid: 0.7782\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 51s 1s/step - g_loss: 0.8829 - d_loss: 0.6810 - real_acc: 0.5271 - gen_acc: 0.7311 - aug_p: 2.5164e-05 - val_kid: 0.6411\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6938 - d_loss: 0.6895 - real_acc: 0.4408 - gen_acc: 0.6151 - aug_p: 5.9868e-05 - val_kid: 1.3474\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6977 - d_loss: 0.6944 - real_acc: 0.6546 - gen_acc: 0.4046 - aug_p: 4.1020e-04 - val_kid: 1.0994\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6840 - d_loss: 0.9132 - real_acc: 0.3725 - gen_acc: 0.6686 - aug_p: 3.9309e-05 - val_kid: 1.6678\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7256 - d_loss: 0.6934 - real_acc: 0.1299 - gen_acc: 0.8816 - aug_p: 0.0000e+00 - val_kid: 1.0660\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7059 - d_loss: 0.7062 - real_acc: 0.4005 - gen_acc: 0.6398 - aug_p: 1.8158e-04 - val_kid: 1.7529\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7705 - d_loss: 0.6848 - real_acc: 0.2607 - gen_acc: 0.8183 - aug_p: 4.4408e-06 - val_kid: 1.2330\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8552 - d_loss: 0.6130 - real_acc: 0.3808 - gen_acc: 0.8610 - aug_p: 5.0987e-06 - val_kid: 1.5570\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6982 - d_loss: 0.6937 - real_acc: 0.3454 - gen_acc: 0.6308 - aug_p: 9.2105e-06 - val_kid: 1.3469\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6957 - d_loss: 0.6981 - real_acc: 0.3446 - gen_acc: 0.6686 - aug_p: 4.0789e-05 - val_kid: 1.0333\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7163 - d_loss: 0.6893 - real_acc: 0.1678 - gen_acc: 0.8470 - aug_p: 3.7007e-05 - val_kid: 1.3230\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6919 - d_loss: 0.7021 - real_acc: 0.2434 - gen_acc: 0.7262 - aug_p: 2.0559e-05 - val_kid: 1.1899\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7852 - d_loss: 0.7124 - real_acc: 0.4186 - gen_acc: 0.6431 - aug_p: 2.4507e-05 - val_kid: 0.9327\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6859 - d_loss: 0.6899 - real_acc: 0.4836 - gen_acc: 0.5559 - aug_p: 8.2566e-05 - val_kid: 2.2453\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6968 - d_loss: 0.6889 - real_acc: 0.4268 - gen_acc: 0.5748 - aug_p: 5.1316e-05 - val_kid: 1.8015\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6936 - d_loss: 0.6931 - real_acc: 0.5082 - gen_acc: 0.5156 - aug_p: 0.0000e+00 - val_kid: 1.9777\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7290 - d_loss: 0.6604 - real_acc: 0.5732 - gen_acc: 0.6094 - aug_p: 3.8816e-05 - val_kid: 1.8850\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.3282 - d_loss: 1.6486 - real_acc: 0.5222 - gen_acc: 0.7089 - aug_p: 1.8109e-04 - val_kid: 1.9704\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6948 - d_loss: 0.6926 - real_acc: 0.4169 - gen_acc: 0.5839 - aug_p: 2.1053e-05 - val_kid: 2.2505\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6850 - d_loss: 0.6917 - real_acc: 0.5576 - gen_acc: 0.4803 - aug_p: 7.2368e-05 - val_kid: 4.0575\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7034 - d_loss: 0.6932 - real_acc: 0.3289 - gen_acc: 0.7064 - aug_p: 3.1250e-06 - val_kid: 2.0751\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6717 - d_loss: 0.7451 - real_acc: 0.5913 - gen_acc: 0.4326 - aug_p: 9.2928e-05 - val_kid: 2.9477\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7110 - d_loss: 0.6979 - real_acc: 0.2410 - gen_acc: 0.7985 - aug_p: 5.1645e-05 - val_kid: 2.1711\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7349 - d_loss: 0.7821 - real_acc: 0.1151 - gen_acc: 0.9449 - aug_p: 8.0592e-06 - val_kid: 1.6414\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7367 - d_loss: 0.6946 - real_acc: 0.2492 - gen_acc: 0.7681 - aug_p: 0.0000e+00 - val_kid: 1.8941\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6924 - d_loss: 0.6931 - real_acc: 0.5329 - gen_acc: 0.4811 - aug_p: 0.0000e+00 - val_kid: 2.4627\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7026 - d_loss: 0.6964 - real_acc: 0.3701 - gen_acc: 0.6604 - aug_p: 1.4803e-06 - val_kid: 2.5898\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7568 - d_loss: 0.6867 - real_acc: 0.4400 - gen_acc: 0.7599 - aug_p: 1.1020e-05 - val_kid: 2.2134\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9593 - d_loss: 0.6211 - real_acc: 0.6719 - gen_acc: 0.6217 - aug_p: 1.0411e-04 - val_kid: 2.4904\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7883 - d_loss: 0.6579 - real_acc: 0.6480 - gen_acc: 0.6201 - aug_p: 2.3520e-05 - val_kid: 2.0792\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7831 - d_loss: 0.6704 - real_acc: 0.5773 - gen_acc: 0.5913 - aug_p: 2.6316e-05 - val_kid: 1.8964\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.0538 - d_loss: 0.6941 - real_acc: 0.6628 - gen_acc: 0.6883 - aug_p: 7.2697e-05 - val_kid: 2.0973\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0824 - d_loss: 0.5745 - real_acc: 0.6653 - gen_acc: 0.8503 - aug_p: 2.1875e-05 - val_kid: 1.9909\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.1760 - d_loss: 0.5393 - real_acc: 0.6571 - gen_acc: 0.8438 - aug_p: 2.9934e-05 - val_kid: 2.8724\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9380 - d_loss: 0.6088 - real_acc: 0.6521 - gen_acc: 0.7245 - aug_p: 1.3651e-05 - val_kid: 6.1432\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.8704 - d_loss: 0.6388 - real_acc: 0.5773 - gen_acc: 0.7459 - aug_p: 8.5526e-06 - val_kid: 4.1201\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.9512 - d_loss: 0.6250 - real_acc: 0.6201 - gen_acc: 0.7393 - aug_p: 5.4112e-05 - val_kid: 1.0987\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9894 - d_loss: 0.5981 - real_acc: 0.4778 - gen_acc: 0.8438 - aug_p: 9.0460e-06 - val_kid: 0.8688\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8433 - d_loss: 0.6786 - real_acc: 0.5855 - gen_acc: 0.6752 - aug_p: 5.6579e-05 - val_kid: 0.7369\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.2895 - d_loss: 0.5123 - real_acc: 0.7410 - gen_acc: 0.7664 - aug_p: 4.3092e-05 - val_kid: 0.9079\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 1.0265 - d_loss: 0.7781 - real_acc: 0.7788 - gen_acc: 0.5658 - aug_p: 5.8043e-04 - val_kid: 1.0685\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7049 - d_loss: 0.6840 - real_acc: 0.5831 - gen_acc: 0.6020 - aug_p: 2.5888e-04 - val_kid: 1.7098\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7802 - d_loss: 0.7009 - real_acc: 0.3939 - gen_acc: 0.7952 - aug_p: 1.9572e-05 - val_kid: 2.8520\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8177 - d_loss: 0.6557 - real_acc: 0.5214 - gen_acc: 0.8026 - aug_p: 7.9112e-05 - val_kid: 3.2102\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7267 - d_loss: 0.6942 - real_acc: 0.1957 - gen_acc: 0.8339 - aug_p: 3.1250e-06 - val_kid: 4.6907\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9254 - d_loss: 0.6505 - real_acc: 0.6003 - gen_acc: 0.7270 - aug_p: 3.4868e-05 - val_kid: 4.5527\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7422 - d_loss: 0.6624 - real_acc: 0.4951 - gen_acc: 0.6266 - aug_p: 1.6447e-05 - val_kid: 4.2859\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7503 - d_loss: 0.6869 - real_acc: 0.4046 - gen_acc: 0.6982 - aug_p: 2.1053e-05 - val_kid: 2.3825\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7942 - d_loss: 0.6586 - real_acc: 0.5000 - gen_acc: 0.6941 - aug_p: 1.3158e-05 - val_kid: 1.5775\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8559 - d_loss: 0.6499 - real_acc: 0.5436 - gen_acc: 0.7344 - aug_p: 7.1053e-05 - val_kid: 2.1908\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7372 - d_loss: 0.7916 - real_acc: 0.4589 - gen_acc: 0.6645 - aug_p: 0.0000e+00 - val_kid: 1.4642\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7345 - d_loss: 0.6735 - real_acc: 0.5461 - gen_acc: 0.6332 - aug_p: 1.7270e-05 - val_kid: 1.8644\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7302 - d_loss: 0.6821 - real_acc: 0.5436 - gen_acc: 0.5748 - aug_p: 2.5493e-05 - val_kid: 1.5048\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7571 - d_loss: 0.6737 - real_acc: 0.5090 - gen_acc: 0.6308 - aug_p: 5.2632e-06 - val_kid: 1.3855\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6918 - d_loss: 0.6931 - real_acc: 0.5502 - gen_acc: 0.4482 - aug_p: 4.6053e-06 - val_kid: 2.0920\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 1.0140 - d_loss: 0.6955 - real_acc: 0.6595 - gen_acc: 0.4770 - aug_p: 3.5263e-04 - val_kid: 3.4624\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0280 - d_loss: 0.6942 - real_acc: 0.5008 - gen_acc: 0.7771 - aug_p: 2.1711e-05 - val_kid: 1.6826\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.3221 - d_loss: 0.6210 - real_acc: 0.7336 - gen_acc: 0.5921 - aug_p: 2.1349e-04 - val_kid: 2.6485\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7236 - d_loss: 0.6880 - real_acc: 0.5008 - gen_acc: 0.6225 - aug_p: 3.8322e-05 - val_kid: 1.9788\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6915 - d_loss: 0.6936 - real_acc: 0.5222 - gen_acc: 0.4515 - aug_p: 2.9605e-06 - val_kid: 2.3349\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6900 - real_acc: 0.5888 - gen_acc: 0.4786 - aug_p: 4.6382e-05 - val_kid: 3.7571\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7139 - d_loss: 0.6969 - real_acc: 0.4819 - gen_acc: 0.6620 - aug_p: 1.0855e-05 - val_kid: 6.7749\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7623 - d_loss: 0.6843 - real_acc: 0.4696 - gen_acc: 0.6324 - aug_p: 6.7434e-06 - val_kid: 7.0250\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7282 - d_loss: 0.6879 - real_acc: 0.4918 - gen_acc: 0.6176 - aug_p: 1.7434e-05 - val_kid: 2.7568\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7152 - d_loss: 0.7826 - real_acc: 0.4383 - gen_acc: 0.6456 - aug_p: 1.9243e-05 - val_kid: 3.7663\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7587 - d_loss: 0.6709 - real_acc: 0.5321 - gen_acc: 0.6217 - aug_p: 1.4309e-05 - val_kid: 3.0364\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8012 - d_loss: 0.6541 - real_acc: 0.5650 - gen_acc: 0.6957 - aug_p: 6.7434e-06 - val_kid: 1.4620\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0864 - d_loss: 0.6251 - real_acc: 0.6604 - gen_acc: 0.8051 - aug_p: 6.0855e-06 - val_kid: 2.6943\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.2461 - d_loss: 0.4618 - real_acc: 0.8002 - gen_acc: 0.7352 - aug_p: 1.0493e-04 - val_kid: 3.9605\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.7512 - d_loss: 0.3590 - real_acc: 0.8183 - gen_acc: 0.9186 - aug_p: 4.0987e-04 - val_kid: 3.7196\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 1.7629 - d_loss: 0.3943 - real_acc: 0.8002 - gen_acc: 0.8692 - aug_p: 2.2023e-04 - val_kid: 4.9612\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.5614 - d_loss: 0.5220 - real_acc: 0.7771 - gen_acc: 0.9062 - aug_p: 9.2434e-05 - val_kid: 3.7213\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9988 - d_loss: 0.6144 - real_acc: 0.5633 - gen_acc: 0.8322 - aug_p: 2.9605e-06 - val_kid: 3.4009\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.1209 - d_loss: 0.5463 - real_acc: 0.7188 - gen_acc: 0.7648 - aug_p: 1.2664e-05 - val_kid: 2.3195\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.2467 - d_loss: 0.5543 - real_acc: 0.6620 - gen_acc: 0.8043 - aug_p: 2.9770e-05 - val_kid: 0.9625\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9113 - d_loss: 0.6441 - real_acc: 0.5674 - gen_acc: 0.6661 - aug_p: 1.0526e-05 - val_kid: 2.0504\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7381 - d_loss: 0.6960 - real_acc: 0.4663 - gen_acc: 0.5905 - aug_p: 2.2368e-05 - val_kid: 1.9878\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7180 - d_loss: 0.6857 - real_acc: 0.5625 - gen_acc: 0.5748 - aug_p: 1.1349e-05 - val_kid: 3.8238\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8177 - d_loss: 0.6701 - real_acc: 0.4753 - gen_acc: 0.7278 - aug_p: 2.0066e-05 - val_kid: 3.1903\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7128 - d_loss: 0.6916 - real_acc: 0.4901 - gen_acc: 0.5617 - aug_p: 3.1250e-06 - val_kid: 6.1943\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7134 - d_loss: 0.6825 - real_acc: 0.4128 - gen_acc: 0.6382 - aug_p: 2.3026e-06 - val_kid: 6.5281\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0418 - d_loss: 0.6093 - real_acc: 0.6398 - gen_acc: 0.7426 - aug_p: 9.7039e-06 - val_kid: 3.8053\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0400 - d_loss: 0.6477 - real_acc: 0.5863 - gen_acc: 0.7747 - aug_p: 1.4803e-05 - val_kid: 2.9908\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8138 - d_loss: 0.6295 - real_acc: 0.6118 - gen_acc: 0.7319 - aug_p: 4.2763e-06 - val_kid: 3.3113\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0626 - d_loss: 0.7342 - real_acc: 0.4622 - gen_acc: 0.7541 - aug_p: 1.4803e-06 - val_kid: 4.3110\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7933 - d_loss: 0.6825 - real_acc: 0.3980 - gen_acc: 0.7401 - aug_p: 3.0263e-05 - val_kid: 3.5899\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7961 - d_loss: 0.6656 - real_acc: 0.7401 - gen_acc: 0.5033 - aug_p: 2.7187e-04 - val_kid: 2.7800\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6938 - d_loss: 0.6932 - real_acc: 0.5132 - gen_acc: 0.5099 - aug_p: 5.0987e-06 - val_kid: 3.5569\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7147 - d_loss: 0.6912 - real_acc: 0.4465 - gen_acc: 0.6086 - aug_p: 3.7829e-06 - val_kid: 6.7661\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.3510 - d_loss: 0.8923 - real_acc: 0.5576 - gen_acc: 0.6151 - aug_p: 5.2632e-06 - val_kid: 5.4496\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.8323 - d_loss: 0.6550 - real_acc: 0.3627 - gen_acc: 0.8396 - aug_p: 6.0855e-06 - val_kid: 4.3283\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7096 - d_loss: 0.6820 - real_acc: 0.5896 - gen_acc: 0.6077 - aug_p: 5.9539e-05 - val_kid: 1.6391\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7966 - d_loss: 0.6750 - real_acc: 0.3191 - gen_acc: 0.8314 - aug_p: 3.1250e-06 - val_kid: 2.8615\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7521 - d_loss: 0.6632 - real_acc: 0.5255 - gen_acc: 0.6743 - aug_p: 3.1250e-06 - val_kid: 3.4973\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7352 - d_loss: 0.6991 - real_acc: 0.2056 - gen_acc: 0.8265 - aug_p: 3.9474e-06 - val_kid: 3.1935\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7096 - d_loss: 0.6880 - real_acc: 0.5099 - gen_acc: 0.5411 - aug_p: 1.2336e-05 - val_kid: 2.9611\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 3.0128 - d_loss: 0.5723 - real_acc: 0.8314 - gen_acc: 0.7204 - aug_p: 8.5132e-04 - val_kid: 1.5061\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.0784 - d_loss: 0.5808 - real_acc: 0.5896 - gen_acc: 0.8322 - aug_p: 1.0362e-05 - val_kid: 1.0281\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9572 - d_loss: 0.6242 - real_acc: 0.6012 - gen_acc: 0.7393 - aug_p: 1.0033e-05 - val_kid: 2.5342\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7977 - d_loss: 0.6579 - real_acc: 0.3660 - gen_acc: 0.8224 - aug_p: 5.4276e-06 - val_kid: 3.3623\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7952 - d_loss: 0.6691 - real_acc: 0.3931 - gen_acc: 0.7796 - aug_p: 5.9211e-06 - val_kid: 2.1029\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7139 - d_loss: 0.7403 - real_acc: 0.5354 - gen_acc: 0.5230 - aug_p: 4.6053e-06 - val_kid: 2.3581\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6943 - d_loss: 0.6955 - real_acc: 0.4194 - gen_acc: 0.5567 - aug_p: 1.1020e-05 - val_kid: 2.4817\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9087 - d_loss: 0.6339 - real_acc: 0.6340 - gen_acc: 0.7368 - aug_p: 3.6678e-05 - val_kid: 2.5895\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8973 - d_loss: 0.6312 - real_acc: 0.6160 - gen_acc: 0.7048 - aug_p: 1.4309e-05 - val_kid: 2.2690\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 1.0959 - d_loss: 0.5518 - real_acc: 0.7015 - gen_acc: 0.7590 - aug_p: 9.1447e-05 - val_kid: 2.3605\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9278 - d_loss: 0.6353 - real_acc: 0.6102 - gen_acc: 0.6933 - aug_p: 5.1645e-05 - val_kid: 1.0068\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8128 - d_loss: 0.6531 - real_acc: 0.4901 - gen_acc: 0.7039 - aug_p: 1.4638e-05 - val_kid: 1.0896\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8569 - d_loss: 0.7052 - real_acc: 0.4564 - gen_acc: 0.8322 - aug_p: 2.4178e-05 - val_kid: 2.0156\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8347 - d_loss: 1.9227 - real_acc: 0.3281 - gen_acc: 0.8824 - aug_p: 1.4803e-06 - val_kid: 1.3829\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8552 - d_loss: 0.6221 - real_acc: 0.3660 - gen_acc: 0.8947 - aug_p: 2.3026e-05 - val_kid: 2.3541\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7325 - d_loss: 0.6827 - real_acc: 0.4309 - gen_acc: 0.6924 - aug_p: 3.5691e-05 - val_kid: 1.1502\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7061 - d_loss: 0.6883 - real_acc: 0.4202 - gen_acc: 0.5905 - aug_p: 1.0362e-05 - val_kid: 2.8986\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7138 - d_loss: 0.6930 - real_acc: 0.4778 - gen_acc: 0.5707 - aug_p: 1.7763e-05 - val_kid: 3.3003\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8346 - d_loss: 0.6893 - real_acc: 0.3651 - gen_acc: 0.7944 - aug_p: 8.9309e-05 - val_kid: 2.1809\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7165 - d_loss: 0.6787 - real_acc: 0.5946 - gen_acc: 0.5477 - aug_p: 2.8980e-04 - val_kid: 1.1171\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6991 - d_loss: 0.6937 - real_acc: 0.3964 - gen_acc: 0.6201 - aug_p: 2.9605e-06 - val_kid: 1.2750\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7324 - d_loss: 0.6980 - real_acc: 0.4104 - gen_acc: 0.5633 - aug_p: 9.2105e-06 - val_kid: 1.3256\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7123 - d_loss: 0.6877 - real_acc: 0.4679 - gen_acc: 0.6192 - aug_p: 6.2500e-06 - val_kid: 1.0522\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7915 - d_loss: 0.6568 - real_acc: 0.4227 - gen_acc: 0.8199 - aug_p: 6.5789e-07 - val_kid: 1.2061\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 1.2302 - d_loss: 0.7255 - real_acc: 0.5419 - gen_acc: 0.6900 - aug_p: 7.3191e-05 - val_kid: 1.9261\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6963 - d_loss: 0.6943 - real_acc: 0.4285 - gen_acc: 0.5535 - aug_p: 0.0000e+00 - val_kid: 6.2320\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6958 - d_loss: 0.6936 - real_acc: 0.4112 - gen_acc: 0.5806 - aug_p: 1.7434e-05 - val_kid: 28.6177\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6973 - d_loss: 0.6939 - real_acc: 0.4227 - gen_acc: 0.5543 - aug_p: 0.0000e+00 - val_kid: 7.6042\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6937 - real_acc: 0.4704 - gen_acc: 0.5000 - aug_p: 6.5789e-07 - val_kid: 14.0214\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7009 - d_loss: 0.6934 - real_acc: 0.3215 - gen_acc: 0.6678 - aug_p: 2.3026e-06 - val_kid: 10.1036\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6974 - d_loss: 0.6930 - real_acc: 0.4893 - gen_acc: 0.5485 - aug_p: 0.0000e+00 - val_kid: 13.3290\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6975 - d_loss: 0.6933 - real_acc: 0.5189 - gen_acc: 0.4811 - aug_p: 8.0592e-06 - val_kid: 14.6811\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6873 - d_loss: 0.7292 - real_acc: 0.5493 - gen_acc: 0.5049 - aug_p: 8.3882e-06 - val_kid: 13.5584\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7588 - d_loss: 0.6992 - real_acc: 0.5288 - gen_acc: 0.5954 - aug_p: 2.6974e-05 - val_kid: 15.1354\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7589 - d_loss: 0.7024 - real_acc: 0.5962 - gen_acc: 0.4556 - aug_p: 1.4079e-04 - val_kid: 6.9995\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6888 - d_loss: 0.6930 - real_acc: 0.6168 - gen_acc: 0.3997 - aug_p: 8.3059e-05 - val_kid: 10.9175\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6965 - d_loss: 0.6933 - real_acc: 0.4655 - gen_acc: 0.5387 - aug_p: 2.9605e-06 - val_kid: 6.6672\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7601 - d_loss: 0.6931 - real_acc: 0.4556 - gen_acc: 0.6340 - aug_p: 5.7566e-06 - val_kid: 3.0871\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7739 - d_loss: 0.6703 - real_acc: 0.4424 - gen_acc: 0.7319 - aug_p: 9.2105e-06 - val_kid: 10.5575\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9674 - d_loss: 0.6130 - real_acc: 0.4984 - gen_acc: 0.8224 - aug_p: 6.5789e-07 - val_kid: 2.5022\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7680 - d_loss: 0.6602 - real_acc: 0.5872 - gen_acc: 0.6250 - aug_p: 2.6480e-05 - val_kid: 1.2607\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9944 - d_loss: 0.5741 - real_acc: 0.6135 - gen_acc: 0.7459 - aug_p: 6.7434e-06 - val_kid: 2.6759\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8610 - d_loss: 0.7154 - real_acc: 0.6143 - gen_acc: 0.6242 - aug_p: 3.6842e-05 - val_kid: 1.5690\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9493 - d_loss: 0.6319 - real_acc: 0.5789 - gen_acc: 0.7401 - aug_p: 1.6283e-05 - val_kid: 2.5337\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7915 - d_loss: 0.6466 - real_acc: 0.5666 - gen_acc: 0.6735 - aug_p: 5.0987e-06 - val_kid: 1.4914\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8504 - d_loss: 0.6203 - real_acc: 0.4893 - gen_acc: 0.7615 - aug_p: 6.2500e-06 - val_kid: 1.9599\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8936 - d_loss: 0.6117 - real_acc: 0.4630 - gen_acc: 0.8051 - aug_p: 6.5789e-07 - val_kid: 1.4367\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7687 - d_loss: 0.6996 - real_acc: 0.5238 - gen_acc: 0.6768 - aug_p: 5.9211e-06 - val_kid: 1.9959\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7755 - d_loss: 0.6738 - real_acc: 0.5609 - gen_acc: 0.6036 - aug_p: 2.7467e-05 - val_kid: 2.2798\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6941 - d_loss: 0.6938 - real_acc: 0.4852 - gen_acc: 0.5033 - aug_p: 1.6447e-07 - val_kid: 4.5746\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7066 - d_loss: 0.6936 - real_acc: 0.3355 - gen_acc: 0.6711 - aug_p: 8.5526e-06 - val_kid: 2.6208\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6924 - d_loss: 0.6927 - real_acc: 0.5312 - gen_acc: 0.5090 - aug_p: 9.3750e-06 - val_kid: 3.3048\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8765 - d_loss: 0.7075 - real_acc: 0.6036 - gen_acc: 0.6094 - aug_p: 9.1118e-05 - val_kid: 1.4317\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8259 - d_loss: 0.6528 - real_acc: 0.6439 - gen_acc: 0.6299 - aug_p: 9.8684e-06 - val_kid: 1.3429\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 1.0547 - d_loss: 0.6224 - real_acc: 0.6702 - gen_acc: 0.7286 - aug_p: 3.2895e-05 - val_kid: 1.1112\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0231 - d_loss: 0.5703 - real_acc: 0.7204 - gen_acc: 0.7245 - aug_p: 8.1908e-05 - val_kid: 0.9242\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8291 - d_loss: 0.6603 - real_acc: 0.7336 - gen_acc: 0.4605 - aug_p: 3.4194e-04 - val_kid: 1.8786\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7686 - d_loss: 0.6868 - real_acc: 0.3882 - gen_acc: 0.6678 - aug_p: 4.5395e-05 - val_kid: 1.7301\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8211 - d_loss: 0.6470 - real_acc: 0.5419 - gen_acc: 0.7459 - aug_p: 6.1678e-05 - val_kid: 0.9417\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9247 - d_loss: 0.6353 - real_acc: 0.5798 - gen_acc: 0.6645 - aug_p: 3.1908e-05 - val_kid: 1.1265\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8314 - d_loss: 0.6707 - real_acc: 0.6094 - gen_acc: 0.6118 - aug_p: 1.9572e-05 - val_kid: 0.9451\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8317 - d_loss: 0.6747 - real_acc: 0.4120 - gen_acc: 0.7615 - aug_p: 3.1250e-06 - val_kid: 0.8605\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8910 - d_loss: 0.6246 - real_acc: 0.6242 - gen_acc: 0.7319 - aug_p: 9.7039e-06 - val_kid: 0.5648\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8417 - d_loss: 0.6500 - real_acc: 0.5789 - gen_acc: 0.7048 - aug_p: 1.9243e-05 - val_kid: 0.8810\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7823 - d_loss: 0.6624 - real_acc: 0.5164 - gen_acc: 0.6793 - aug_p: 2.9112e-05 - val_kid: 1.0827\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7863 - d_loss: 0.6729 - real_acc: 0.5329 - gen_acc: 0.6974 - aug_p: 5.4276e-06 - val_kid: 1.2797\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9093 - d_loss: 0.6199 - real_acc: 0.6160 - gen_acc: 0.7122 - aug_p: 1.4967e-05 - val_kid: 0.7961\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.0357 - d_loss: 0.5787 - real_acc: 0.6077 - gen_acc: 0.7615 - aug_p: 1.0855e-05 - val_kid: 1.4068\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9801 - d_loss: 0.5850 - real_acc: 0.6760 - gen_acc: 0.7418 - aug_p: 2.7632e-05 - val_kid: 1.6583\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.8981 - d_loss: 0.6409 - real_acc: 0.5962 - gen_acc: 0.6620 - aug_p: 8.4539e-05 - val_kid: 1.0398\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8651 - d_loss: 0.6287 - real_acc: 0.6053 - gen_acc: 0.6916 - aug_p: 8.2237e-06 - val_kid: 0.7332\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8861 - d_loss: 0.6152 - real_acc: 0.6637 - gen_acc: 0.6891 - aug_p: 5.9211e-06 - val_kid: 0.4874\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9073 - d_loss: 0.6453 - real_acc: 0.5090 - gen_acc: 0.7541 - aug_p: 3.6184e-06 - val_kid: 1.0863\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7427 - d_loss: 0.7252 - real_acc: 0.4276 - gen_acc: 0.6941 - aug_p: 9.3750e-06 - val_kid: 0.9834\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7400 - d_loss: 0.6891 - real_acc: 0.5814 - gen_acc: 0.5411 - aug_p: 8.2237e-06 - val_kid: 0.6947\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.9265 - d_loss: 0.5899 - real_acc: 0.5970 - gen_acc: 0.7706 - aug_p: 6.5789e-06 - val_kid: 0.6922\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0168 - d_loss: 0.5802 - real_acc: 0.6168 - gen_acc: 0.7755 - aug_p: 1.1349e-05 - val_kid: 0.5208\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.9416 - d_loss: 0.6777 - real_acc: 0.6299 - gen_acc: 0.6036 - aug_p: 9.0789e-05 - val_kid: 0.4644\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7306 - d_loss: 0.6826 - real_acc: 0.5461 - gen_acc: 0.5617 - aug_p: 1.4474e-05 - val_kid: 0.4636\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.8429 - d_loss: 0.6645 - real_acc: 0.5140 - gen_acc: 0.7015 - aug_p: 0.0000e+00 - val_kid: 0.5650\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7371 - d_loss: 0.6779 - real_acc: 0.5395 - gen_acc: 0.6053 - aug_p: 1.4145e-05 - val_kid: 0.6061\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7680 - d_loss: 0.6700 - real_acc: 0.4770 - gen_acc: 0.7007 - aug_p: 1.3158e-06 - val_kid: 0.4499\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7781 - d_loss: 0.6601 - real_acc: 0.5354 - gen_acc: 0.7015 - aug_p: 5.7566e-06 - val_kid: 0.3159\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7567 - d_loss: 0.6745 - real_acc: 0.5674 - gen_acc: 0.6612 - aug_p: 2.5164e-05 - val_kid: 0.5022\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7582 - d_loss: 0.6712 - real_acc: 0.4918 - gen_acc: 0.6908 - aug_p: 0.0000e+00 - val_kid: 0.8498\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7627 - d_loss: 0.6770 - real_acc: 0.4062 - gen_acc: 0.7434 - aug_p: 6.5789e-07 - val_kid: 0.8199\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7581 - d_loss: 0.6604 - real_acc: 0.5559 - gen_acc: 0.6719 - aug_p: 7.8947e-06 - val_kid: 1.8078\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8236 - d_loss: 0.6470 - real_acc: 0.5715 - gen_acc: 0.6883 - aug_p: 3.1250e-06 - val_kid: 0.6108\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7571 - d_loss: 0.6797 - real_acc: 0.5699 - gen_acc: 0.5715 - aug_p: 5.4605e-05 - val_kid: 1.3663\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7344 - d_loss: 0.6884 - real_acc: 0.4720 - gen_acc: 0.6184 - aug_p: 9.2105e-06 - val_kid: 1.1010\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7863 - d_loss: 0.6673 - real_acc: 0.4778 - gen_acc: 0.7311 - aug_p: 3.7829e-06 - val_kid: 0.7954\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8165 - d_loss: 0.6388 - real_acc: 0.5197 - gen_acc: 0.7755 - aug_p: 5.4276e-06 - val_kid: 0.4929\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.9774 - d_loss: 0.5330 - real_acc: 0.7730 - gen_acc: 0.7763 - aug_p: 2.5132e-04 - val_kid: 0.8217\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.6740 - d_loss: 0.5767 - real_acc: 0.8758 - gen_acc: 0.5312 - aug_p: 0.0012 - val_kid: 1.3276\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.8603 - d_loss: 0.6813 - real_acc: 0.6785 - gen_acc: 0.4071 - aug_p: 0.0010 - val_kid: 0.7028\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9107 - d_loss: 0.7240 - real_acc: 0.7714 - gen_acc: 0.3898 - aug_p: 7.8388e-04 - val_kid: 0.8900\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6997 - d_loss: 0.6945 - real_acc: 0.4367 - gen_acc: 0.5280 - aug_p: 1.4803e-06 - val_kid: 0.9470\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6977 - d_loss: 0.6942 - real_acc: 0.4227 - gen_acc: 0.5485 - aug_p: 0.0000e+00 - val_kid: 1.0199\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6984 - d_loss: 0.6941 - real_acc: 0.4852 - gen_acc: 0.5329 - aug_p: 2.3026e-06 - val_kid: 1.3961\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7446 - d_loss: 0.7045 - real_acc: 0.4959 - gen_acc: 0.5370 - aug_p: 3.6842e-05 - val_kid: 1.0740\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7993 - d_loss: 0.6970 - real_acc: 0.5757 - gen_acc: 0.5387 - aug_p: 4.0460e-05 - val_kid: 0.7174\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7757 - d_loss: 0.6581 - real_acc: 0.6102 - gen_acc: 0.6291 - aug_p: 7.5000e-05 - val_kid: 0.7417\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0044 - d_loss: 0.6302 - real_acc: 0.6513 - gen_acc: 0.7451 - aug_p: 1.3322e-05 - val_kid: 1.7117\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8065 - d_loss: 0.6616 - real_acc: 0.4926 - gen_acc: 0.6447 - aug_p: 2.7796e-05 - val_kid: 2.9132\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7115 - d_loss: 0.6919 - real_acc: 0.4844 - gen_acc: 0.5888 - aug_p: 2.0724e-05 - val_kid: 4.2042\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7046 - d_loss: 0.6929 - real_acc: 0.4959 - gen_acc: 0.5699 - aug_p: 4.6382e-05 - val_kid: 3.7364\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7387 - d_loss: 0.6797 - real_acc: 0.5370 - gen_acc: 0.5831 - aug_p: 1.6612e-05 - val_kid: 3.9744\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7599 - d_loss: 0.6700 - real_acc: 0.4679 - gen_acc: 0.7064 - aug_p: 5.0987e-06 - val_kid: 1.5291\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8120 - d_loss: 0.6441 - real_acc: 0.5041 - gen_acc: 0.7113 - aug_p: 2.4013e-05 - val_kid: 1.7820\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7127 - d_loss: 0.6937 - real_acc: 0.3964 - gen_acc: 0.6513 - aug_p: 3.0592e-05 - val_kid: 1.1428\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7488 - d_loss: 0.6957 - real_acc: 0.4342 - gen_acc: 0.6891 - aug_p: 3.1250e-05 - val_kid: 0.6320\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7337 - d_loss: 0.6990 - real_acc: 0.3750 - gen_acc: 0.6974 - aug_p: 4.6053e-06 - val_kid: 0.5210\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7251 - d_loss: 0.6790 - real_acc: 0.6480 - gen_acc: 0.5370 - aug_p: 3.0428e-05 - val_kid: 0.5124\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8195 - d_loss: 0.6862 - real_acc: 0.5905 - gen_acc: 0.5452 - aug_p: 1.4474e-05 - val_kid: 0.7083\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7092 - d_loss: 0.7348 - real_acc: 0.4762 - gen_acc: 0.6258 - aug_p: 7.2368e-06 - val_kid: 0.8816\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7020 - d_loss: 0.6897 - real_acc: 0.5617 - gen_acc: 0.5214 - aug_p: 5.4441e-05 - val_kid: 1.3821\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7095 - d_loss: 0.6925 - real_acc: 0.3479 - gen_acc: 0.6604 - aug_p: 1.8914e-05 - val_kid: 1.1920\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7039 - d_loss: 0.6907 - real_acc: 0.3627 - gen_acc: 0.6801 - aug_p: 2.0724e-05 - val_kid: 1.4452\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7462 - d_loss: 0.6952 - real_acc: 0.4934 - gen_acc: 0.5658 - aug_p: 4.5230e-05 - val_kid: 0.9833\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6979 - d_loss: 0.6924 - real_acc: 0.5452 - gen_acc: 0.4646 - aug_p: 1.4803e-05 - val_kid: 1.2028\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6983 - d_loss: 0.6936 - real_acc: 0.3890 - gen_acc: 0.5872 - aug_p: 3.7829e-06 - val_kid: 0.5778\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6970 - d_loss: 0.6931 - real_acc: 0.4408 - gen_acc: 0.5806 - aug_p: 1.4145e-05 - val_kid: 1.0987\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6892 - d_loss: 0.6915 - real_acc: 0.5173 - gen_acc: 0.5271 - aug_p: 2.6645e-05 - val_kid: 0.3560\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6936 - real_acc: 0.4918 - gen_acc: 0.5148 - aug_p: 0.0000e+00 - val_kid: 0.5840\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6928 - d_loss: 0.6942 - real_acc: 0.4868 - gen_acc: 0.5173 - aug_p: 1.1513e-06 - val_kid: 0.4266\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6965 - d_loss: 0.6938 - real_acc: 0.4095 - gen_acc: 0.5888 - aug_p: 0.0000e+00 - val_kid: 0.5248\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6933 - real_acc: 0.4827 - gen_acc: 0.5263 - aug_p: 0.0000e+00 - val_kid: 0.5352\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7076 - d_loss: 0.6904 - real_acc: 0.3010 - gen_acc: 0.7155 - aug_p: 6.2500e-06 - val_kid: 1.3923\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6969 - d_loss: 0.6934 - real_acc: 0.4342 - gen_acc: 0.5658 - aug_p: 6.4145e-06 - val_kid: 0.7049\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7586 - d_loss: 0.6674 - real_acc: 0.4877 - gen_acc: 0.7171 - aug_p: 1.4474e-05 - val_kid: 0.7599\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7175 - d_loss: 0.6919 - real_acc: 0.3380 - gen_acc: 0.6924 - aug_p: 1.4803e-06 - val_kid: 0.4991\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7084 - d_loss: 0.6934 - real_acc: 0.3799 - gen_acc: 0.6439 - aug_p: 9.8684e-06 - val_kid: 0.5122\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6874 - d_loss: 0.6925 - real_acc: 0.5247 - gen_acc: 0.5247 - aug_p: 2.3191e-05 - val_kid: 0.4761\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7164 - d_loss: 0.6881 - real_acc: 0.3882 - gen_acc: 0.6842 - aug_p: 6.0855e-06 - val_kid: 0.8904\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7140 - d_loss: 0.6946 - real_acc: 0.5115 - gen_acc: 0.5609 - aug_p: 3.1579e-05 - val_kid: 0.8523\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7032 - d_loss: 0.6897 - real_acc: 0.4490 - gen_acc: 0.6209 - aug_p: 2.1382e-06 - val_kid: 1.4712\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6999 - d_loss: 0.6867 - real_acc: 0.5551 - gen_acc: 0.5321 - aug_p: 6.5789e-07 - val_kid: 0.6918\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7008 - d_loss: 0.6859 - real_acc: 0.5345 - gen_acc: 0.5633 - aug_p: 1.1842e-05 - val_kid: 0.7925\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7722 - d_loss: 0.6746 - real_acc: 0.4893 - gen_acc: 0.6850 - aug_p: 2.3026e-06 - val_kid: 0.6527\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7583 - d_loss: 0.6784 - real_acc: 0.4745 - gen_acc: 0.6340 - aug_p: 5.9211e-06 - val_kid: 0.7394\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8160 - d_loss: 0.6574 - real_acc: 0.4753 - gen_acc: 0.7434 - aug_p: 2.9605e-06 - val_kid: 0.6648\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6964 - d_loss: 0.6831 - real_acc: 0.5469 - gen_acc: 0.5814 - aug_p: 1.2336e-05 - val_kid: 0.2009\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7210 - d_loss: 0.6869 - real_acc: 0.4762 - gen_acc: 0.6332 - aug_p: 1.8586e-05 - val_kid: 0.6817\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7636 - d_loss: 0.6702 - real_acc: 0.4844 - gen_acc: 0.7081 - aug_p: 1.4803e-06 - val_kid: 1.2121\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.8120 - d_loss: 0.6282 - real_acc: 0.6242 - gen_acc: 0.6785 - aug_p: 1.5789e-05 - val_kid: 1.0571\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7909 - d_loss: 0.6676 - real_acc: 0.5049 - gen_acc: 0.6809 - aug_p: 1.8750e-05 - val_kid: 0.7861\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7322 - d_loss: 0.6952 - real_acc: 0.2829 - gen_acc: 0.8059 - aug_p: 0.0000e+00 - val_kid: 1.7561\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8187 - d_loss: 0.6074 - real_acc: 0.3429 - gen_acc: 0.9219 - aug_p: 6.5789e-07 - val_kid: 1.1384\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7141 - d_loss: 0.6963 - real_acc: 0.3240 - gen_acc: 0.6727 - aug_p: 1.4638e-05 - val_kid: 0.8803\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7146 - d_loss: 0.6952 - real_acc: 0.3512 - gen_acc: 0.7237 - aug_p: 3.3388e-05 - val_kid: 0.9911\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7159 - d_loss: 0.6938 - real_acc: 0.2434 - gen_acc: 0.7664 - aug_p: 1.1513e-06 - val_kid: 0.7552\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6694 - d_loss: 0.7103 - real_acc: 0.5206 - gen_acc: 0.5584 - aug_p: 4.1776e-05 - val_kid: 0.9757\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7032 - d_loss: 0.6935 - real_acc: 0.3931 - gen_acc: 0.6464 - aug_p: 2.2368e-05 - val_kid: 0.7715\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7372 - d_loss: 0.6755 - real_acc: 0.4021 - gen_acc: 0.7245 - aug_p: 6.9079e-06 - val_kid: 1.7911\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7083 - d_loss: 0.6946 - real_acc: 0.4169 - gen_acc: 0.5962 - aug_p: 1.6776e-05 - val_kid: 1.2135\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7014 - d_loss: 0.6934 - real_acc: 0.3939 - gen_acc: 0.6365 - aug_p: 1.0197e-05 - val_kid: 1.4013\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6967 - d_loss: 0.6931 - real_acc: 0.4227 - gen_acc: 0.5938 - aug_p: 4.2105e-05 - val_kid: 0.7915\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6936 - d_loss: 0.7002 - real_acc: 0.4243 - gen_acc: 0.5847 - aug_p: 6.7434e-06 - val_kid: 1.6988\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7235 - d_loss: 0.6853 - real_acc: 0.6464 - gen_acc: 0.4926 - aug_p: 9.7039e-05 - val_kid: 1.3966\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7248 - d_loss: 0.6951 - real_acc: 0.3396 - gen_acc: 0.7015 - aug_p: 2.0641e-04 - val_kid: 1.1023\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7079 - d_loss: 0.6916 - real_acc: 0.4268 - gen_acc: 0.5905 - aug_p: 1.9408e-05 - val_kid: 0.9436\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7877 - d_loss: 0.6795 - real_acc: 0.4219 - gen_acc: 0.6998 - aug_p: 2.6151e-05 - val_kid: 0.3492\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8045 - d_loss: 0.6256 - real_acc: 0.2664 - gen_acc: 0.9293 - aug_p: 1.0197e-05 - val_kid: 0.6847\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7093 - d_loss: 0.6933 - real_acc: 0.3717 - gen_acc: 0.6554 - aug_p: 1.7763e-05 - val_kid: 0.9150\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.7033 - d_loss: 0.6952 - real_acc: 0.4852 - gen_acc: 0.5132 - aug_p: 3.9638e-05 - val_kid: 0.4657\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7166 - d_loss: 0.7242 - real_acc: 0.5238 - gen_acc: 0.5025 - aug_p: 1.8914e-05 - val_kid: 0.6023\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6893 - d_loss: 0.6933 - real_acc: 0.5970 - gen_acc: 0.4137 - aug_p: 6.5954e-05 - val_kid: 0.6982\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7052 - d_loss: 0.6965 - real_acc: 0.3503 - gen_acc: 0.6785 - aug_p: 1.6612e-05 - val_kid: 0.6135\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6967 - d_loss: 0.6930 - real_acc: 0.4613 - gen_acc: 0.5502 - aug_p: 6.5789e-07 - val_kid: 0.6058\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7227 - d_loss: 0.6913 - real_acc: 0.4054 - gen_acc: 0.6505 - aug_p: 1.3651e-05 - val_kid: 0.7645\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7537 - d_loss: 0.7038 - real_acc: 0.6250 - gen_acc: 0.4885 - aug_p: 2.6316e-04 - val_kid: 0.8240\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6908 - d_loss: 0.6938 - real_acc: 0.5428 - gen_acc: 0.4268 - aug_p: 0.0000e+00 - val_kid: 0.9496\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7233 - d_loss: 0.6810 - real_acc: 0.5715 - gen_acc: 0.5683 - aug_p: 4.2928e-05 - val_kid: 0.7250\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7814 - d_loss: 0.6496 - real_acc: 0.5403 - gen_acc: 0.7155 - aug_p: 3.8487e-05 - val_kid: 0.7750\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7928 - d_loss: 0.6783 - real_acc: 0.3832 - gen_acc: 0.6990 - aug_p: 4.8684e-05 - val_kid: 0.4537\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8271 - d_loss: 0.6862 - real_acc: 0.5395 - gen_acc: 0.4671 - aug_p: 2.7237e-04 - val_kid: 0.5676\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7080 - d_loss: 0.6895 - real_acc: 0.5049 - gen_acc: 0.5896 - aug_p: 5.9145e-04 - val_kid: 0.4455\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9600 - d_loss: 0.6482 - real_acc: 0.6077 - gen_acc: 0.6447 - aug_p: 4.2763e-05 - val_kid: 0.6703\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7865 - d_loss: 0.6374 - real_acc: 0.5255 - gen_acc: 0.7961 - aug_p: 8.9145e-05 - val_kid: 0.7027\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7512 - d_loss: 0.7849 - real_acc: 0.4819 - gen_acc: 0.6225 - aug_p: 1.3668e-04 - val_kid: 1.2857\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6929 - d_loss: 0.6935 - real_acc: 0.5214 - gen_acc: 0.4852 - aug_p: 1.1513e-05 - val_kid: 0.9108\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6973 - d_loss: 0.6937 - real_acc: 0.4260 - gen_acc: 0.5691 - aug_p: 3.9474e-06 - val_kid: 1.0782\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6938 - d_loss: 0.6936 - real_acc: 0.4671 - gen_acc: 0.5387 - aug_p: 2.1382e-06 - val_kid: 0.7976\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6896 - d_loss: 0.6936 - real_acc: 0.5559 - gen_acc: 0.4194 - aug_p: 6.7434e-06 - val_kid: 0.8640\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7102 - d_loss: 0.6950 - real_acc: 0.5419 - gen_acc: 0.4712 - aug_p: 1.9408e-05 - val_kid: 1.2246\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6896 - d_loss: 0.6927 - real_acc: 0.6028 - gen_acc: 0.4515 - aug_p: 4.6546e-05 - val_kid: 1.0559\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6926 - d_loss: 0.6936 - real_acc: 0.5238 - gen_acc: 0.4877 - aug_p: 0.0000e+00 - val_kid: 1.0169\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7428 - d_loss: 0.6993 - real_acc: 0.3569 - gen_acc: 0.6365 - aug_p: 0.0000e+00 - val_kid: 1.0948\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7835 - d_loss: 0.6857 - real_acc: 0.6719 - gen_acc: 0.4301 - aug_p: 3.9967e-05 - val_kid: 0.9361\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7234 - d_loss: 0.6931 - real_acc: 0.4178 - gen_acc: 0.6472 - aug_p: 1.9737e-06 - val_kid: 1.7507\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7142 - d_loss: 0.6847 - real_acc: 0.6283 - gen_acc: 0.4211 - aug_p: 2.3339e-04 - val_kid: 1.3480\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6868 - d_loss: 0.6936 - real_acc: 0.5970 - gen_acc: 0.3775 - aug_p: 2.6447e-04 - val_kid: 0.9828\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7067 - d_loss: 0.6945 - real_acc: 0.5337 - gen_acc: 0.4531 - aug_p: 2.3191e-05 - val_kid: 1.3970\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6917 - d_loss: 0.6968 - real_acc: 0.3470 - gen_acc: 0.6283 - aug_p: 6.5789e-07 - val_kid: 0.7202\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6734 - d_loss: 0.8277 - real_acc: 0.8988 - gen_acc: 0.1143 - aug_p: 0.0014 - val_kid: 1.0825\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7023 - d_loss: 0.6921 - real_acc: 0.6308 - gen_acc: 0.3939 - aug_p: 0.0011 - val_kid: 0.7415\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6980 - d_loss: 0.6945 - real_acc: 0.5633 - gen_acc: 0.4285 - aug_p: 2.6020e-04 - val_kid: 0.6379\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6910 - d_loss: 0.6925 - real_acc: 0.6012 - gen_acc: 0.4005 - aug_p: 3.1414e-05 - val_kid: 0.4498\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7459 - d_loss: 0.6690 - real_acc: 0.4753 - gen_acc: 0.6151 - aug_p: 6.5789e-07 - val_kid: 0.5944\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 1.1562 - d_loss: 0.5915 - real_acc: 0.6069 - gen_acc: 0.7993 - aug_p: 2.0559e-05 - val_kid: 1.3310\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 1.0868 - d_loss: 0.7161 - real_acc: 0.8627 - gen_acc: 0.3158 - aug_p: 6.5082e-04 - val_kid: 2.6196\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7417 - d_loss: 0.6841 - real_acc: 0.6283 - gen_acc: 0.4638 - aug_p: 3.2385e-04 - val_kid: 2.7992\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6942 - d_loss: 0.6736 - real_acc: 0.4211 - gen_acc: 0.6694 - aug_p: 8.3553e-05 - val_kid: 2.2370\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7157 - d_loss: 0.7160 - real_acc: 0.4169 - gen_acc: 0.6933 - aug_p: 1.6776e-04 - val_kid: 3.0552\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6967 - d_loss: 0.7003 - real_acc: 0.4120 - gen_acc: 0.5979 - aug_p: 3.7336e-05 - val_kid: 4.1593\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7550 - d_loss: 0.6944 - real_acc: 0.5691 - gen_acc: 0.6488 - aug_p: 4.8684e-05 - val_kid: 2.6085\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7113 - d_loss: 0.6938 - real_acc: 0.4326 - gen_acc: 0.6077 - aug_p: 3.6349e-05 - val_kid: 2.8535\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6958 - d_loss: 0.6897 - real_acc: 0.5576 - gen_acc: 0.4811 - aug_p: 4.0461e-05 - val_kid: 1.5608\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7032 - d_loss: 0.6932 - real_acc: 0.4219 - gen_acc: 0.5979 - aug_p: 7.8947e-06 - val_kid: 1.7419\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7032 - d_loss: 0.6927 - real_acc: 0.3495 - gen_acc: 0.6620 - aug_p: 6.5789e-07 - val_kid: 1.4566\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6970 - d_loss: 0.6931 - real_acc: 0.4326 - gen_acc: 0.5888 - aug_p: 6.5789e-07 - val_kid: 1.4307\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.5123 - gen_acc: 0.4737 - aug_p: 0.0000e+00 - val_kid: 1.4493\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6919 - d_loss: 0.6937 - real_acc: 0.5189 - gen_acc: 0.4951 - aug_p: 0.0000e+00 - val_kid: 3.0013\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6929 - real_acc: 0.5329 - gen_acc: 0.4786 - aug_p: 2.9605e-06 - val_kid: 2.3513\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6908 - d_loss: 0.6938 - real_acc: 0.5345 - gen_acc: 0.4729 - aug_p: 0.0000e+00 - val_kid: 2.0439\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6950 - d_loss: 0.6934 - real_acc: 0.4539 - gen_acc: 0.5321 - aug_p: 0.0000e+00 - val_kid: 1.9324\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6975 - d_loss: 0.6931 - real_acc: 0.4293 - gen_acc: 0.5650 - aug_p: 6.5789e-07 - val_kid: 1.1939\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6943 - d_loss: 0.6930 - real_acc: 0.4786 - gen_acc: 0.5214 - aug_p: 0.0000e+00 - val_kid: 1.5485\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6791 - d_loss: 0.7565 - real_acc: 0.5378 - gen_acc: 0.4712 - aug_p: 6.9079e-06 - val_kid: 1.5087\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7073 - d_loss: 0.6882 - real_acc: 0.5173 - gen_acc: 0.5461 - aug_p: 0.0000e+00 - val_kid: 1.8245\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7708 - d_loss: 0.6647 - real_acc: 0.4819 - gen_acc: 0.7442 - aug_p: 2.3026e-06 - val_kid: 1.1425\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7965 - d_loss: 0.6587 - real_acc: 0.4753 - gen_acc: 0.7426 - aug_p: 6.0855e-06 - val_kid: 0.8845\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6836 - d_loss: 0.6896 - real_acc: 0.6579 - gen_acc: 0.4235 - aug_p: 3.9145e-05 - val_kid: 1.1534\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8260 - d_loss: 0.6567 - real_acc: 0.5436 - gen_acc: 0.7163 - aug_p: 7.9605e-05 - val_kid: 0.8721\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9439 - d_loss: 0.6638 - real_acc: 0.6447 - gen_acc: 0.6258 - aug_p: 2.1579e-04 - val_kid: 1.3893\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6945 - d_loss: 0.6900 - real_acc: 0.6382 - gen_acc: 0.4013 - aug_p: 1.8372e-04 - val_kid: 1.3824\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6879 - d_loss: 0.6939 - real_acc: 0.4852 - gen_acc: 0.5247 - aug_p: 3.9474e-05 - val_kid: 1.5784\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6889 - d_loss: 0.6951 - real_acc: 0.5329 - gen_acc: 0.4794 - aug_p: 1.3405e-04 - val_kid: 1.6362\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7078 - d_loss: 0.6918 - real_acc: 0.3273 - gen_acc: 0.7146 - aug_p: 7.0724e-06 - val_kid: 1.8970\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7204 - d_loss: 0.6877 - real_acc: 0.5584 - gen_acc: 0.5748 - aug_p: 2.7961e-05 - val_kid: 1.3294\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6997 - d_loss: 0.6930 - real_acc: 0.4359 - gen_acc: 0.5674 - aug_p: 3.9474e-05 - val_kid: 2.1790\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6973 - d_loss: 0.6932 - real_acc: 0.4079 - gen_acc: 0.5946 - aug_p: 0.0000e+00 - val_kid: 3.2592\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7162 - d_loss: 0.6874 - real_acc: 0.5510 - gen_acc: 0.4794 - aug_p: 8.3882e-06 - val_kid: 2.0479\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7646 - d_loss: 0.6758 - real_acc: 0.5938 - gen_acc: 0.5740 - aug_p: 1.9737e-05 - val_kid: 2.3842\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7967 - d_loss: 0.6805 - real_acc: 0.5567 - gen_acc: 0.6456 - aug_p: 1.8717e-04 - val_kid: 2.1745\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.8536 - d_loss: 0.7035 - real_acc: 0.5296 - gen_acc: 0.6513 - aug_p: 2.8618e-05 - val_kid: 1.8818\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7430 - d_loss: 0.6706 - real_acc: 0.6053 - gen_acc: 0.6077 - aug_p: 1.2336e-05 - val_kid: 1.1584\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7434 - d_loss: 0.6732 - real_acc: 0.5419 - gen_acc: 0.6299 - aug_p: 1.5625e-05 - val_kid: 1.1895\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7276 - d_loss: 0.6785 - real_acc: 0.4408 - gen_acc: 0.6456 - aug_p: 1.5789e-05 - val_kid: 1.3824\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7059 - d_loss: 0.6936 - real_acc: 0.3799 - gen_acc: 0.6299 - aug_p: 1.2336e-05 - val_kid: 2.7227\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6967 - d_loss: 0.6938 - real_acc: 0.4211 - gen_acc: 0.5600 - aug_p: 4.1118e-06 - val_kid: 1.8195\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6874 - d_loss: 0.6946 - real_acc: 0.4638 - gen_acc: 0.5288 - aug_p: 1.6283e-05 - val_kid: 1.7566\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7132 - d_loss: 0.6928 - real_acc: 0.5238 - gen_acc: 0.5271 - aug_p: 2.2961e-04 - val_kid: 2.4672\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7067 - d_loss: 0.6737 - real_acc: 0.5707 - gen_acc: 0.5822 - aug_p: 3.8322e-05 - val_kid: 2.0461\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.7163 - d_loss: 0.6836 - real_acc: 0.3388 - gen_acc: 0.7533 - aug_p: 3.9474e-06 - val_kid: 1.0595\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7699 - d_loss: 0.6917 - real_acc: 0.5658 - gen_acc: 0.5510 - aug_p: 8.7007e-05 - val_kid: 1.0387\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7178 - d_loss: 0.6892 - real_acc: 0.5263 - gen_acc: 0.5535 - aug_p: 2.3684e-05 - val_kid: 1.5882\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7320 - d_loss: 0.6706 - real_acc: 0.4737 - gen_acc: 0.7105 - aug_p: 0.0000e+00 - val_kid: 1.7804\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8211 - d_loss: 0.6219 - real_acc: 0.6003 - gen_acc: 0.7500 - aug_p: 7.7303e-06 - val_kid: 2.1217\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.9080 - d_loss: 0.6167 - real_acc: 0.5896 - gen_acc: 0.7434 - aug_p: 4.4408e-06 - val_kid: 1.3231\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.9987 - d_loss: 0.5882 - real_acc: 0.6332 - gen_acc: 0.7508 - aug_p: 2.7961e-06 - val_kid: 1.6168\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7305 - d_loss: 0.6802 - real_acc: 0.5831 - gen_acc: 0.6061 - aug_p: 1.2007e-05 - val_kid: 1.7688\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7203 - d_loss: 0.6918 - real_acc: 0.4235 - gen_acc: 0.6587 - aug_p: 6.2500e-06 - val_kid: 1.1816\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7518 - d_loss: 0.6830 - real_acc: 0.4663 - gen_acc: 0.6859 - aug_p: 6.5789e-07 - val_kid: 0.7789\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7279 - d_loss: 0.6851 - real_acc: 0.3487 - gen_acc: 0.7673 - aug_p: 7.8947e-06 - val_kid: 1.0952\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7840 - d_loss: 0.6759 - real_acc: 0.3939 - gen_acc: 0.7952 - aug_p: 1.1513e-05 - val_kid: 0.7968\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7589 - d_loss: 0.7075 - real_acc: 0.3314 - gen_acc: 0.8035 - aug_p: 1.7105e-05 - val_kid: 0.5273\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7344 - d_loss: 0.6876 - real_acc: 0.5329 - gen_acc: 0.6102 - aug_p: 1.0033e-05 - val_kid: 0.7843\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.8100 - d_loss: 0.6776 - real_acc: 0.6538 - gen_acc: 0.5798 - aug_p: 8.3717e-05 - val_kid: 0.4418\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6798 - d_loss: 0.6937 - real_acc: 0.5995 - gen_acc: 0.4079 - aug_p: 2.3668e-04 - val_kid: 0.5977\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6979 - d_loss: 0.6934 - real_acc: 0.4408 - gen_acc: 0.5855 - aug_p: 0.0000e+00 - val_kid: 0.5850\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6970 - d_loss: 0.6944 - real_acc: 0.4046 - gen_acc: 0.6192 - aug_p: 3.3882e-05 - val_kid: 0.5221\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7055 - d_loss: 0.6858 - real_acc: 0.5115 - gen_acc: 0.5781 - aug_p: 4.3421e-05 - val_kid: 0.4715\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7210 - d_loss: 0.6827 - real_acc: 0.4465 - gen_acc: 0.6883 - aug_p: 8.3882e-06 - val_kid: 0.4840\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.7111 - d_loss: 0.6855 - real_acc: 0.5387 - gen_acc: 0.5970 - aug_p: 7.7303e-06 - val_kid: 0.4826\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 1.0246 - d_loss: 0.7130 - real_acc: 0.7179 - gen_acc: 0.4153 - aug_p: 2.0740e-04 - val_kid: 0.3170\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7305 - d_loss: 0.6584 - real_acc: 0.6316 - gen_acc: 0.5107 - aug_p: 2.6151e-05 - val_kid: 0.2570\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6939 - real_acc: 0.4967 - gen_acc: 0.5123 - aug_p: 0.0000e+00 - val_kid: 0.2940\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6923 - d_loss: 0.6926 - real_acc: 0.5444 - gen_acc: 0.4679 - aug_p: 9.0460e-06 - val_kid: 0.4079\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6941 - d_loss: 0.6932 - real_acc: 0.4630 - gen_acc: 0.5222 - aug_p: 2.6316e-05 - val_kid: 0.5632\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6984 - d_loss: 0.6936 - real_acc: 0.4309 - gen_acc: 0.5641 - aug_p: 0.0000e+00 - val_kid: 0.2834\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6942 - d_loss: 0.6932 - real_acc: 0.4786 - gen_acc: 0.5288 - aug_p: 2.7961e-06 - val_kid: 0.4452\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6944 - d_loss: 0.6925 - real_acc: 0.5189 - gen_acc: 0.5082 - aug_p: 6.7434e-06 - val_kid: 0.3749\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6996 - d_loss: 0.6938 - real_acc: 0.3635 - gen_acc: 0.6242 - aug_p: 0.0000e+00 - val_kid: 0.6087\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6946 - d_loss: 0.6930 - real_acc: 0.4942 - gen_acc: 0.5403 - aug_p: 3.6184e-06 - val_kid: 0.5293\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6942 - d_loss: 0.6936 - real_acc: 0.4671 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.3230\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.7013 - d_loss: 0.6935 - real_acc: 0.3331 - gen_acc: 0.6645 - aug_p: 1.4803e-06 - val_kid: 0.2320\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6922 - d_loss: 0.6936 - real_acc: 0.4811 - gen_acc: 0.5148 - aug_p: 2.1382e-06 - val_kid: 0.2375\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.7000 - d_loss: 0.6932 - real_acc: 0.3750 - gen_acc: 0.6234 - aug_p: 0.0000e+00 - val_kid: 0.2512\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6954 - d_loss: 0.6932 - real_acc: 0.4375 - gen_acc: 0.5641 - aug_p: 0.0000e+00 - val_kid: 0.2651\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6949 - d_loss: 0.6934 - real_acc: 0.4688 - gen_acc: 0.5280 - aug_p: 3.6184e-06 - val_kid: 0.5463\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6943 - d_loss: 0.6934 - real_acc: 0.4663 - gen_acc: 0.5238 - aug_p: 0.0000e+00 - val_kid: 0.4075\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6906 - d_loss: 0.6933 - real_acc: 0.5428 - gen_acc: 0.4457 - aug_p: 0.0000e+00 - val_kid: 0.8486\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6936 - real_acc: 0.4901 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.2134\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6951 - d_loss: 0.6937 - real_acc: 0.4260 - gen_acc: 0.5559 - aug_p: 0.0000e+00 - val_kid: 0.4693\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6945 - d_loss: 0.6933 - real_acc: 0.4548 - gen_acc: 0.5493 - aug_p: 0.0000e+00 - val_kid: 0.6546\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6936 - real_acc: 0.4712 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.4438\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6950 - d_loss: 0.6933 - real_acc: 0.4243 - gen_acc: 0.5666 - aug_p: 0.0000e+00 - val_kid: 0.7355\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6926 - d_loss: 0.6931 - real_acc: 0.5387 - gen_acc: 0.5058 - aug_p: 0.0000e+00 - val_kid: 0.2423\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6952 - d_loss: 0.6934 - real_acc: 0.4400 - gen_acc: 0.5584 - aug_p: 0.0000e+00 - val_kid: 0.4578\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6936 - real_acc: 0.4646 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.2745\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6939 - d_loss: 0.6935 - real_acc: 0.4507 - gen_acc: 0.5247 - aug_p: 0.0000e+00 - val_kid: 0.5317\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5354 - gen_acc: 0.4753 - aug_p: 0.0000e+00 - val_kid: 0.9466\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6945 - real_acc: 0.5132 - gen_acc: 0.4712 - aug_p: 0.0000e+00 - val_kid: 0.3023\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6928 - d_loss: 0.6929 - real_acc: 0.5156 - gen_acc: 0.5000 - aug_p: 0.0000e+00 - val_kid: 0.4464\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6944 - d_loss: 0.6933 - real_acc: 0.4474 - gen_acc: 0.5395 - aug_p: 0.0000e+00 - val_kid: 0.2813\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6918 - d_loss: 0.6935 - real_acc: 0.5197 - gen_acc: 0.4638 - aug_p: 0.0000e+00 - val_kid: 0.5159\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6942 - d_loss: 0.6932 - real_acc: 0.4548 - gen_acc: 0.5559 - aug_p: 0.0000e+00 - val_kid: 0.3301\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6939 - d_loss: 0.6932 - real_acc: 0.4762 - gen_acc: 0.5469 - aug_p: 0.0000e+00 - val_kid: 0.4875\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6944 - d_loss: 0.6931 - real_acc: 0.5123 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.7331\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6929 - real_acc: 0.5312 - gen_acc: 0.5058 - aug_p: 0.0000e+00 - val_kid: 0.3158\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6931 - real_acc: 0.5181 - gen_acc: 0.5132 - aug_p: 0.0000e+00 - val_kid: 0.5282\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6926 - d_loss: 0.6937 - real_acc: 0.4860 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.2535\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4786 - gen_acc: 0.5008 - aug_p: 0.0000e+00 - val_kid: 0.4165\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6930 - d_loss: 0.6930 - real_acc: 0.5263 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.2359\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6925 - d_loss: 0.6934 - real_acc: 0.5115 - gen_acc: 0.4597 - aug_p: 0.0000e+00 - val_kid: 0.1469\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6934 - real_acc: 0.4942 - gen_acc: 0.4852 - aug_p: 0.0000e+00 - val_kid: 0.5251\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6931 - real_acc: 0.5255 - gen_acc: 0.4918 - aug_p: 0.0000e+00 - val_kid: 0.2249\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6959 - d_loss: 0.6930 - real_acc: 0.4309 - gen_acc: 0.5962 - aug_p: 0.0000e+00 - val_kid: 0.4956\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6919 - d_loss: 0.6933 - real_acc: 0.5436 - gen_acc: 0.4465 - aug_p: 0.0000e+00 - val_kid: 0.5313\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6942 - d_loss: 0.6931 - real_acc: 0.4827 - gen_acc: 0.5362 - aug_p: 0.0000e+00 - val_kid: 0.6965\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6919 - d_loss: 0.6931 - real_acc: 0.5592 - gen_acc: 0.4548 - aug_p: 0.0000e+00 - val_kid: 0.2171\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6924 - d_loss: 0.6934 - real_acc: 0.5247 - gen_acc: 0.4827 - aug_p: 0.0000e+00 - val_kid: 0.4310\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6919 - d_loss: 0.6934 - real_acc: 0.5214 - gen_acc: 0.4696 - aug_p: 0.0000e+00 - val_kid: 0.1590\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6940 - d_loss: 0.6934 - real_acc: 0.4671 - gen_acc: 0.5370 - aug_p: 0.0000e+00 - val_kid: 0.3095\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6923 - d_loss: 0.6932 - real_acc: 0.5066 - gen_acc: 0.4729 - aug_p: 0.0000e+00 - val_kid: 0.3402\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6898 - d_loss: 0.6935 - real_acc: 0.5757 - gen_acc: 0.4062 - aug_p: 0.0000e+00 - val_kid: 0.2278\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6931 - real_acc: 0.4967 - gen_acc: 0.5132 - aug_p: 0.0000e+00 - val_kid: 0.8515\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6941 - d_loss: 0.6931 - real_acc: 0.4696 - gen_acc: 0.5403 - aug_p: 0.0000e+00 - val_kid: 0.3256\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6943 - d_loss: 0.6930 - real_acc: 0.4868 - gen_acc: 0.5214 - aug_p: 0.0000e+00 - val_kid: 0.3659\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6930 - real_acc: 0.5049 - gen_acc: 0.5222 - aug_p: 0.0000e+00 - val_kid: 0.3887\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6919 - d_loss: 0.6937 - real_acc: 0.4901 - gen_acc: 0.4696 - aug_p: 0.0000e+00 - val_kid: 0.6552\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6938 - d_loss: 0.6932 - real_acc: 0.4893 - gen_acc: 0.5197 - aug_p: 0.0000e+00 - val_kid: 0.1704\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6933 - real_acc: 0.4441 - gen_acc: 0.5230 - aug_p: 0.0000e+00 - val_kid: 0.2249\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6927 - d_loss: 0.6935 - real_acc: 0.4975 - gen_acc: 0.4836 - aug_p: 0.0000e+00 - val_kid: 0.2663\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6924 - d_loss: 0.6936 - real_acc: 0.5115 - gen_acc: 0.4737 - aug_p: 0.0000e+00 - val_kid: 0.5412\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6925 - d_loss: 0.6931 - real_acc: 0.5280 - gen_acc: 0.4885 - aug_p: 6.5789e-07 - val_kid: 0.4495\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6932 - real_acc: 0.5238 - gen_acc: 0.4581 - aug_p: 0.0000e+00 - val_kid: 0.3468\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6960 - d_loss: 0.6929 - real_acc: 0.4490 - gen_acc: 0.5748 - aug_p: 0.0000e+00 - val_kid: 0.4907\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6913 - d_loss: 0.6936 - real_acc: 0.5337 - gen_acc: 0.4622 - aug_p: 1.4803e-06 - val_kid: 0.4370\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6909 - d_loss: 0.6935 - real_acc: 0.5551 - gen_acc: 0.4095 - aug_p: 0.0000e+00 - val_kid: 0.3406\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6909 - d_loss: 0.6936 - real_acc: 0.5584 - gen_acc: 0.4087 - aug_p: 0.0000e+00 - val_kid: 0.3690\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5025 - gen_acc: 0.5041 - aug_p: 0.0000e+00 - val_kid: 0.4567\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6948 - d_loss: 0.6933 - real_acc: 0.4252 - gen_acc: 0.5617 - aug_p: 0.0000e+00 - val_kid: 0.3937\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6933 - d_loss: 0.6933 - real_acc: 0.4844 - gen_acc: 0.5033 - aug_p: 0.0000e+00 - val_kid: 0.3619\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6930 - real_acc: 0.5140 - gen_acc: 0.5058 - aug_p: 0.0000e+00 - val_kid: 0.4290\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.5025 - gen_acc: 0.5255 - aug_p: 0.0000e+00 - val_kid: 0.5260\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.5033 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.3606\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6902 - d_loss: 0.6935 - real_acc: 0.5551 - gen_acc: 0.4252 - aug_p: 0.0000e+00 - val_kid: 0.3522\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6940 - d_loss: 0.6934 - real_acc: 0.4581 - gen_acc: 0.5238 - aug_p: 0.0000e+00 - val_kid: 0.3027\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6937 - real_acc: 0.4671 - gen_acc: 0.5041 - aug_p: 0.0000e+00 - val_kid: 0.5460\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6934 - real_acc: 0.4844 - gen_acc: 0.4942 - aug_p: 0.0000e+00 - val_kid: 0.6021\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5329 - gen_acc: 0.4844 - aug_p: 0.0000e+00 - val_kid: 0.4560\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6928 - d_loss: 0.6931 - real_acc: 0.5214 - gen_acc: 0.4762 - aug_p: 0.0000e+00 - val_kid: 0.3573\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6936 - real_acc: 0.4613 - gen_acc: 0.4893 - aug_p: 0.0000e+00 - val_kid: 0.2377\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6921 - d_loss: 0.6931 - real_acc: 0.5378 - gen_acc: 0.4753 - aug_p: 0.0000e+00 - val_kid: 0.2330\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6937 - real_acc: 0.4498 - gen_acc: 0.5271 - aug_p: 0.0000e+00 - val_kid: 0.2487\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6931 - real_acc: 0.5312 - gen_acc: 0.4852 - aug_p: 0.0000e+00 - val_kid: 0.3960\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6934 - real_acc: 0.4778 - gen_acc: 0.4926 - aug_p: 0.0000e+00 - val_kid: 0.3779\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6915 - d_loss: 0.6934 - real_acc: 0.5584 - gen_acc: 0.4334 - aug_p: 6.5789e-07 - val_kid: 0.5887\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6921 - d_loss: 0.6932 - real_acc: 0.5378 - gen_acc: 0.4243 - aug_p: 0.0000e+00 - val_kid: 0.3371\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6919 - d_loss: 0.6934 - real_acc: 0.5238 - gen_acc: 0.4597 - aug_p: 6.5789e-07 - val_kid: 0.4362\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6917 - d_loss: 0.6931 - real_acc: 0.5428 - gen_acc: 0.4827 - aug_p: 4.7697e-06 - val_kid: 0.2754\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6956 - d_loss: 0.6933 - real_acc: 0.3750 - gen_acc: 0.6086 - aug_p: 0.0000e+00 - val_kid: 0.5351\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6947 - d_loss: 0.6929 - real_acc: 0.4441 - gen_acc: 0.5757 - aug_p: 0.0000e+00 - val_kid: 0.6494\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5148 - gen_acc: 0.5016 - aug_p: 0.0000e+00 - val_kid: 0.4069\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6924 - d_loss: 0.6930 - real_acc: 0.5403 - gen_acc: 0.4827 - aug_p: 0.0000e+00 - val_kid: 0.4516\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6949 - d_loss: 0.6932 - real_acc: 0.4309 - gen_acc: 0.5641 - aug_p: 0.0000e+00 - val_kid: 0.4695\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6933 - real_acc: 0.4836 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.5980\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6936 - d_loss: 0.6932 - real_acc: 0.4753 - gen_acc: 0.5337 - aug_p: 0.0000e+00 - val_kid: 0.5819\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6932 - real_acc: 0.4770 - gen_acc: 0.5395 - aug_p: 0.0000e+00 - val_kid: 0.4381\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6910 - d_loss: 0.6932 - real_acc: 0.5600 - gen_acc: 0.4729 - aug_p: 8.0592e-06 - val_kid: 0.8321\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.5016 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.3730\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6922 - d_loss: 0.6936 - real_acc: 0.5123 - gen_acc: 0.4646 - aug_p: 0.0000e+00 - val_kid: 0.5295\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6918 - d_loss: 0.6933 - real_acc: 0.4942 - gen_acc: 0.4901 - aug_p: 1.9737e-06 - val_kid: 0.1944\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6943 - d_loss: 0.6934 - real_acc: 0.4104 - gen_acc: 0.5773 - aug_p: 0.0000e+00 - val_kid: 0.3161\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4951 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.2788\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6930 - real_acc: 0.5304 - gen_acc: 0.4811 - aug_p: 0.0000e+00 - val_kid: 0.3614\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6931 - real_acc: 0.5288 - gen_acc: 0.4852 - aug_p: 0.0000e+00 - val_kid: 0.5161\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6926 - d_loss: 0.6934 - real_acc: 0.4868 - gen_acc: 0.4745 - aug_p: 0.0000e+00 - val_kid: 0.5636\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6934 - real_acc: 0.4753 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.6425\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6899 - d_loss: 0.6934 - real_acc: 0.5576 - gen_acc: 0.4465 - aug_p: 1.3158e-06 - val_kid: 0.2194\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6939 - d_loss: 0.6934 - real_acc: 0.4408 - gen_acc: 0.5197 - aug_p: 0.0000e+00 - val_kid: 0.5403\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5164 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.7518\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5066 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.4311\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6922 - d_loss: 0.6934 - real_acc: 0.5304 - gen_acc: 0.4301 - aug_p: 0.0000e+00 - val_kid: 0.3553\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6936 - d_loss: 0.6931 - real_acc: 0.4918 - gen_acc: 0.5238 - aug_p: 0.0000e+00 - val_kid: 0.4429\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.4885 - gen_acc: 0.4926 - aug_p: 0.0000e+00 - val_kid: 0.2865\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5090 - gen_acc: 0.4827 - aug_p: 0.0000e+00 - val_kid: 0.3096\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6937 - d_loss: 0.6933 - real_acc: 0.4679 - gen_acc: 0.5387 - aug_p: 0.0000e+00 - val_kid: 0.2386\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6925 - d_loss: 0.6934 - real_acc: 0.5041 - gen_acc: 0.4433 - aug_p: 0.0000e+00 - val_kid: 0.7935\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6934 - real_acc: 0.4819 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.5179\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6929 - real_acc: 0.5271 - gen_acc: 0.5173 - aug_p: 0.0000e+00 - val_kid: 0.7236\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6933 - real_acc: 0.4868 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.5434\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6934 - d_loss: 0.6930 - real_acc: 0.5016 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.3432\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.4918 - gen_acc: 0.4836 - aug_p: 0.0000e+00 - val_kid: 0.2532\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6930 - real_acc: 0.5058 - gen_acc: 0.5280 - aug_p: 0.0000e+00 - val_kid: 0.3004\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6930 - real_acc: 0.5337 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.2492\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6930 - real_acc: 0.5164 - gen_acc: 0.5008 - aug_p: 0.0000e+00 - val_kid: 0.3515\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6934 - d_loss: 0.6933 - real_acc: 0.4836 - gen_acc: 0.5074 - aug_p: 0.0000e+00 - val_kid: 0.5872\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6928 - real_acc: 0.5337 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.4616\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5016 - gen_acc: 0.4967 - aug_p: 0.0000e+00 - val_kid: 0.3980\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6938 - d_loss: 0.6929 - real_acc: 0.5049 - gen_acc: 0.5329 - aug_p: 0.0000e+00 - val_kid: 0.6247\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6930 - real_acc: 0.4860 - gen_acc: 0.5107 - aug_p: 0.0000e+00 - val_kid: 0.4086\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6939 - d_loss: 0.6930 - real_acc: 0.4918 - gen_acc: 0.5173 - aug_p: 0.0000e+00 - val_kid: 0.3369\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6928 - d_loss: 0.6932 - real_acc: 0.5345 - gen_acc: 0.4836 - aug_p: 0.0000e+00 - val_kid: 0.5677\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6928 - real_acc: 0.5321 - gen_acc: 0.5016 - aug_p: 0.0000e+00 - val_kid: 0.3749\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6936 - d_loss: 0.6930 - real_acc: 0.5000 - gen_acc: 0.5173 - aug_p: 0.0000e+00 - val_kid: 0.5870\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6923 - d_loss: 0.6937 - real_acc: 0.5041 - gen_acc: 0.4679 - aug_p: 0.0000e+00 - val_kid: 0.5034\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5222 - gen_acc: 0.4868 - aug_p: 0.0000e+00 - val_kid: 0.5121\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5099 - gen_acc: 0.4885 - aug_p: 0.0000e+00 - val_kid: 0.3720\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6932 - real_acc: 0.4959 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.4084\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6930 - real_acc: 0.5107 - gen_acc: 0.5082 - aug_p: 0.0000e+00 - val_kid: 0.4130\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6939 - d_loss: 0.6931 - real_acc: 0.4712 - gen_acc: 0.5189 - aug_p: 0.0000e+00 - val_kid: 0.3131\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4959 - gen_acc: 0.4786 - aug_p: 0.0000e+00 - val_kid: 0.7757\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4852 - gen_acc: 0.4951 - aug_p: 0.0000e+00 - val_kid: 0.4454\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6922 - d_loss: 0.6930 - real_acc: 0.5452 - gen_acc: 0.4704 - aug_p: 0.0000e+00 - val_kid: 0.4551\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6944 - d_loss: 0.6932 - real_acc: 0.4474 - gen_acc: 0.5370 - aug_p: 0.0000e+00 - val_kid: 0.3942\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6935 - real_acc: 0.4663 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.3696\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5230 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.2100\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6910 - d_loss: 0.6930 - real_acc: 0.5814 - gen_acc: 0.4219 - aug_p: 0.0000e+00 - val_kid: 0.4713\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6914 - d_loss: 0.6932 - real_acc: 0.5617 - gen_acc: 0.4449 - aug_p: 0.0000e+00 - val_kid: 0.1530\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6920 - d_loss: 0.6931 - real_acc: 0.5559 - gen_acc: 0.4663 - aug_p: 0.0000e+00 - val_kid: 0.3615\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6948 - d_loss: 0.6933 - real_acc: 0.4400 - gen_acc: 0.5535 - aug_p: 0.0000e+00 - val_kid: 0.3788\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6938 - d_loss: 0.6930 - real_acc: 0.4885 - gen_acc: 0.5156 - aug_p: 0.0000e+00 - val_kid: 0.3775\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6931 - real_acc: 0.4992 - gen_acc: 0.5041 - aug_p: 0.0000e+00 - val_kid: 0.3000\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6934 - real_acc: 0.4712 - gen_acc: 0.5148 - aug_p: 0.0000e+00 - val_kid: 0.6682\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5025 - gen_acc: 0.4778 - aug_p: 0.0000e+00 - val_kid: 0.3211\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6936 - d_loss: 0.6931 - real_acc: 0.4934 - gen_acc: 0.5247 - aug_p: 0.0000e+00 - val_kid: 0.3601\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6926 - d_loss: 0.6934 - real_acc: 0.5148 - gen_acc: 0.4622 - aug_p: 0.0000e+00 - val_kid: 0.5144\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6928 - d_loss: 0.6930 - real_acc: 0.5502 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.2736\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4778 - gen_acc: 0.4934 - aug_p: 0.0000e+00 - val_kid: 0.5423\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6930 - real_acc: 0.5378 - gen_acc: 0.4918 - aug_p: 0.0000e+00 - val_kid: 0.5309\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6934 - real_acc: 0.4827 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.1827\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6940 - d_loss: 0.6935 - real_acc: 0.4326 - gen_acc: 0.5551 - aug_p: 0.0000e+00 - val_kid: 0.2301\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6938 - d_loss: 0.6934 - real_acc: 0.4383 - gen_acc: 0.5337 - aug_p: 0.0000e+00 - val_kid: 0.3560\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6931 - real_acc: 0.5066 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.4004\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6947 - d_loss: 0.6930 - real_acc: 0.4367 - gen_acc: 0.5880 - aug_p: 0.0000e+00 - val_kid: 0.2858\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.5123 - gen_acc: 0.4712 - aug_p: 0.0000e+00 - val_kid: 0.2878\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.4992 - gen_acc: 0.4638 - aug_p: 0.0000e+00 - val_kid: 0.4650\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6933 - real_acc: 0.4803 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.3046\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6927 - d_loss: 0.6931 - real_acc: 0.5337 - gen_acc: 0.4655 - aug_p: 0.0000e+00 - val_kid: 0.3020\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6937 - d_loss: 0.6930 - real_acc: 0.4762 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.2925\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4959 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.2614\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6935 - d_loss: 0.6932 - real_acc: 0.4967 - gen_acc: 0.4934 - aug_p: 0.0000e+00 - val_kid: 0.1764\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6925 - d_loss: 0.6934 - real_acc: 0.5008 - gen_acc: 0.4515 - aug_p: 0.0000e+00 - val_kid: 0.2450\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6930 - real_acc: 0.4877 - gen_acc: 0.5271 - aug_p: 0.0000e+00 - val_kid: 0.4833\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6928 - d_loss: 0.6933 - real_acc: 0.5271 - gen_acc: 0.4811 - aug_p: 0.0000e+00 - val_kid: 0.4896\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6933 - real_acc: 0.4778 - gen_acc: 0.5033 - aug_p: 0.0000e+00 - val_kid: 0.4447\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5132 - gen_acc: 0.4786 - aug_p: 0.0000e+00 - val_kid: 0.3685\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5082 - gen_acc: 0.4819 - aug_p: 0.0000e+00 - val_kid: 0.6145\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5140 - gen_acc: 0.4663 - aug_p: 0.0000e+00 - val_kid: 0.3813\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.5008 - gen_acc: 0.4885 - aug_p: 0.0000e+00 - val_kid: 0.4486\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.4992 - gen_acc: 0.4926 - aug_p: 0.0000e+00 - val_kid: 0.3963\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4844 - gen_acc: 0.4844 - aug_p: 0.0000e+00 - val_kid: 0.3048\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6934 - d_loss: 0.6931 - real_acc: 0.4836 - gen_acc: 0.5206 - aug_p: 0.0000e+00 - val_kid: 0.4268\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6931 - real_acc: 0.4852 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.5890\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4975 - gen_acc: 0.4836 - aug_p: 0.0000e+00 - val_kid: 0.1361\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5082 - gen_acc: 0.4753 - aug_p: 0.0000e+00 - val_kid: 0.4065\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4794 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.7510\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.5016 - gen_acc: 0.5066 - aug_p: 0.0000e+00 - val_kid: 0.4129\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5107 - gen_acc: 0.4918 - aug_p: 0.0000e+00 - val_kid: 0.3583\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4959 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.4641\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6931 - real_acc: 0.4827 - gen_acc: 0.5181 - aug_p: 0.0000e+00 - val_kid: 0.5026\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6928 - d_loss: 0.6934 - real_acc: 0.5008 - gen_acc: 0.4770 - aug_p: 0.0000e+00 - val_kid: 0.2976\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6934 - d_loss: 0.6932 - real_acc: 0.4852 - gen_acc: 0.5123 - aug_p: 0.0000e+00 - val_kid: 0.4535\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5140 - gen_acc: 0.4572 - aug_p: 0.0000e+00 - val_kid: 0.3197\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.5206 - gen_acc: 0.4605 - aug_p: 0.0000e+00 - val_kid: 0.8052\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6933 - real_acc: 0.4589 - gen_acc: 0.5288 - aug_p: 0.0000e+00 - val_kid: 0.3449\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4704 - gen_acc: 0.4868 - aug_p: 0.0000e+00 - val_kid: 0.4941\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6928 - d_loss: 0.6932 - real_acc: 0.5288 - gen_acc: 0.4646 - aug_p: 0.0000e+00 - val_kid: 0.6090\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6931 - real_acc: 0.4794 - gen_acc: 0.5066 - aug_p: 0.0000e+00 - val_kid: 0.5380\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.4836 - gen_acc: 0.4951 - aug_p: 0.0000e+00 - val_kid: 0.4265\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6924 - d_loss: 0.6934 - real_acc: 0.5288 - gen_acc: 0.4539 - aug_p: 0.0000e+00 - val_kid: 0.3553\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6936 - d_loss: 0.6930 - real_acc: 0.4984 - gen_acc: 0.5387 - aug_p: 0.0000e+00 - val_kid: 0.5010\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6935 - d_loss: 0.6931 - real_acc: 0.4984 - gen_acc: 0.5025 - aug_p: 0.0000e+00 - val_kid: 0.6444\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6936 - d_loss: 0.6933 - real_acc: 0.4276 - gen_acc: 0.5164 - aug_p: 0.0000e+00 - val_kid: 0.4961\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5132 - gen_acc: 0.4901 - aug_p: 0.0000e+00 - val_kid: 0.2881\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6930 - real_acc: 0.5255 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.3187\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4975 - gen_acc: 0.4663 - aug_p: 0.0000e+00 - val_kid: 0.3215\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4860 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.3724\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6903 - d_loss: 0.6932 - real_acc: 0.5921 - gen_acc: 0.4087 - aug_p: 1.5461e-05 - val_kid: 0.3137\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6930 - real_acc: 0.5008 - gen_acc: 0.5066 - aug_p: 0.0000e+00 - val_kid: 0.5516\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6955 - d_loss: 0.6933 - real_acc: 0.4227 - gen_acc: 0.5748 - aug_p: 0.0000e+00 - val_kid: 0.2368\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6926 - d_loss: 0.6932 - real_acc: 0.5148 - gen_acc: 0.4712 - aug_p: 0.0000e+00 - val_kid: 0.2736\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6933 - real_acc: 0.5164 - gen_acc: 0.4737 - aug_p: 0.0000e+00 - val_kid: 0.3383\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5016 - gen_acc: 0.4901 - aug_p: 0.0000e+00 - val_kid: 0.5508\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6930 - real_acc: 0.5329 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.4818\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6939 - d_loss: 0.6929 - real_acc: 0.4893 - gen_acc: 0.5255 - aug_p: 0.0000e+00 - val_kid: 0.2984\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.4918 - gen_acc: 0.5016 - aug_p: 0.0000e+00 - val_kid: 0.7062\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6928 - d_loss: 0.6932 - real_acc: 0.5164 - gen_acc: 0.4737 - aug_p: 0.0000e+00 - val_kid: 0.3331\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6928 - d_loss: 0.6934 - real_acc: 0.4885 - gen_acc: 0.4811 - aug_p: 0.0000e+00 - val_kid: 0.3678\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6928 - d_loss: 0.6933 - real_acc: 0.4844 - gen_acc: 0.4770 - aug_p: 0.0000e+00 - val_kid: 0.2692\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6948 - d_loss: 0.6932 - real_acc: 0.4120 - gen_acc: 0.5995 - aug_p: 0.0000e+00 - val_kid: 0.3455\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6934 - d_loss: 0.6933 - real_acc: 0.4803 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.4790\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4918 - gen_acc: 0.5132 - aug_p: 0.0000e+00 - val_kid: 0.4274\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6924 - d_loss: 0.6932 - real_acc: 0.5263 - gen_acc: 0.4671 - aug_p: 0.0000e+00 - val_kid: 0.3594\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6933 - real_acc: 0.5033 - gen_acc: 0.4762 - aug_p: 0.0000e+00 - val_kid: 0.2126\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6933 - real_acc: 0.4646 - gen_acc: 0.5280 - aug_p: 0.0000e+00 - val_kid: 0.4868\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6926 - d_loss: 0.6932 - real_acc: 0.5337 - gen_acc: 0.4548 - aug_p: 0.0000e+00 - val_kid: 0.3092\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5156 - gen_acc: 0.5148 - aug_p: 0.0000e+00 - val_kid: 0.3934\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6932 - real_acc: 0.4893 - gen_acc: 0.5247 - aug_p: 0.0000e+00 - val_kid: 0.3493\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6926 - d_loss: 0.6932 - real_acc: 0.5189 - gen_acc: 0.4729 - aug_p: 0.0000e+00 - val_kid: 0.4766\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6931 - real_acc: 0.4934 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.2646\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5123 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.2283\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6925 - d_loss: 0.6930 - real_acc: 0.5633 - gen_acc: 0.4696 - aug_p: 0.0000e+00 - val_kid: 0.4980\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6937 - d_loss: 0.6931 - real_acc: 0.4836 - gen_acc: 0.5304 - aug_p: 0.0000e+00 - val_kid: 0.3047\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.5247 - gen_acc: 0.4655 - aug_p: 0.0000e+00 - val_kid: 0.4187\n",
            "Epoch 634/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6933 - real_acc: 0.4630 - gen_acc: 0.5263 - aug_p: 0.0000e+00 - val_kid: 0.1947\n",
            "Epoch 635/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6906 - d_loss: 0.6932 - real_acc: 0.5757 - gen_acc: 0.4285 - aug_p: 0.0000e+00 - val_kid: 0.3683\n",
            "Epoch 636/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6931 - real_acc: 0.5041 - gen_acc: 0.5008 - aug_p: 0.0000e+00 - val_kid: 0.4317\n",
            "Epoch 637/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6938 - d_loss: 0.6933 - real_acc: 0.4449 - gen_acc: 0.5354 - aug_p: 0.0000e+00 - val_kid: 0.7708\n",
            "Epoch 638/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6925 - d_loss: 0.6933 - real_acc: 0.5222 - gen_acc: 0.4737 - aug_p: 0.0000e+00 - val_kid: 0.3466\n",
            "Epoch 639/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6934 - d_loss: 0.6931 - real_acc: 0.5090 - gen_acc: 0.5156 - aug_p: 0.0000e+00 - val_kid: 0.4872\n",
            "Epoch 640/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6937 - d_loss: 0.6933 - real_acc: 0.4531 - gen_acc: 0.5296 - aug_p: 0.0000e+00 - val_kid: 0.3266\n",
            "Epoch 641/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6932 - real_acc: 0.5033 - gen_acc: 0.5107 - aug_p: 0.0000e+00 - val_kid: 0.1913\n",
            "Epoch 642/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.5140 - gen_acc: 0.4688 - aug_p: 0.0000e+00 - val_kid: 0.3680\n",
            "Epoch 643/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6929 - real_acc: 0.5370 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.2784\n",
            "Epoch 644/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6925 - d_loss: 0.6931 - real_acc: 0.5403 - gen_acc: 0.4729 - aug_p: 0.0000e+00 - val_kid: 0.4570\n",
            "Epoch 645/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6938 - d_loss: 0.6930 - real_acc: 0.4852 - gen_acc: 0.5181 - aug_p: 0.0000e+00 - val_kid: 0.6574\n",
            "Epoch 646/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6933 - real_acc: 0.4770 - gen_acc: 0.5222 - aug_p: 0.0000e+00 - val_kid: 0.2734\n",
            "Epoch 647/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6928 - d_loss: 0.6934 - real_acc: 0.5058 - gen_acc: 0.4918 - aug_p: 0.0000e+00 - val_kid: 0.3219\n",
            "Epoch 648/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4737 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.3867\n",
            "Epoch 649/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.4877 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.2874\n",
            "Epoch 650/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4885 - gen_acc: 0.5025 - aug_p: 0.0000e+00 - val_kid: 0.4440\n",
            "Epoch 651/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5148 - gen_acc: 0.4770 - aug_p: 0.0000e+00 - val_kid: 0.4339\n",
            "Epoch 652/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6931 - real_acc: 0.4959 - gen_acc: 0.5041 - aug_p: 0.0000e+00 - val_kid: 0.4086\n",
            "Epoch 653/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6914 - d_loss: 0.6931 - real_acc: 0.5576 - gen_acc: 0.4704 - aug_p: 1.4803e-05 - val_kid: 0.3743\n",
            "Epoch 654/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6933 - real_acc: 0.4400 - gen_acc: 0.5485 - aug_p: 0.0000e+00 - val_kid: 0.2081\n",
            "Epoch 655/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4910 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.2361\n",
            "Epoch 656/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5247 - gen_acc: 0.4696 - aug_p: 0.0000e+00 - val_kid: 0.6028\n",
            "Epoch 657/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6935 - d_loss: 0.6932 - real_acc: 0.4729 - gen_acc: 0.5189 - aug_p: 0.0000e+00 - val_kid: 0.3791\n",
            "Epoch 658/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4942 - gen_acc: 0.5197 - aug_p: 0.0000e+00 - val_kid: 0.1180\n",
            "Epoch 659/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6929 - real_acc: 0.5058 - gen_acc: 0.5395 - aug_p: 0.0000e+00 - val_kid: 0.5427\n",
            "Epoch 660/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6938 - d_loss: 0.6932 - real_acc: 0.4720 - gen_acc: 0.5247 - aug_p: 0.0000e+00 - val_kid: 0.3802\n",
            "Epoch 661/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6934 - d_loss: 0.6931 - real_acc: 0.4951 - gen_acc: 0.5370 - aug_p: 0.0000e+00 - val_kid: 0.3360\n",
            "Epoch 662/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5099 - gen_acc: 0.5058 - aug_p: 5.2632e-06 - val_kid: 0.4554\n",
            "Epoch 663/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6927 - d_loss: 0.6934 - real_acc: 0.5090 - gen_acc: 0.4770 - aug_p: 0.0000e+00 - val_kid: 0.2492\n",
            "Epoch 664/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6933 - real_acc: 0.4803 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.6135\n",
            "Epoch 665/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6941 - d_loss: 0.6929 - real_acc: 0.4885 - gen_acc: 0.5551 - aug_p: 0.0000e+00 - val_kid: 0.3289\n",
            "Epoch 666/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5148 - gen_acc: 0.4868 - aug_p: 0.0000e+00 - val_kid: 0.4398\n",
            "Epoch 667/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6955 - d_loss: 0.6931 - real_acc: 0.4276 - gen_acc: 0.6086 - aug_p: 0.0000e+00 - val_kid: 0.2360\n",
            "Epoch 668/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6921 - d_loss: 0.6933 - real_acc: 0.5444 - gen_acc: 0.4408 - aug_p: 0.0000e+00 - val_kid: 0.4162\n",
            "Epoch 669/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6931 - real_acc: 0.5321 - gen_acc: 0.4860 - aug_p: 0.0000e+00 - val_kid: 0.2609\n",
            "Epoch 670/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.4992 - gen_acc: 0.4893 - aug_p: 0.0000e+00 - val_kid: 0.4231\n",
            "Epoch 671/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.5173 - gen_acc: 0.4951 - aug_p: 0.0000e+00 - val_kid: 0.3507\n",
            "Epoch 672/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6900 - d_loss: 0.6930 - real_acc: 0.6398 - gen_acc: 0.3808 - aug_p: 4.1118e-06 - val_kid: 0.4064\n",
            "Epoch 673/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6912 - d_loss: 0.6932 - real_acc: 0.5831 - gen_acc: 0.4169 - aug_p: 0.0000e+00 - val_kid: 0.4638\n",
            "Epoch 674/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6931 - real_acc: 0.4416 - gen_acc: 0.5477 - aug_p: 0.0000e+00 - val_kid: 0.2273\n",
            "Epoch 675/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6936 - d_loss: 0.6933 - real_acc: 0.4605 - gen_acc: 0.5395 - aug_p: 0.0000e+00 - val_kid: 0.2259\n",
            "Epoch 676/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6926 - d_loss: 0.6932 - real_acc: 0.5189 - gen_acc: 0.4745 - aug_p: 0.0000e+00 - val_kid: 0.3120\n",
            "Epoch 677/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6908 - d_loss: 0.6933 - real_acc: 0.5510 - gen_acc: 0.4433 - aug_p: 1.8092e-06 - val_kid: 0.5098\n",
            "Epoch 678/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6934 - real_acc: 0.4844 - gen_acc: 0.4967 - aug_p: 0.0000e+00 - val_kid: 0.6069\n",
            "Epoch 679/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6940 - d_loss: 0.6932 - real_acc: 0.4515 - gen_acc: 0.5485 - aug_p: 0.0000e+00 - val_kid: 0.2564\n",
            "Epoch 680/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6932 - d_loss: 0.6934 - real_acc: 0.4712 - gen_acc: 0.5008 - aug_p: 0.0000e+00 - val_kid: 0.6314\n",
            "Epoch 681/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6934 - real_acc: 0.4786 - gen_acc: 0.4868 - aug_p: 0.0000e+00 - val_kid: 0.4427\n",
            "Epoch 682/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.4984 - gen_acc: 0.5033 - aug_p: 0.0000e+00 - val_kid: 0.1849\n",
            "Epoch 683/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6934 - real_acc: 0.4934 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.5884\n",
            "Epoch 684/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6928 - real_acc: 0.5378 - gen_acc: 0.5312 - aug_p: 6.5789e-07 - val_kid: 0.2621\n",
            "Epoch 685/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6953 - d_loss: 0.6932 - real_acc: 0.4071 - gen_acc: 0.5822 - aug_p: 0.0000e+00 - val_kid: 0.2425\n",
            "Epoch 686/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4926 - gen_acc: 0.4984 - aug_p: 0.0000e+00 - val_kid: 0.3009\n",
            "Epoch 687/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6933 - d_loss: 0.6930 - real_acc: 0.5123 - gen_acc: 0.5008 - aug_p: 0.0000e+00 - val_kid: 0.3863\n",
            "Epoch 688/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6931 - real_acc: 0.4918 - gen_acc: 0.5148 - aug_p: 0.0000e+00 - val_kid: 0.2160\n",
            "Epoch 689/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.5189 - gen_acc: 0.4844 - aug_p: 0.0000e+00 - val_kid: 0.6827\n",
            "Epoch 690/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6928 - d_loss: 0.6931 - real_acc: 0.5271 - gen_acc: 0.4794 - aug_p: 0.0000e+00 - val_kid: 0.4762\n",
            "Epoch 691/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6934 - d_loss: 0.6929 - real_acc: 0.5197 - gen_acc: 0.5132 - aug_p: 0.0000e+00 - val_kid: 0.3512\n",
            "Epoch 692/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6899 - d_loss: 0.6926 - real_acc: 0.6012 - gen_acc: 0.4507 - aug_p: 0.0000e+00 - val_kid: 0.3222\n",
            "Epoch 693/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6939 - real_acc: 0.4498 - gen_acc: 0.5271 - aug_p: 0.0000e+00 - val_kid: 0.5524\n",
            "Epoch 694/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6951 - d_loss: 0.6933 - real_acc: 0.3997 - gen_acc: 0.5806 - aug_p: 0.0000e+00 - val_kid: 0.5173\n",
            "Epoch 695/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6908 - d_loss: 0.6932 - real_acc: 0.5543 - gen_acc: 0.4490 - aug_p: 3.1250e-06 - val_kid: 0.3271\n",
            "Epoch 696/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6934 - real_acc: 0.4572 - gen_acc: 0.5181 - aug_p: 0.0000e+00 - val_kid: 0.7034\n",
            "Epoch 697/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4844 - gen_acc: 0.5074 - aug_p: 0.0000e+00 - val_kid: 0.6401\n",
            "Epoch 698/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6916 - d_loss: 0.6931 - real_acc: 0.5699 - gen_acc: 0.4482 - aug_p: 0.0000e+00 - val_kid: 0.2649\n",
            "Epoch 699/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6920 - d_loss: 0.6930 - real_acc: 0.5510 - gen_acc: 0.4827 - aug_p: 0.0000e+00 - val_kid: 0.6194\n",
            "Epoch 700/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6948 - d_loss: 0.6935 - real_acc: 0.3865 - gen_acc: 0.5806 - aug_p: 0.0000e+00 - val_kid: 0.4264\n",
            "Epoch 701/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4794 - gen_acc: 0.5074 - aug_p: 0.0000e+00 - val_kid: 0.2544\n",
            "Epoch 702/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4819 - gen_acc: 0.4951 - aug_p: 0.0000e+00 - val_kid: 0.4623\n",
            "Epoch 703/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5263 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.4625\n",
            "Epoch 704/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.5099 - gen_acc: 0.4893 - aug_p: 0.0000e+00 - val_kid: 0.3927\n",
            "Epoch 705/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4819 - gen_acc: 0.4992 - aug_p: 0.0000e+00 - val_kid: 0.7715\n",
            "Epoch 706/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6931 - d_loss: 0.6933 - real_acc: 0.4893 - gen_acc: 0.4967 - aug_p: 0.0000e+00 - val_kid: 0.2314\n",
            "Epoch 707/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6941 - d_loss: 0.6931 - real_acc: 0.4638 - gen_acc: 0.5493 - aug_p: 0.0000e+00 - val_kid: 0.6318\n",
            "Epoch 708/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6923 - d_loss: 0.6933 - real_acc: 0.5395 - gen_acc: 0.4515 - aug_p: 0.0000e+00 - val_kid: 0.2932\n",
            "Epoch 709/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4967 - gen_acc: 0.5066 - aug_p: 0.0000e+00 - val_kid: 0.6566\n",
            "Epoch 710/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6929 - d_loss: 0.6932 - real_acc: 0.4918 - gen_acc: 0.4942 - aug_p: 0.0000e+00 - val_kid: 0.3325\n",
            "Epoch 711/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4860 - gen_acc: 0.5197 - aug_p: 0.0000e+00 - val_kid: 0.3927\n",
            "Epoch 712/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6933 - real_acc: 0.4827 - gen_acc: 0.4918 - aug_p: 0.0000e+00 - val_kid: 0.2170\n",
            "Epoch 713/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4901 - gen_acc: 0.5107 - aug_p: 0.0000e+00 - val_kid: 0.4194\n",
            "Epoch 714/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6933 - real_acc: 0.4901 - gen_acc: 0.5140 - aug_p: 0.0000e+00 - val_kid: 0.4318\n",
            "Epoch 715/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6925 - d_loss: 0.6933 - real_acc: 0.5214 - gen_acc: 0.4613 - aug_p: 1.1513e-06 - val_kid: 0.5493\n",
            "Epoch 716/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6926 - d_loss: 0.6933 - real_acc: 0.5271 - gen_acc: 0.4498 - aug_p: 0.0000e+00 - val_kid: 0.2891\n",
            "Epoch 717/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6933 - real_acc: 0.4655 - gen_acc: 0.5247 - aug_p: 0.0000e+00 - val_kid: 0.3710\n",
            "Epoch 718/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6913 - d_loss: 0.6931 - real_acc: 0.5880 - gen_acc: 0.4556 - aug_p: 0.0000e+00 - val_kid: 0.2734\n",
            "Epoch 719/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6927 - d_loss: 0.6930 - real_acc: 0.5337 - gen_acc: 0.4967 - aug_p: 0.0000e+00 - val_kid: 0.5658\n",
            "Epoch 720/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6948 - d_loss: 0.6934 - real_acc: 0.3816 - gen_acc: 0.5913 - aug_p: 0.0000e+00 - val_kid: 0.1712\n",
            "Epoch 721/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4737 - gen_acc: 0.5049 - aug_p: 0.0000e+00 - val_kid: 0.5279\n",
            "Epoch 722/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6932 - real_acc: 0.4474 - gen_acc: 0.5255 - aug_p: 0.0000e+00 - val_kid: 0.3170\n",
            "Epoch 723/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6934 - real_acc: 0.4745 - gen_acc: 0.5025 - aug_p: 0.0000e+00 - val_kid: 0.1590\n",
            "Epoch 724/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6929 - real_acc: 0.4671 - gen_acc: 0.5559 - aug_p: 0.0000e+00 - val_kid: 0.9771\n",
            "Epoch 725/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6916 - d_loss: 0.6931 - real_acc: 0.5765 - gen_acc: 0.4326 - aug_p: 6.9079e-06 - val_kid: 0.1684\n",
            "Epoch 726/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6939 - d_loss: 0.6934 - real_acc: 0.4169 - gen_acc: 0.5617 - aug_p: 3.2895e-07 - val_kid: 0.7195\n",
            "Epoch 727/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6878 - d_loss: 0.6933 - real_acc: 0.6275 - gen_acc: 0.3865 - aug_p: 1.3816e-05 - val_kid: 0.4806\n",
            "Epoch 728/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6935 - real_acc: 0.4975 - gen_acc: 0.5041 - aug_p: 0.0000e+00 - val_kid: 0.5476\n",
            "Epoch 729/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6923 - d_loss: 0.6933 - real_acc: 0.4523 - gen_acc: 0.5263 - aug_p: 8.3882e-06 - val_kid: 0.4733\n",
            "Epoch 730/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6921 - d_loss: 0.6931 - real_acc: 0.5428 - gen_acc: 0.4753 - aug_p: 4.4408e-06 - val_kid: 0.2174\n",
            "Epoch 731/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6935 - d_loss: 0.6932 - real_acc: 0.4556 - gen_acc: 0.5378 - aug_p: 0.0000e+00 - val_kid: 0.3864\n",
            "Epoch 732/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6940 - d_loss: 0.6932 - real_acc: 0.4285 - gen_acc: 0.5748 - aug_p: 0.0000e+00 - val_kid: 0.3100\n",
            "Epoch 733/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6931 - real_acc: 0.4572 - gen_acc: 0.5559 - aug_p: 0.0000e+00 - val_kid: 0.2668\n",
            "Epoch 734/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6933 - real_acc: 0.4827 - gen_acc: 0.4967 - aug_p: 0.0000e+00 - val_kid: 0.2864\n",
            "Epoch 735/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6930 - d_loss: 0.6932 - real_acc: 0.5025 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.2181\n",
            "Epoch 736/1000\n",
            "38/38 [==============================] - 48s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5189 - gen_acc: 0.4852 - aug_p: 0.0000e+00 - val_kid: 0.2336\n",
            "Epoch 737/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6933 - d_loss: 0.6931 - real_acc: 0.4959 - gen_acc: 0.5189 - aug_p: 0.0000e+00 - val_kid: 0.3060\n",
            "Epoch 738/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6933 - real_acc: 0.4811 - gen_acc: 0.5099 - aug_p: 0.0000e+00 - val_kid: 0.5680\n",
            "Epoch 739/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6930 - real_acc: 0.5132 - gen_acc: 0.4877 - aug_p: 0.0000e+00 - val_kid: 0.1476\n",
            "Epoch 740/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.5156 - gen_acc: 0.4975 - aug_p: 0.0000e+00 - val_kid: 0.5300\n",
            "Epoch 741/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6931 - real_acc: 0.5230 - gen_acc: 0.4819 - aug_p: 0.0000e+00 - val_kid: 0.2812\n",
            "Epoch 742/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6922 - d_loss: 0.6930 - real_acc: 0.5773 - gen_acc: 0.4564 - aug_p: 0.0000e+00 - val_kid: 0.5310\n",
            "Epoch 743/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6946 - d_loss: 0.6931 - real_acc: 0.4712 - gen_acc: 0.5255 - aug_p: 0.0000e+00 - val_kid: 0.2569\n",
            "Epoch 744/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6953 - d_loss: 0.6932 - real_acc: 0.4202 - gen_acc: 0.5905 - aug_p: 0.0000e+00 - val_kid: 0.3218\n",
            "Epoch 745/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6932 - d_loss: 0.6934 - real_acc: 0.4803 - gen_acc: 0.5016 - aug_p: 0.0000e+00 - val_kid: 0.2476\n",
            "Epoch 746/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4827 - gen_acc: 0.5140 - aug_p: 0.0000e+00 - val_kid: 0.2472\n",
            "Epoch 747/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.4893 - gen_acc: 0.4901 - aug_p: 0.0000e+00 - val_kid: 0.2708\n",
            "Epoch 748/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.4942 - gen_acc: 0.5181 - aug_p: 0.0000e+00 - val_kid: 0.3092\n",
            "Epoch 749/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6897 - d_loss: 0.6924 - real_acc: 0.5650 - gen_acc: 0.4844 - aug_p: 1.9737e-06 - val_kid: 0.2730\n",
            "Epoch 750/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6954 - d_loss: 0.6937 - real_acc: 0.4062 - gen_acc: 0.5831 - aug_p: 0.0000e+00 - val_kid: 0.1547\n",
            "Epoch 751/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6937 - d_loss: 0.6932 - real_acc: 0.4572 - gen_acc: 0.5370 - aug_p: 0.0000e+00 - val_kid: 0.1995\n",
            "Epoch 752/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.4819 - gen_acc: 0.5099 - aug_p: 0.0000e+00 - val_kid: 0.5577\n",
            "Epoch 753/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.5041 - gen_acc: 0.5107 - aug_p: 0.0000e+00 - val_kid: 0.3476\n",
            "Epoch 754/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.5041 - gen_acc: 0.5066 - aug_p: 0.0000e+00 - val_kid: 0.3364\n",
            "Epoch 755/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4959 - gen_acc: 0.4762 - aug_p: 0.0000e+00 - val_kid: 0.1870\n",
            "Epoch 756/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6931 - real_acc: 0.5066 - gen_acc: 0.5016 - aug_p: 0.0000e+00 - val_kid: 0.3632\n",
            "Epoch 757/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.5066 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.8775\n",
            "Epoch 758/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5148 - gen_acc: 0.4762 - aug_p: 0.0000e+00 - val_kid: 0.2888\n",
            "Epoch 759/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4622 - gen_acc: 0.5304 - aug_p: 1.4803e-06 - val_kid: 0.1383\n",
            "Epoch 760/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.5025 - gen_acc: 0.4934 - aug_p: 0.0000e+00 - val_kid: 0.5324\n",
            "Epoch 761/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6932 - real_acc: 0.4844 - gen_acc: 0.4868 - aug_p: 0.0000e+00 - val_kid: 0.4690\n",
            "Epoch 762/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6914 - d_loss: 0.6931 - real_acc: 0.5419 - gen_acc: 0.4729 - aug_p: 6.4145e-06 - val_kid: 0.1831\n",
            "Epoch 763/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6941 - d_loss: 0.6933 - real_acc: 0.4474 - gen_acc: 0.5395 - aug_p: 0.0000e+00 - val_kid: 0.1110\n",
            "Epoch 764/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.5041 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.3234\n",
            "Epoch 765/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6924 - d_loss: 0.6933 - real_acc: 0.5058 - gen_acc: 0.4885 - aug_p: 0.0000e+00 - val_kid: 0.4260\n",
            "Epoch 766/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6922 - d_loss: 0.6931 - real_acc: 0.5674 - gen_acc: 0.4391 - aug_p: 0.0000e+00 - val_kid: 0.3412\n",
            "Epoch 767/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6919 - d_loss: 0.6932 - real_acc: 0.5658 - gen_acc: 0.4556 - aug_p: 0.0000e+00 - val_kid: 0.7193\n",
            "Epoch 768/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6916 - d_loss: 0.6932 - real_acc: 0.5641 - gen_acc: 0.4457 - aug_p: 0.0000e+00 - val_kid: 0.3850\n",
            "Epoch 769/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6932 - d_loss: 0.6932 - real_acc: 0.4910 - gen_acc: 0.5115 - aug_p: 0.0000e+00 - val_kid: 0.9034\n",
            "Epoch 770/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6935 - d_loss: 0.6931 - real_acc: 0.5016 - gen_acc: 0.5230 - aug_p: 0.0000e+00 - val_kid: 0.5269\n",
            "Epoch 771/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6938 - d_loss: 0.6935 - real_acc: 0.4104 - gen_acc: 0.5345 - aug_p: 0.0000e+00 - val_kid: 0.2937\n",
            "Epoch 772/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6929 - real_acc: 0.5041 - gen_acc: 0.5230 - aug_p: 0.0000e+00 - val_kid: 0.3279\n",
            "Epoch 773/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6934 - real_acc: 0.4786 - gen_acc: 0.5090 - aug_p: 0.0000e+00 - val_kid: 0.6329\n",
            "Epoch 774/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6930 - d_loss: 0.6931 - real_acc: 0.5058 - gen_acc: 0.4959 - aug_p: 0.0000e+00 - val_kid: 0.2459\n",
            "Epoch 775/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6933 - d_loss: 0.6932 - real_acc: 0.4836 - gen_acc: 0.5132 - aug_p: 0.0000e+00 - val_kid: 0.3376\n",
            "Epoch 776/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6922 - d_loss: 0.6933 - real_acc: 0.5173 - gen_acc: 0.4498 - aug_p: 6.5789e-07 - val_kid: 0.5019\n",
            "Epoch 777/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6945 - d_loss: 0.6932 - real_acc: 0.3257 - gen_acc: 0.6456 - aug_p: 4.7697e-06 - val_kid: 0.7373\n",
            "Epoch 778/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6936 - d_loss: 0.6932 - real_acc: 0.4507 - gen_acc: 0.5493 - aug_p: 0.0000e+00 - val_kid: 0.3793\n",
            "Epoch 779/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6909 - d_loss: 0.6931 - real_acc: 0.4827 - gen_acc: 0.5403 - aug_p: 2.3849e-05 - val_kid: 0.4498\n",
            "Epoch 780/1000\n",
            "38/38 [==============================] - 49s 1s/step - g_loss: 0.6945 - d_loss: 0.6930 - real_acc: 0.4293 - gen_acc: 0.5946 - aug_p: 0.0000e+00 - val_kid: 0.2529\n",
            "Epoch 781/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6914 - d_loss: 0.6931 - real_acc: 0.5469 - gen_acc: 0.4539 - aug_p: 0.0000e+00 - val_kid: 0.3392\n",
            "Epoch 782/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6939 - d_loss: 0.6932 - real_acc: 0.4589 - gen_acc: 0.5378 - aug_p: 0.0000e+00 - val_kid: 0.3255\n",
            "Epoch 783/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6933 - real_acc: 0.5058 - gen_acc: 0.5025 - aug_p: 0.0000e+00 - val_kid: 0.1409\n",
            "Epoch 784/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6931 - d_loss: 0.6931 - real_acc: 0.5090 - gen_acc: 0.5164 - aug_p: 0.0000e+00 - val_kid: 0.3809\n",
            "Epoch 785/1000\n",
            "38/38 [==============================] - 50s 1s/step - g_loss: 0.6927 - d_loss: 0.6932 - real_acc: 0.5189 - gen_acc: 0.4877 - aug_p: 0.0000e+00 - val_kid: 0.3682\n",
            "Epoch 786/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6929 - d_loss: 0.6928 - real_acc: 0.5428 - gen_acc: 0.4852 - aug_p: 0.0000e+00 - val_kid: 0.3982\n",
            "Epoch 787/1000\n",
            "38/38 [==============================] - 47s 1s/step - g_loss: 0.6929 - d_loss: 0.6935 - real_acc: 0.4877 - gen_acc: 0.4803 - aug_p: 0.0000e+00 - val_kid: 0.2676\n",
            "Epoch 788/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6940 - d_loss: 0.6933 - real_acc: 0.4145 - gen_acc: 0.5559 - aug_p: 0.0000e+00 - val_kid: 0.4410\n",
            "Epoch 789/1000\n",
            "38/38 [==============================] - 46s 1s/step - g_loss: 0.6922 - d_loss: 0.6930 - real_acc: 0.5683 - gen_acc: 0.4613 - aug_p: 0.0000e+00 - val_kid: 0.8321\n",
            "Epoch 790/1000\n",
            "18/38 [=============>................] - ETA: 23s - g_loss: 0.6917 - d_loss: 0.6935 - real_acc: 0.5503 - gen_acc: 0.4462 - aug_p: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 38000 batches). You may need to use the repeat() function when building your dataset.\n",
            "38/38 [==============================] - 25s 662ms/step - g_loss: 0.6917 - d_loss: 0.6935 - real_acc: 0.5503 - gen_acc: 0.4462 - aug_p: 0.0000e+00 - val_kid: 0.4399\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7836166210>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ConditionalGAN( discriminator=discriminator , generator=generator)\n",
        "Lr=0.0002\n",
        "model.compile(\n",
        "    g_optimizer= keras.optimizers.Adam(learning_rate=Lr, beta_1=0.5, beta_2=0.9),\n",
        "    d_optimizer= keras.optimizers.Adam(learning_rate=Lr, beta_1=0.5, beta_2=0.9),\n",
        ")\n",
        "\n",
        "# save the best model based on the validation KID metric\n",
        "checkpoint_dir = '/content/drive/MyDrive/GAN GENERATED'\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "csv_logger=tf.keras.callbacks.CSVLogger('/content/drive/MyDrive/GAN GENERATED/log.csv', separator=\",\", append=True)\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_kid\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# run training and plot generated images periodically\n",
        "model.fit(\n",
        "    dataset,\n",
        "    epochs=1000,\n",
        "    steps_per_epoch=38,\n",
        "    validation_steps=5,\n",
        "    validation_data=dataset,\n",
        "    callbacks=[monitor,csv_logger,\n",
        "        # keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images),\n",
        "        checkpoint_callback,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v2xrhNmW99VA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_vACEXJj991_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OJ05GkVH99-U"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Data Efficient Gan",
      "provenance": [],
      "mount_file_id": "1bj5_aaL_460ksBz9AEgzRlezyOYQCLCo",
      "authorship_tag": "ABX9TyPh8bzrXq/0q9ul2WjiyDto",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}